---
title: "Schedule"
---

::: {.callout-important}
[**Room Change!** Come to SH-229 Video Conference in South Hall from Sep 29 on!]{.red}
:::

:::{.callout-important collapse=false appearance='default' icon=true}
## Developing Schedule
The schedule will be continuously updated also with additional readings, homework, lecture slides, and achievement check lists.
:::

# Tabular Schedule  {.unnumbered}

Date format MM-DD (month-day) (09-05 is Sep, 5) 

**Data Science Tools** is Thursdays. First meeting: **09-04**.   
**Data Science Concepts** is Mondays. First meeting:  **09-08**. 

| Week | Dates Concepts  | **Concepts Topics**                                | Dates Tools  | **Tools Topic**    |
|------|--------|-------------------------------------------------------------|----------|:------------:|
| 1    | 09-01  | *No class, Academic Opening*                                | 09-04    | R            |
| 2    | 09-08  | W#1 [What is Data Science?](material/M01.qmd)  | 09-11    | R            |
| 3    | 09-15  | W#2 [Data Visualization, Data Formats](material/M02.qmd) | 09-18    | R            |
| 4    | 09-22  | W#3 [Data Import, Data Wrangling](material/M03.qmd) | 09-25    | R            |
| 5    | 09-29  | [**Room Change!** Come to SH-229 Video Conference in South Hall from now on!]{.red} <br> [W#4 Relational Data, Math: Sets and Functions, Shift-Scale Transformation, Function Programming](material/M04.qmd)  | 10-02    | R |
| 6    | 10-06  | W#5 Descriptive Statistics, Exploratory Data Analysis | 10-09    | R            |
| 7    | 10-13  | W#6 Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus | 10-16    | R            |
| 8    | 10-20  | W#07 Models in Science, Linear Model, Interaction Effects, Nonlinear Models| 10-23    | python       |
| 9    | 10-27  | W#08 Predicting Categorical Variables, Logistic Regression, Classification Problems | 10-30    | python |
| 10   | 11-03  | **Final Projects Info** Hypothesis Testing, Classification and Regression with Decision Trees, Overfitting | 11-06    | python       |
| 11   | 11-10  | W#10 Overfitting, Clustering Algorithms  | 11-13    | python       |
| 12   | 11-17  | W#11 Collaborative Git, Bootstrapping, Cross validation, Bias-Variance Tradeoff | 11-20    | python  |
| 13   | 11-24  | W#12 Probability, Random Variables, Probability Distributions, Central Limit Theorem | 11-27    | python / R   |
| 14   | 12-01  | *No Class* Exam Preparation with a Mock Exam       | 12-04    | Student projects |
| Exam | tbd  | *To be scheduled by the admin.* **The exam takes place as an online exam**  |  |  |
| Project |        | **Deadline for submission of the Final Project marked in the [academic calendar]({{< var link.academic-calendar >}})) | 12-21 |   |
|      |        | *2025* |  |  |
| 2nd <br> Exam |   | Those who fail the exam and those who are officially excused can sit in the second exam end of January 2025. <br> *To be scheduled by the admin.*  |   |   |
|      |        | Those who fail to deliver their final project or are officially excused must deliver it by the second deadline next year (see [academic calendar]({{< var link.academic-calendar >}})) |    |   |

<!-- *Final note on official assessment scheduling: This semester provides two options to pass. The final 3rd attempt (in particular the exam) is offered again in the fall semester 2025.* -->


<!-- # Achievements W#1 {#sec-week1}

You  

- have read the [Syllabus](index.qmd) and understood the course organization
- have a running R with RStudio installation on you computer
- have done the *git-GitHub dance* and know what the tools are in principle
- have rendered quarto documents and understood its idea
- have made your first steps with R

Additional reading: 

- Quarto: Watch <https://www.youtube.com/watch?v=_f3latmOhew> from Mine Çetinkaya-Rundel (co-developer of quarto, R for Data Science, datasciencebox). 
- R: The following sections in [R for Data Science](http://r4ds.hadley.nz) 
    - [Introduction](https://r4ds.hadley.nz/intro)
    - [Whole Game (the outline of the part)](https://r4ds.hadley.nz/whole-game)
    
# Achievements W#2 {#sec-week2}

You  

- have understood the *data science process*, in particular you can describe with examples what is understood as *data wrangling* and *data exploration*, and you can describe two different purposes of data visualization in the data science process
- have identified and can explain when a pie chart is a bad visualization (when the pieces do not add up to 100%) and when a truncated y-axis is a bad visualization (when it is used to make a small difference look big).
- have understood the basic idea of the grammar of graphics and can explain what the role of a mapping and and geom is
- have made a bar chart, a scatter plot, and a line plot with ggplot
- know how many rows and columns an $m\times n$ data frame has
- can explain the basic data types, in particular `character`, `logical`, and `double` 
- know what coercion of data is (what happens when different data types are combined in a vector)
- have understood the concept of the tidy data format and can argue why a certain form of data representation is more or less tidy
- made a data frame longer and wider 

Additional reading: 

- ggplot: The following sections in [R for Data Science](http://r4ds.hadley.nz) 
    - [Ch 1: Data Visualization](https://r4ds.hadley.nz/data-visualize)
    - If you want to go deeper already now, chapter [Ch 9: Layers](https://r4ds.hadley.nz/layers)
    

# Achievements W#3 {#sec-week3}

You 

- have read in a csv-file, you can interpret the output of column type guessing, and use it to adjust and correct it for your needs if necessary
- can take a statement with a pipe operator and translate it into a nested function call without the pipe operator (and the other way round)
- you have used the `dplyr` functions `select`, `slice`, and `filter`
- you understood the concept of logical indexing, vectorized logical operation (in particular AND, OR, and NOT), and how it relates to filtering data
- you know if R or python is 0- or 1-indexed and what this means
- you have used the `dplyr` functions `distinct`, and `arrange`
- you understood how you use `mutate` and `summarize` to gather with the `.by =` specification (or `group_by`) to create new variables and data frames with aggregated data
- you know about the practical importance of the special data types `factor` and `date`

Additional reading:

The following sections in [R for Data Science](http://r4ds.hadley.nz) 

 - [Ch 3: Data transformation](https://r4ds.hadley.nz/data-transform)
 - [Ch 5: Tidy Data](https://r4ds.hadley.nz/data-tidy)
 - [Ch 7: Data Import](https://r4ds.hadley.nz/data-import)
 

# Achievements W#4 {#sec-week4}

You 

- you know the difference between `NaN` and `NA`
- you have used the `dplyr` functions `left_join`, and `full_join` to combine data frames
- you know what is meant by primary and foreign key
- know the difference between a vector (ordered elements, duplicates possible) and a set (no order, no duplicates) and have used the functions `unique`, `union`, `intersect`, and `setdiff`
- can program a function with various arguments and default values
- can program a function which does a shift and scale transformation to data
- know about the value of vectorized functions for data operations
- have used the concept of the function `map` (for iteration over values of a list or vector) and `reduce` (for aggregation over values of a list or vector)

Additional reading:

Sections in [R for Data Science](http://r4ds.hadley.nz) 

 - [Ch 19: Joins](https://r4ds.hadley.nz/joins)
 - [Ch 25: Functions](https://r4ds.hadley.nz/functions)
 - [Ch 26: Iteration](https://r4ds.hadley.nz/iteration)


# Achievements W#5 {#sec-week5}

You

- can compute and interpret the mean, median, variance, and standard deviation of vector of numbers
- can create and interpret histogram plots
- can compute and interpret quantiles of a data set
- can create and interpret boxplots
- can compute and interpret the correlation between two vectors of numbers
- you have done a first exploratory data analysis and have a first feeling of why it is not a fully standardized process
- you can classify data science research questions according to the six types of questions of Leek and Peng (2015)


Additional reading:

Leek, Jeffery T., and Peng, Roger D. 2015. “What Is the Question?” Science 347 (6228): 1314–15. <https://doi.org/10.1126/science.aaa6146>.

Read the following sections in [R for Data Science](http://r4ds.hadley.nz) 

 - [Ch 10: Exploratory Data Analysis](https://r4ds.hadley.nz/eda)


# Achievements W#6 {#sec-week6}

You

- you can create and interpret a principal component analysis, in particular you can 
    - look at the principle components, 
    - the data in PCA coordinates, and 
    - the explained variance of the principle components 
    
    and relate them to each other
- can handle computations with exponents and logarithms
- understood why logarithms appear mostly as the natural logarithm (with base $e = 2.718...$) or the logarithm with base 10
- can interpret the numbers in a vector after a $\log_{10}$ transformation
- can operationalize the concept of differentiation and integration of calculus to data science operations, e.g. with time series data:
    - You can visualize on paper the ideas that 
        - the derivative represents the slope of a function at a certain $x$-value, and 
        - the integral represents the area under the curve of a function from $x=0$ up to a certain $x$-value.
    - With time series data you can compute the change and the cumulative sum of a variable over time.
- know how the fundamental theorem of calculus relates the derivative and the integral of a function and how you can show it with data.

Additional reading:

Read the following section in [Introduction to Modern Statistics](https://openintro-ims.netlify.app/):

- [Ch 7: Linear regression with a single predictor](https://openintro-ims.netlify.app/model-slr)


# Achievements W#7 {#sec-week7}

You

- can explain, and interpret the coefficients of a linear model
- can define and fit a linear model (in R and/or python)
- know which part of a linear model output relates to explanation and prediction 
- can explain what residuals are
- have an idea what "All models are wrong, but some are useful" means
- know the difference between the $\beta$'s (population parameters which we do not know) and the $\hat\beta$'s (the estimated parameters from the data) and how this relates to a *inferential* research questions
- know how the correlation of two variables relates to the slope of a linear model with one variable as predictor and the other as response variable (the slope is the correlation times the ratio of the standard deviations of the two variables)
- know how to interpret the $R^2$ of a linear model
- know what dummy variables are and how many you need for a categorical variable with $k$ levels
- can interpret the coefficients of a linear model with dummy variables as main effects, in particular you 
    - know what it means that the intercept is the mean of the reference category (the one which is not represented by a dummy variable)
    - know that the coefficient of a dummy variable is the difference of the mean of the category represented by the dummy variable and the mean of the reference category
- can interpret the coefficients of interaction effects of dummy variables with a numerical variable
- can draw example data points in 2-dimensions where a linear model is bad
- can give an explanation where log-transforming the response variable for a linear model is a good idea

Read the following section in [Introduction to Modern Statistics](https://openintro-ims.netlify.app/):

- [Ch 8: Linear regression with multiple predictors](https://openintro-ims.netlify.app/model-mlr)

# Achievements W#8 {#sec-week8}

You 

- know how to compute the odds and the log-odds of a probability and the other way round and how the range of theoretically possible values changes between the three ways to represent the same information
- can visually sketch the logistic and the logit function within their ranges on the x-axis and y-axis
- can explain the goal of logistic regression and the conceptual steps such that a linear model can be used
- can distinguish the goals and mindsets of prediction and explanation and how a logistic regression or a linear model can be used for both
- know how a threshold probability can be used to make a classifier for actual binary predictions (yes or no) from the predicted log-odds of a logistic regression (which can be transformed to odds or probabilities)
- know what the four basic values of the confusion matrix of a classifier are (TP, FN, FP, TN)
- can make sense of the various derived measures of a classifier like accuracy, sensitivity, specificity, precision, recall (you are not expected to memorize the exact definition you can look them up)
- can explain why data is split into training and testing data and how this relates to the goals of prediction (but not to explanation)
- can explain how a classifier can manage the trade-off between sensitivity and specificity from the ROC-curve (by changing the threshold probability) 
- can explain what the AUC of a ROC-curve is -->



