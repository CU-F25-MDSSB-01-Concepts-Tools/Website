{
  "hash": "5920251508e1209375ce1b9dc2316af8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus\"\nauthor: Jan Lorenz\nformat: \n  revealjs: \n    toc: true\n    toc-depth: 1\n    slide-number: true\n    chalkboard: \n      buttons: true\n    preview-links: true\n    logo: img/ConstructorUniversity.png\n    footer: \"MDSSB-DSCO-02: Data Science Concepts\"\nbibliography: \"/home/janlo/Documents/literature/litlorenz_zot.bib\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Preliminaries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(palmerpenguins)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'palmerpenguins'\n\nThe following objects are masked from 'package:datasets':\n\n    penguins, penguins_raw\n```\n\n\n:::\n:::\n\n\n\n# Principal component analysis (PCA)\n\nA typical part of Exploratory Data Analysis. \n\n## PCA Description {.smaller}\n\nPrinciple component analysis \n\n- is a **dimensionality-reduction** technique, that means it can be used to reduce the number of variables\n- computes new variables which represent the data in a different way\n- transforms the data **linearly** to a new coordinate system where most of the variation in the data can be described with fewer variables than the original data\n\n**Today:** Quick walk through how to use and interpret it. \n\n\n## Example: Numerical variables of penguins {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeng <- \n penguins |> \n select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) |> \n na.omit()\npeng |> count(species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  species       n\n  <fct>     <int>\n1 Adelie      151\n2 Chinstrap    68\n3 Gentoo      123\n```\n\n\n:::\n:::\n\n\nWe have 342 penguins and 4 numeric variables.\n\n\n## Two Variables {.smaller}\n\n\nExample for the new axes. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npca1 <- peng |> select(flipper_length_mm, bill_length_mm) |> \n prcomp(~., data = _, scale = FALSE)\npca_vec <- t(pca1$rotation) |> as_tibble() # Vectors with x = flipper_length, y = bill_length\nggplot(peng) +\n geom_point(aes(x = flipper_length_mm, y = bill_length_mm, color = species)) +\n geom_segment(\n  data = pca_vec, \n  aes(x = mean(peng$flipper_length_mm), \n      y = mean(peng$bill_length_mm), \n      xend = c(pca1$sdev)*flipper_length_mm + mean(peng$flipper_length_mm), \n      yend = c(pca1$sdev)*bill_length_mm + mean(peng$bill_length_mm)), \n  arrow = arrow(length = unit(0.3, \"cm\"))) +\n coord_fixed()\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n::: aside\nThe two arrows show the two eigenvectors of the covariance matrix of the two variables scaled by the square root of the corresponding eigenvalues, and shifted so their origins are at the means of both variables. \n:::\n\n\n## Computation in R {.smaller}\n\nThe basic function is base-R's `prcomp` (there is an older `princomp` which is not advisable to use). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# prcomp can take a data frame with all numerical vectors as 1st argument\nP <- peng |> \n select(flipper_length_mm, bill_length_mm) |> \n prcomp()\n```\n:::\n\n\n:::: {.columns}\n\n::: {.column width='50%'}\nThe base output\n\n\n::: {.cell}\n\n```{.r .cell-code}\nP\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard deviations (1, .., p=2):\n[1] 14.549388  3.981729\n\nRotation (n x k) = (2 x 2):\n                        PC1        PC2\nflipper_length_mm 0.9637169 -0.2669266\nbill_length_mm    0.2669266  0.9637169\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width='50%'}\nThe summary output\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(P)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImportance of components:\n                           PC1     PC2\nStandard deviation     14.5494 3.98173\nProportion of Variance  0.9303 0.06968\nCumulative Proportion   0.9303 1.00000\n```\n\n\n:::\n:::\n\n:::\n\n::::\n\n\n\n## The `prcomp` object {.smaller}\n\nIncludes 4 different related entities.\n\n:::: {.columns}\n\n::: {.column width='50%'}\nThe **standard deviations** related to each principal component.   \n\n::: {.cell}\n\n```{.r .cell-code}\nP$sdev\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 14.549388  3.981729\n```\n\n\n:::\n:::\n\n\nThe matrix of variable **loadings**. (It is also the matrix which rotates the original data vectors.)\n\n::: {.cell}\n\n```{.r .cell-code}\nP$rotation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                        PC1        PC2\nflipper_length_mm 0.9637169 -0.2669266\nbill_length_mm    0.2669266  0.9637169\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width='50%'}\nThe means for each original variable. \n\n::: {.cell}\n\n```{.r .cell-code}\nP$center\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nflipper_length_mm    bill_length_mm \n        200.91520          43.92193 \n```\n\n\n:::\n:::\n\nNote, there are also standard deviations of original variables in `$scale` when this is set to be used.\n\nThe centered (scaled, if set) and rotated data.\n\n::: {.cell}\n\n```{.r .cell-code}\nP$x\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               PC1         PC2\n  [1,] -20.4797199  0.66892267\n  [2,] -15.5543649 -0.28022355\n  [3,]  -6.6673719 -1.91158941\n  [4,]  -9.5557414 -4.84711693\n  [5,] -11.7528828 -1.54067330\n  [6,] -20.5331052  0.47617930\n  [7,]  -6.9609911 -2.97167796\n  [8,] -10.2497505 -7.35278078\n  [9,] -11.0321810  1.06136223\n [10,] -16.0081402 -1.91854222\n [11,] -21.7904413 -0.31698266\n [12,] -18.9821498  2.32942980\n [13,] -10.9760146 -2.48220170\n [14,]  -5.2977029 -8.20555532\n [15,] -17.2921689 -2.80807586\n [16,]  -7.0944544 -3.45353639\n [17,]  -4.1526997 -0.32526550\n [18,] -18.8431243 -4.66132637\n [19,]  -6.1096072  3.84852331\n [20,] -27.5727425  1.28457691\n [21,] -21.8171340 -0.41335434\n [22,] -13.6241501 -4.55038405\n [23,] -16.8650864 -1.26612888\n [24,] -21.5235147  0.64673421\n [25,] -15.7117398 -4.59476098\n [26,] -18.1518963  1.58064478\n [27,] -14.3237215  0.41656672\n [28,] -29.4734836  1.91480178\n [29,] -21.0697395  2.28505287\n [30,] -23.2640999  1.85518920\n [31,] -23.8780310 -0.36135959\n [32,] -13.6269312 -0.81407674\n [33,] -17.1081014  1.60283324\n [34,]  -7.7083856 -5.67008518\n [35,]  -5.9972743 -3.23860456\n [36,] -11.8863461 -2.02253174\n [37,] -20.6159643  3.92337154\n [38,] -20.8801098 -0.77665262\n [39,] -17.4017207  0.54274469\n [40,] -20.2100122 -2.10366777\n [41,]  -6.5339086 -1.42973098\n [42,] -16.4886080 -3.65323258\n [43,]  -4.6893340  1.48360808\n [44,] -17.1853983 -2.42258912\n [45,] -11.6728048 -1.25155824\n [46,] -18.9821498  2.32942980\n [47,] -22.8342362 -0.33917112\n [48,] -12.6337406 -4.72093895\n [49,]  -9.9883862  1.08355069\n [50,] -15.5276723 -0.18385187\n [51,] -13.4667753 -0.23584662\n [52,] -12.9006672 -5.68465582\n [53,]  -1.3950124 -1.60790371\n [54,] -15.9252810 -5.36573447\n [55,] -10.2286201  0.21620552\n [56,] -15.6878282 -0.76208199\n [57,]  -8.5147276 -1.08862116\n [58,] -21.1737290 -1.83674117\n [59,]  -8.3517906 -4.24669835\n [60,] -17.5324029 -3.67542104\n [61,]  -6.4004453 -0.94787255\n [62,] -17.0252423 -1.84435900\n [63,]  -9.3449812 -0.33983614\n [64,] -18.3092711 -2.73389264\n [65,]  -9.2115179  0.14202229\n [66,]  -7.9486195 -6.53743036\n [67,] -13.1998487  0.72787024\n [68,] -12.6604332 -4.81731064\n [69,]  -3.3758314 -1.26679390\n [70,] -13.3010571 -7.13023111\n [71,] -11.6461122 -1.15518656\n [72,]  -5.8905036 -2.85311781\n [73,]  -3.2718419  2.85500015\n [74,] -12.7672039 -5.20279739\n [75,]  -6.0000554  0.49770275\n [76,] -10.3620834 -0.26565292\n [77,] -18.0957298 -1.96291915\n [78,] -15.4715058 -3.72741580\n [79,]  -6.1869040 -0.17689906\n [80,] -13.9711547 -5.80321597\n [81,]  -5.0096459  0.32714784\n [82,] -15.3380425 -3.24555737\n [83,]  -9.9828239 -6.38906391\n [84,] -11.3230191 -3.73503363\n [85,]  -7.3641622 -0.68094595\n [86,] -12.5536626 -4.43182390\n [87,] -13.3572235 -3.58666718\n [88,] -12.9835263 -2.23746357\n [89,] -11.8596534 -1.92616005\n [90,]  -1.1492162 -8.21317314\n [91,]   3.1833380 -3.80988186\n [92,] -17.9861781 -5.31373971\n [93,] -15.5276723 -0.18385187\n [94,] -15.4715058 -3.72741580\n [95,]   5.9944106 -4.89977671\n [96,] -12.0731947 -2.69713354\n [97,]  -5.7036550 -2.17851601\n [98,] -24.9724301 -4.31259873\n [99,]  -8.7844354  1.68396928\n[100,] -10.9732334 -6.21850901\n[101,]   1.2292116 -3.37240036\n[102,] -18.9259834 -1.21413413\n[103,] -12.1532727 -2.98624860\n[104,]  -9.2354294 -3.69065670\n[105,] -17.4284133  0.44637301\n[106,]  -3.2662796 -4.61761446\n[107,] -12.0465021 -2.60076185\n[108,] -20.7466465 -0.29479419\n[109,]  -3.9658510  0.34933630\n[110,]  -4.3634598 -4.83254629\n[111,]  -9.1075284  4.26381634\n[112,]  -8.7549616 -1.95596634\n[113,]  -4.2327776 -0.61438056\n[114,] -10.7090880 -1.51848484\n[115,]  -5.0630312  0.13440447\n[116,] -13.8671651 -1.68142192\n[117,]  -3.6132842 -5.87044638\n[118,] -13.6775354 -4.74312742\n[119,] -12.2361318  0.46094364\n[120,] -15.4715058 -3.72741580\n[121,]  -4.4702304 -5.21803304\n[122,] -25.0046850  3.06364419\n[123,]   0.3722654 -2.71998702\n[124,] -16.7021493 -4.42420607\n[125,]  -2.7324265 -2.69018073\n[126,] -10.9226292 -2.28945833\n[127,]  -6.3470600 -0.75512918\n[128,] -10.8692439 -2.09671496\n[129,]   8.8027021 -2.25336424\n[130,] -11.9664241 -2.31164679\n[131,]  -3.9925437  0.25296462\n[132,]  -9.5290487 -4.75074525\n[133,]  -3.5598989 -5.67770301\n[134,] -14.9643453 -1.89635376\n[135,] -11.2724149  0.19401705\n[136,] -11.7767943 -5.37335229\n[137,]  -1.8754802 -3.34259407\n[138,] -17.1853983 -2.42258912\n[139,]  -8.7549616 -1.95596634\n[140,]  -8.6214983 -1.47410791\n[141,] -14.2970288  0.51293840\n[142,] -15.6021880 -7.94558153\n[143,] -11.3791856 -0.19146969\n[144,] -10.3593023 -4.00196022\n[145,] -16.6515451 -0.49515539\n[146,] -11.7795755 -1.63704499\n[147,] -18.2558858 -2.54114927\n[148,]  -7.8151562 -6.05557193\n[149,]  -9.2621221 -3.78702838\n[150,] -15.5248912 -3.92015917\n[151,]  -0.5647588 -2.35668874\n[152,]  10.3002722 -0.59285711\n[153,]  29.6519063 -1.90596663\n[154,]  10.0305645  2.17973333\n[155,]  18.0873039  1.29715250\n[156,]  14.5555295 -0.21498819\n[157,]   9.4433259  0.05955623\n[158,]  10.1134236 -1.26745892\n[159,]  18.1701630 -2.15003975\n[160,]   7.6254440 -2.75741114\n[161,]  14.3419882 -0.98596168\n[162,]  11.8034045 -6.40496458\n[163,]  15.8929436  0.86728882\n[164,]  13.0312668 -1.97186701\n[165,]  12.8416371  1.08983849\n[166,]   9.2564773 -0.61504558\n[167,]  16.9367385  0.88947729\n[168,]   8.2421563 -4.27716966\n[169,]  20.7649133 -0.27460078\n[170,]   8.3995311  0.03736776\n[171,]  21.5951668 -1.02338580\n[172,]  18.1406893  1.48989587\n[173,]  13.8882130 -2.62428035\n[174,]  12.3344765 -0.74122355\n[175,]  14.2085249 -1.46782012\n[176,]  13.3009745 -4.74445745\n[177,]  14.1551396 -1.66056349\n[178,]  14.6917739 -3.46943706\n[179,]  14.6089148 -0.02224482\n[180,]   9.8971012  1.69787490\n[181,]  20.0147377  0.76329931\n[182,]  21.2214696 -2.37258941\n[183,]   7.4919807 -3.23926957\n[184,]   6.1784781 -0.48886760\n[185,]  32.2144016  7.34571526\n[186,]  19.7745037 -0.10404587\n[187,]  19.5876551 -0.77864767\n[188,]  11.2934628 -4.49971932\n[189,]  17.5562319 -4.36658853\n[190,]   6.8485757 -1.81588274\n[191,]   8.1031307  2.71358652\n[192,]   6.5015712 -3.06871466\n[193,]  24.7265513 -0.95682041\n[194,]   9.1230140 -1.09690401\n[195,]  16.0530996  1.44551894\n[196,]  22.0756347  0.71130455\n[197,]  15.4152569 -4.60370884\n[198,]   9.1763994 -0.90416063\n[199,]  24.9667853 -0.08947523\n[200,]  11.9073940 -2.28317054\n[201,]  13.9149057 -2.52790867\n[202,]   9.4700186  0.15592792\n[203,]  19.6143478 -0.68227599\n[204,]   9.0696287 -1.28964738\n[205,]  24.8600146 -0.47496198\n[206,]  16.1893440 -1.80892993\n[207,]  18.6801047 -4.05528501\n[208,]   6.7951904 -2.00862611\n[209,]  18.8135680 -3.57342658\n[210,]   6.6350345 -2.58685623\n[211,]  23.9763758  0.08107968\n[212,]   7.1955803 -0.56305082\n[213,]  19.9641335 -3.16575137\n[214,]  13.0846521 -1.77912364\n[215,]  31.7634075  1.97108929\n[216,]  17.9299291 -3.01738492\n[217,]  29.5985210 -2.09871001\n[218,]  13.2181154 -1.29726521\n[219,]  28.5547261 -2.12089847\n[220,]  18.2797148 -5.50086030\n[221,]  23.0927369  0.63712133\n[222,]  15.5459390 -0.38554310\n[223,]  20.0175188 -2.97300799\n[224,]  20.4979867 -1.23831764\n[225,]  16.1893440 -1.80892993\n[226,]  15.1989345 -1.63837502\n[227,]  29.2782091 -3.25517024\n[228,]   8.7465357  1.29019969\n[229,]  20.3083569  1.82338786\n[230,]  13.9149057 -2.52790867\n[231,]  21.6246406 -4.66332142\n[232,]  12.0647688  2.03136689\n[233,]  21.6457710  2.90566487\n[234,]  11.6109936  0.39304822\n[235,]  23.8696051 -0.30440707\n[236,]  10.9436771 -2.01624394\n[237,]  27.9380138 -0.60113995\n[238,]  16.3255884 -5.06337880\n[239,]  18.4343085  2.54998442\n[240,]  11.6376863  0.48941990\n[241,]  30.2124521  0.11783878\n[242,]  17.4199874 -1.11213966\n[243,]  28.3117111  0.74806366\n[244,]  11.1038331 -1.43801382\n[245,]  23.7361418 -0.78626550\n[246,]  12.7643402 -2.93558388\n[247,]  26.0105801 -0.06728677\n[248,]  15.9997143  1.25277557\n[249,]  21.1146989 -2.75807616\n[250,]   3.2044684  3.75910443\n[251,]  25.1269412  0.48875489\n[252,]  18.6506309 -0.41534939\n[253,]  29.2993395  4.31381605\n[254,]  14.4487589 -0.60047494\n[255,]  27.4842386 -2.23945862\n[256,]  15.4391684 -0.77102985\n[257,]  14.3419882 -0.98596168\n[258,]   8.1620783 -4.56628472\n[259,]  19.9585712  4.30686324\n[260,]   6.6617271 -2.49048455\n[261,]   8.9066916  1.86842981\n[262,]  16.2933335  2.31286412\n[263,]  28.6348041 -1.83178341\n[264,]  11.5336968 -3.63237414\n[265,]  30.0522962 -0.46039134\n[266,]  16.1092660 -2.09804499\n[267,]  31.0132319  3.00898937\n[268,]  15.6554908 -3.73636366\n[269,]  21.6218595 -0.92701412\n[270,]  13.4850420 -0.33354834\n[271,]  14.3419882 -0.98596168\n[272,]  22.0489420  0.61493287\n[273,]  11.0237551 -1.72712888\n[274,]  13.2420270  2.53541378\n[275,]  -7.9035776  4.86423493\n[276,]  -3.1144671  7.16953757\n[277,]  -5.6586131  9.22314928\n[278,] -12.0520643  4.87185275\n[279,]  -1.4300484  9.50464651\n[280,]  -2.4682810  2.00984344\n[281,] -21.5023843  8.21572050\n[282,]  -1.8037456  8.15544290\n[283,]  -5.1458903  3.58159671\n[284,]  -0.8400288  7.88851631\n[285,]  -6.9131681  4.69368002\n[286,]  -4.5881256  9.34170943\n[287,] -14.5161323  7.21457952\n[288,]   2.2379704  7.76233833\n[289,]  -9.9911673  4.81985800\n[290,]   1.8375806  6.31676303\n[291,]  -2.0706722  7.19172604\n[292,] -15.4348073 18.88317139\n[293,]  -9.8577040  5.30171643\n[294,]  -4.2917252  6.66549067\n[295,] -19.5988621  3.84918832\n[296,]  -8.3334413  7.05859525\n[297,] -13.6030197  3.01860225\n[298,]  -5.8454617  8.54854747\n[299,]  -4.9590417  4.25619852\n[300,]  -1.6168970  8.83004470\n[301,]   0.8738637  6.58368963\n[302,]   0.6069371  5.61997276\n[303,]  -8.8939871  5.03478983\n[304,]   6.3063792  7.46560544\n[305,] -14.2169508  0.80205346\n[306,]   2.8252089  9.88251543\n[307,] -13.7898683  2.34400044\n[308,]   3.8984776  6.26476828\n[309,]  -4.1582619  7.14734911\n[310,]  -0.8906330  3.95946563\n[311,]  -4.7188078  5.12354369\n[312,]  10.9114222  5.35999898\n[313,]  -7.7968070  5.24972167\n[314,]   6.4932278  8.14020725\n[315,]  10.1106424  2.46884839\n[316,] -12.8022399  5.90975284\n[317,]  -2.8742331  8.03688275\n[318,]  -4.3156367  2.83281168\n[319,]  -2.8742331  8.03688275\n[320,]   1.9176585  6.60587809\n[321,]  -8.8700756  8.86746882\n[322,]  12.0380762  1.93499520\n[323,] -11.3875289 11.01745222\n[324,]  -1.2404187  6.44294101\n[325,]  -0.7304770  4.53769575\n[326,]   2.0778145  7.18410821\n[327,]  -7.1534020  3.82633484\n[328,]   3.8183996  5.97565322\n[329,] -13.7898683  2.34400044\n[330,]  -1.5635117  9.02278808\n[331,]  -9.2142990  3.87832960\n[332,]   3.4447024  4.62644961\n[333,]   2.7212194  5.76072138\n[334,]  -6.2163778  3.46303656\n[335,]   7.0298621  6.33133367\n[336,] -10.7146502  5.95412977\n[337,]  -5.2259683  3.29248165\n[338,]   9.0345927  9.82290284\n[339,]   0.9328113 -0.69618161\n[340,]  -6.1123883  7.58483061\n[341,]  10.5911103  4.20353874\n[342,]  -1.1336480  6.82842776\n```\n\n\n:::\n:::\n\n:::\n\n::::\n\n## PCA as Exploratory Data Analysis {.smaller}\n\nSuppose we do a PCA with all 342 penguins (rows) and all 4 numeric variables.\n\n- *How long will the vector of standard deviations be?* [4]{.fragment}  \n- *What dimensions will the rotation matrix have?* [4 x 4]{.fragment}  \n- *What dimensions will the rotated data frame have?* [342 x 4]{.fragment}\n\n. . . \n\nWhen we do a PCA for exploration there are 3 things to look at: \n\n1. The data in PC coordinates - the centered (scaled, if set) and rotated data.  \n2. The rotation matrix - the variable loadings.\n3. The variance explained by each PC - based on the standard deviations. \n\n## All variables {.smaller}\n\nNow, with `scale = TRUE` (recommended). Data will be centered and scaled (a.k.a. standardized) first. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npeng_PCA <- peng |> select(-species) |> \n prcomp(scale = TRUE)\npeng_PCA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard deviations (1, .., p=4):\n[1] 1.6594442 0.8789293 0.6043475 0.3293816\n\nRotation (n x k) = (4 x 4):\n                         PC1          PC2        PC3        PC4\nbill_length_mm     0.4552503 -0.597031143 -0.6443012  0.1455231\nbill_depth_mm     -0.4003347 -0.797766572  0.4184272 -0.1679860\nflipper_length_mm  0.5760133 -0.002282201  0.2320840 -0.7837987\nbody_mass_g        0.5483502 -0.084362920  0.5966001  0.5798821\n```\n\n\n:::\n:::\n\n\n\n## Explore data in PC coordinates {.smaller}\n\n\n:::: {.columns}\n\n::: {.column width='35%'}\n- Start plotting PC1 against PC2. By default these are the most important ones. Drill deeper later. \n- Append the original data. Here used to color by species. \n:::\n\n::: {.column width='65%'}\n\n::: {.cell}\n\n```{.r .cell-code}\nplotdata <- peng_PCA$x |> \n as_tibble() |> \n bind_cols(peng)\nplotdata |> ggplot(aes(PC1, PC2, color = species)) +\n geom_point() +\n coord_fixed() + theme_minimal(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n:::\n\n::::\n\n\n## Variable loadings {.smaller}\n\n- The columns of the rotation matrix shows how the original variables *load* on the principle components. \n- We can interpret these loadings and give descriptive names to principal components. \n- For plotting we bring the rotation matrix to long format with `PC` and `value` column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeng_PCA$rotation |> as_tibble(rownames = \"variable\") |> \n pivot_longer(starts_with(\"PC\"), names_to = \"PC\", values_to = \"value\") |> \n ggplot(aes(value, variable)) + \n geom_col() + \n geom_vline(xintercept = 0, color = \"blue\") +\n facet_wrap(~PC, nrow = 1) +\n theme_minimal(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n## Variance explained {.smaller}\n\n- Principle components are by default sorted by importance. \n- The squares of the standard deviation for each component gives its variances and **variances have to sum up to the sum of the variances** of the original variables. \n    - When original variables were standardized their original variances are all each one. Consequently, the variances of the principal components sum up to the number of original variables.\n- A typical plot to visualize the importance of the components is to plot the percentage of the variance explained by each component.\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ntibble(PC = 1:4, sdev = peng_PCA$sdev) |>\n mutate(percent = sdev^2/sum(sdev^2) * 100) |>\n ggplot(aes(PC, percent)) +\n geom_col() +\n theme_grey(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n## Interpretations (1) {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(PC = 1:4, sdev = peng_PCA$sdev) |> \n mutate(percent = sdev^2/sum(sdev^2) * 100,\n        cum_percent = cumsum(percent)) |>\n ggplot(aes(PC, percent)) + geom_col() + \n geom_line(aes(y = cum_percent), color = \"blue\") +\n geom_point(aes(y = cum_percent), color = \"blue\") + \n scale_y_continuous(breaks = seq(0,100,20))\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-15-1.png){width=480}\n:::\n:::\n\n\n- The first component explains almost 70% of the variance.  \n- The first two explain about 88% of the total variance. \n\n\n## Interpretations (2) {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeng_PCA$rotation |> as_tibble(rownames = \"variable\") |> \n pivot_longer(starts_with(\"PC\"), names_to = \"PC\", values_to = \"value\") |> \n ggplot(aes(value, variable)) + geom_col() + geom_vline(xintercept = 0, color = \"blue\") +\n facet_wrap(~PC, nrow = 1) \n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n1. To score high on PC1 a penguin needs to be generally large but with low bill depth.\n2. Penguins scoring high on PC2 are penguins with generally small bills.  \n\n## Interpretations (3) {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng1 <- plotdata |> ggplot(aes(PC1, PC2, color = species)) +\n geom_point() + coord_fixed()\ng2 <- peng_PCA$rotation |> as_tibble(rownames = \"variable\") |> \n pivot_longer(starts_with(\"PC\"), names_to = \"PC\", values_to = \"value\") |> \n filter(PC==\"PC2\" | PC == \"PC1\") |> \n ggplot(aes(value, variable)) + geom_col() +\n facet_wrap(~PC, nrow = 1)\nlibrary(patchwork)\ng1 + g2\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n![](https://upload.wikimedia.org/wikipedia/commons/e/e3/Hope_Bay-2016-Trinity_Peninsula%E2%80%93Ad%C3%A9lie_penguin_%28Pygoscelis_adeliae%29_04.jpg){height=120}\n![](https://upload.wikimedia.org/wikipedia/commons/0/08/South_Shetland-2016-Deception_Island%E2%80%93Chinstrap_penguin_%28Pygoscelis_antarctica%29_04.jpg){height=120}\n![](https://upload.wikimedia.org/wikipedia/commons/0/00/Brown_Bluff-2016-Tabarin_Peninsula%E2%80%93Gentoo_penguin_%28Pygoscelis_papua%29_03.jpg){height=120}\n\n\n\n## Apply PCA {.smaller}\n\n- Besides standardization, PCA may benefit from **preprocessing** steps of **data transformation** with variables with skew distributions. Use log, square-root, or Box-Cox transformation. This may result in less outliers.\n- PCA is a often a useful step of **exploratory data analysis** when you have a large number of numerical variables to show the empirical *dimensionality* of the data and its structure.\n- It is related to the correlation-matrix and can \"summarize\" its structure.\n- Limitation: PCA is only sensitive for linear relation ships (no U-shaped) or the like\n- The principal components can be used **as predictors** in a model instead of the raw variables. \n\n## Properties of PCA {.smaller}\n\n::: {.incremental}\n- The principal components (the columns of the rotation matrix) are maximally *uncorrelated* (actually they are even *orthogonal*).\n- This also holds for the columns of the rotated data. \n- The total variances of all prinicipal components sum up to the number of variables (when variables are standardized)\n- The PCA is unique. All principle components together are a complete representation of the data. (Unlike other technique of dimensionality reduction which may rely on starting values, random factors, or tuning parameters)\n    - To be precise: It is unique modulo the sign of the PCs. When $x$ is a PC, then $-x$ is as well and can replace it.  \n:::\n\n\n## Relations of PCA {.smaller}\n\n::: {.incremental}\n- A technique similar in spirit is *factor analysis* (e.g. `factanal`). It is more theory based as it requires to specify to the theoriezed number of factors up front. \n- PCA is an example of the importance of linear algebra (\"matrixology\") in data science techniques. \n:::\n\n. . .\n\n:::: {.columns}\n\n::: {.column width='50%'}\n  - PCA is based on the **eigenvalue decomposition** of the covariance matrix (or correlation matrix in the standardized case) of the data.\n:::\n\n::: {.column width='50%'}\n![](https://imgs.xkcd.com/comics/machine_learning.png){ height=350 }<https://xkcd.com/1838/>\n:::\n\n::::\n\n\n\n\n\n\n\n# Math: Exponentiations and Logarithms\n\n## Rules for Exponentiation {background-color=\"aquamarine\" .smaller}\n\n:::{.columns}\n:::{.column width=\"20%\"}\n$x^0$  \n\n$0^x$  \n\n$0^0$  \n\n$(x\\cdot y)^a$  \n\n$x^{-a}$, $x^{-1}$  \n\n$x^\\frac{a}{b}$, $x^\\frac{1}{2}$  \n\n$(x^a)^b$  \n\n::: \n:::{.column}\n:::{.fragment fragment-index=1}\n$x^0 = 1$\n:::\n:::{.fragment fragment-index=2}\n$0^x = 0$ for $x\\neq 0$\n:::\n:::{.fragment fragment-index=3}\n$0^0 = 1$ (discontinuity in $0^x$)\n:::\n:::{.fragment fragment-index=4}\n$(x\\cdot y)^a = x^a\\cdot x^b$  \n:::\n:::{.fragment fragment-index=5}\n$x^{-a} = \\frac{1}{x^a}$, $x^{-1} = \\frac{1}{x}$  \n:::\n:::{.fragment fragment-index=6}\n$x^\\frac{a}{b} = \\sqrt[b]{x^a} = (\\sqrt[b]{x})^a,\\ x^\\frac{1}{2} = \\sqrt{x}$  \n:::\n:::{.fragment fragment-index=7}\n$(x^a)^b = x^{a\\cdot b} = (x^b)^a \\neq x^{a^b} = x^{(a^b)}$   \nExample: $(4^3)^2 = 64^2 = 4096 \\qquad 4^{3^2} = 4^9 = 262144$\n:::\n:::\n:::\n\n\n## More rules for exponentiation {.smaller background-color=\"aquamarine\"}\n\n:::{.columns}\n:::{.column width=\"20%\"}\n$x^a\\cdot x^b$\n::: \n:::{.column width=\"79%\"}\n:::{.fragment}\n$x^a\\cdot x^b = x^{a+b}$  Multiplication of powers (with same base $x$) becomes addition of exponents.\n:::\n:::\n:::\n\n. . . \n\n:::{.columns}\n:::{.column width=\"20%\"}\n$(x+y)^a$\n::: \n:::{.column width=\"79%\"}\n:::{.fragment}\nNo \"simple\" form! For $a$ integer use *binomial expansion*.\n$(x+y)^2 = x^2 + 2xy + y^2$  \n$(x+y)^3 = x^3 + 3x^2y + 3xy^2 + y^3$  \n$(x+y)^n = \\sum_{k=0}^n {n \\choose k} x^{n-k}y^k$\n:::\n:::\n:::\n\n. . . \n\n**Pascal's triangle**\n\n:::{.columns}\n:::{.column width=\"40%\"}\n![From wikipedia](https://upload.wikimedia.org/wikipedia/commons/0/0d/PascalTriangleAnimated2.gif){height=200} \n:::\n:::{.column}\nWe meet it again in **Probability**:   \nA row represents a *binomial distribution*   \nWhich tends to mimics the *normal distribution* more and more  \nand is related to the *central limit theorem*\n:::\n:::\n\n\n## Logarithms {.smaller background-color=\"aquamarine\"}\n\n**Definition:** A *logarithm* of $a$ for some base $b$ is the value of the exponent which brings $b$ to $a$: \n$\\log_b(a) = x$ means that $b^x =a$\n\n**Most common:**\n\n- $\\log_{10}$ useful for plotting data in logarithmic scales because the numbers can be interpreted easiest (number of decimals of the original values)\n- $\\log_{e}$ *natural logarithm* (also $\\log$ or $\\ln$) useful in calculus and statistics because of nice mathematical properties\n\n. . .\n\n:::{.columns}\n:::{.column width=\"30%\"}\n$\\log_{10}(100) =$\n::: \n:::{.column}\n:::{.fragment}\n$2$\n:::\n:::\n:::\n\n. . .\n\n:::{.columns}\n:::{.column width=\"30%\"}\n$\\log_{10}(1) =$\n::: \n:::{.column}\n:::{.fragment}\n$0$\n:::\n:::\n:::\n\n. . .\n\n:::{.columns}\n:::{.column width=\"30%\"}\n$\\log_{10}(6590) =$\n::: \n:::{.column}\n:::{.fragment}\n$3.818885$\n:::\n:::\n:::\n\n. . .\n\n:::{.columns}\n:::{.column width=\"30%\"}\n$\\log_{10}(0.02) =$\n::: \n:::{.column}\n:::{.fragment}\n$-1.69897$\n:::\n:::\n:::\n\n\n## Rules for logarithms {.smaller background-color=\"aquamarine\"}\n\nUsually only one base is used in the same context, because changing base is easy:\n\n$\\log_c(x) = \\frac{\\log_b(x)}{\\log_b(c)} = \\frac{\\log(x)}{\\log(c)}$\n\n\n\n\n:::{.columns}\n:::{.column width=\"20%\"}\n$\\log(x\\cdot y)$\n::: \n:::{.column width=\"79%\"}\n:::{.fragment}\n$= \\log(x) + \\log(y)$ Multiplication $\\to$ addition.\n:::\n:::\n:::\n\n. . .\n\n:::{.columns}\n:::{.column width=\"20%\"}\n$\\log(x^y)$\n::: \n:::{.column width=\"75%\"}\n:::{.fragment}\n$= y\\cdot\\log(x)$\n:::\n:::\n\n\n:::\n:::{.columns}\n:::{.column width=\"20%\"}\n$\\log(x+y)$\n::: \n:::{.column width=\"75%\"}\n:::{.fragment}\ncomplicated!\n:::\n:::\n:::\n\n. . . \n\nAlso changing bases for powers is easy: $x^y = (e^{\\log(x)})^y = e^{y\\cdot\\log(x)}$\n\n\n\n\n\n\n\n# Epidemic Modeling\n\nAn example for **modeling** the **data generating process**\n\n\n## SIR model  {.smaller  background-color=\"khaki\"}\n\n- Assume a population of $N$ individuals.  \n- Individuals can have different states, e.g.: **S**usceptible, **I**nfectious, **R**ecovered, ...\n- The population divides into compartments of these states which change over time, e.g.:   $S(t), I(t), R(t)$ *number of susceptible, infectious, recovered* individuals\n\nNow we define dynamics like\n\n![](https://upload.wikimedia.org/wikipedia/commons/3/30/Diagram_of_SIR_epidemic_model_states_and_transition_rates.svg)\n\nwhere the numbers on the arrows represent transition probabilities. \n\n## Agent-based Simulation {.smaller  background-color=\"khaki\"}\n\n**Agent-based model**: Individual agents are simulated and interact with each other.  \nExplore and analyze with **computer simulations**.\n\nA tool: **NetLogo** <https://ccl.northwestern.edu/netlogo/>\n\n![](http://netlogoweb.org/assets/images/desktopicon.png)\n\nWe look at the model **\"Virus on a Network\"** from the model library.\n\nDirect Link to [Virus on a Network in NetLogoWeb](https://www.netlogoweb.org/launch#https://www.netlogoweb.org/assets/modelslib/Sample%20Models/Networks/Virus%20on%20a%20Network.nlogo)\n\n## Virus on a Network: 6 links, initial {.smaller  background-color=\"khaki\"}\n\nAgents connected in a **network** with on average 6 links per agent. 3 are infected initially.\n\n![](img/netlogo_SIR_6links_init.png)\n\n\n## Virus on a Network: 6 links, final {.smaller  background-color=\"khaki\"}\n\nThe outbreak dies out after some time.\n\n![](img/netlogo_SIR_6links_final.png)\n\n\n## Virus on a Network: 15 links, initial {.smaller  background-color=\"khaki\"}\n\nRepeat the simulation with 15 links per agent. 3 are infected initially.\n![](img/netlogo_SIR_15links_init.png)\n\n\n## Virus on a Network: 15 links, final {.smaller  background-color=\"khaki\"}\n\nThe outbreak had infected most agents.\n\n![](img/netlogo_SIR_15links_final.png)\n\n\n## SI model {.smaller  background-color=\"khaki\"}\n\nNow, we only treat the SI part of the model. We ignore recovery. \n\n- People who are susceptible can become infected through contact with infectious\n- People who are infectious stay infectious \n\nThe parameter $\\beta$ is the average number of contacts per unit time multiplied with the probability that an infection happens during such a contact. \n\n\n## SI-model: Simulation in R {.smaller background-color=\"khaki\"}\n\n- We produce a vector of length $N$ with entries representing the state of each individual as `\"S\"` or `\"I\"`. \n- We model the random infection process in each step of unit time\n\n**Setup**\n\nParameters: $N=150, \\beta=0.3$, a function to produce randomly infect individuals\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nN <- 150\nbeta <- 0.3\nrandomly_infect <- function(N, prob) { \n runif(N) < prob \n # Gives a logical vector of length N\n # where TRUE appears with probability beta\n}\n# Test\nrandomly_infect(N, beta) |> head() # First 6\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE FALSE FALSE  TRUE FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ninit <- rep(\"S\",N) # All susceptible\ninit[1] <- \"I\" # Infect one individual\ninit |> head() # First 6\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"I\" \"S\" \"S\" \"S\" \"S\" \"S\"\n```\n\n\n:::\n:::\n\n\n\n## SI-model: Simulation in R {.smaller background-color=\"khaki\"}\n\nIteration over 75 time steps.\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ntmax <- 75\nsim_run <- list(init) # list with one element\n# This list will collect the states of \n# all individuals over tmax time steps \nfor (i in 2:tmax) {\n # Every agents has a contact with a random other\n contacts <- sample(sim_run[[i-1]], size = N)\n sim_run[[i]] <- if_else( # vectorised ifelse\n  # conditions vector: contact is infected\n  # and a random infection happens\n  contacts == \"I\" & randomly_infect(N, beta), \n  true = \"I\", \n  false = sim_run[[i-1]]\n  ) # otherwise state stays the same\n}\nsim_output <- tibble( # create tibble for ggplot\n # Compute a vector with length tmax \n # with the count of \"I\" in sim_run list\n t = 0:(tmax-1), # times steps\n # count of infected and output a vector\n infected = sim_run |> map_dbl(\\(x) sum(x == \"I\"))) \nsim_output |> \n ggplot(aes(t,infected)) + geom_line() +\n theme_minimal(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## SI-model: Simulation in R {.smaller background-color=\"khaki\"}\n\nRun with $N = 10000$\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nN <- 10000\ninit <- rep(\"S\",N) # All susceptible\ninit[1] <- \"I\" # Infect one individual\ntmax <- 75\nsim_run <- list(init) # list with one element\n# This list will collect the states of \n# all individuals over tmax time steps \nfor (i in 2:tmax) {\n # Every agents has a contact with a random other\n contacts <- sample(sim_run[[i-1]], size = N)\n sim_run[[i]] <- if_else( # vectorised ifelse\n  # conditions vector: contact is infected\n  # and a random infection happens\n  contacts == \"I\" & randomly_infect(N, beta), \n  true = \"I\", \n  false = sim_run[[i-1]]\n  ) # otherwise state stays the same\n}\nsim_output <- tibble( # create tibble for ggplot\n # Compute a vector with length tmax \n # with the count of \"I\" in sim_run list\n t = 0:(tmax-1), # times steps\n # count of infected, notice map_dbl\n infected = map_dbl(sim_run, \\(x) sum(x == \"I\"))) \nsim_output |> \n ggplot(aes(t,infected)) + geom_line() +\n theme_minimal(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\n## New programming concepts {.smaller}\n\nFrom base R:\n\n`runif` random numbers from uniform distribution  \n`sample` random sampling from a vector  \n`for` loop over commands with index (`i`) taking values of a vector (`2:tmax`) one by one\n`if_else` vectorized version of conditional statements\n\n\n# Calculus\n\nThe mathematics of the **change** and the **accumulation** of quantities\n\n## Motivation:  SI model with <br> population compartments {background-color=\"khaki\"}\n\nTwo compartments:   \n$S(t)$ is the number of susceptible people at time $t$.  \n$I(t)$ is the number of infected people at time $t$.  \n\nIt always holds $S(t) + I(t) = N$. (The total population is constant.)\n\n## How many infections per time? {.smaller background-color=\"khaki\"}\n\nThe **change** of the number of infectious\n\n$$\\frac{dI}{dt} = \\underbrace{\\beta}_\\text{infection prob.} \\cdot \\underbrace{\\frac{S}{N}}_\\text{frac. of $S$ still there} \\cdot \\underbrace{\\frac{I}{N}}_\\text{frac. $I$ to meet} \\cdot N = \\frac{\\beta\\cdot S\\cdot I}{N}$$\n\nwhere $dI$ is the *change* of $I$ (the newly infected here) and $dt$ the time interval. \n\n. . . \n\n**Interpretation:** The newly infected are from the fraction of susceptible *times* the probability that they meet an infected *times* the infection probability *times* the total number of individuals.   \n[Same logic as our Simulation in R!]{style='color:red;'}\n\n. . . \n\nUsing $S = N - I$ we rewrite\n\n$$\\frac{dI}{dt} = \\frac{\\beta (N-I)I}{N}$$\n\n\n## Ordinary differential equation {background-color=\"aquamarine\"}\n\nWe interpret $I(t)$ as a function of time which gives us the number of infectious at each point in time. The change function is now\n\n$$\\frac{dI(t)}{dt} = \\frac{\\beta (N-I(t))I(t)}{N}$$\n\nand $\\frac{dI(t)}{dt}$ is also called the **derivative** of $I(t)$. \n\n## Derivatives {.smaller  background-color=\"aquamarine\"}\n\n::: {.columns}\n\n::: {.column width='70%'}\n- The *derivative* of a function is also a function with the same domain. \n- Measures the sensitivity to change of the function output when the input changes (a bit)\n- Example from physics: The derivative of the *position* of a moving object is its *speed*. The derivative of its speed is its *acceleration.* \n- Graphically: The derivative is the *slope* of a *tangent line* of the graph of a function. \n:::\n\n::: {.column width='30%'}\n![](https://upload.wikimedia.org/wikipedia/commons/2/2d/Tangent_function_animation.gif)\n:::\n\n:::\n\n## Differentiation {.smaller  background-color=\"aquamarine\"}\n \nis the process to compute the derivative. For parameters $a$ and $b$ and other functions $g$ and $h$, rules of differentiation are\n\n:::{.columns}\n:::{.column width=\"30%\"}\nFunction $f(x)$\n::: \n:::{.column width='70%'}\nIts derivative $\\frac{df(x)}{dx}$ or  $\\frac{d}{dx}f(x)$ or $f'(x)$\n:::\n:::\n\n:::{.columns}\n:::{.column width=\"30%\"}\n$a\\cdot x$\n\n$b$\n\n$x^2,\\ x^{-1} = \\frac{1}{x},\\ x^k$\n\n$g(x) + h(x)$\n\n$g(x)\\cdot h(x)$\n\n$g(h(x))$\n\n$e^x,\\ 10^x  = e^{\\log(10)x}$\n\n$\\log(x)$\n::: \n:::{.column width='70%'}\n:::{.fragment fragment-index=1}\n$a$\n:::\n:::{.fragment fragment-index=2}\n$0$\n:::\n:::{.fragment fragment-index=3}\n$2\\cdot x,\\ -x^{-2} = -\\frac{1}{x^2},\\ k\\cdot x^{k-1}$\n:::\n:::{.fragment fragment-index=4}\n$g'(x) + h'(x)$\n:::\n:::{.fragment fragment-index=5}\n$g'(x)\\cdot h(x) + g(x)\\cdot h'(x)$ (product rule)\n:::\n:::{.fragment fragment-index=6}\n$g'(h(x))\\cdot h'(x)$ (chain rule)\n:::\n:::{.fragment fragment-index=7}\n$e^x,\\ 10^x = \\log(10)\\cdot10^x$\n:::\n:::{.fragment fragment-index=}\n$\\frac{1}{x}$ (A surprising relation to me at least)\n:::\n:::\n:::\n\n## Differential equation {.smaller  background-color=\"aquamarine\"}\n\nIn a differential equation the *unknown* is a function!\n\nWe are looking for a function which derivative is a function of the function itself. \n\n**Example: SI-model**\n\n$$\\frac{dI(t)}{dt} = \\frac{\\beta (N-I(t))I(t)}{N}$$\n\nWhich function $I(t)$ fulfills this equation?\n\nThe **analytical solution**^[Can you check that this is correct? Compute $I'(t)$ ($=\\frac{dI(t)}{dt}$) and check if $I'(t) = \\frac{\\beta (N-I(t))I(t)}{N}$. It is a bit of work, but try it! Let me know, if you want a solution.] \n\n$I(t) = \\frac{N}{1 + (\\frac{N}{I(0)} - 1)e^{-\\beta t}}$\n\nWhich is called the *logistic equation*. \nNote, we need to specify the initial number of infectious individuals $I(0)$. \n\n## SI-model: Logistic Equation {.smaller  background-color=\"khaki\"}\n\n$I(t) = \\frac{N}{1 + (\\frac{N}{I(0)} - 1)e^{-\\beta t}}$\n\nPlot the equation for $N = 10000$, $I_0 = 1$, and $\\beta = 0.3$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 10000\nI0 <- 1\nbeta <- 0.3\nggplot() + \n geom_function( fun = function(t) N / (1 + (N/I0 - 1)*exp(-beta*t)) ) + \n xlim(c(0,75))\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n## SI-model: Numerical integration {.smaller background-color=\"khaki\"}\n\nAnother way of solution is **numerical integration**, e.g. using *Euler's method*. \n\nWe compute the solution step-by-step using increments of, e.g. $dt = 1$.\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nN <- 10000\nI0 <- 1\ndI <- function(I,N,b) b*I*(N - I)/N\nbeta <- 0.3\ndt <- 1 # time increment, \n# supposed to be infinitesimally small\ntmax <- 75\nt <- seq(0,tmax,dt) \n# this is the vector of timesteps\nIt <- I0 # this will become the vector \n# of the number infected I(t) over time\nfor (i in 2:length(t)) { \n # We iterate over the vector of time steps \n # and incrementally compute It\n It[i] = It[i-1] + dt * dI(It[i-1], N, beta) \n # This is called Euler's method\n}\ntibble(t, It) |> ggplot(aes(t,It)) + \n geom_line(color = \"red\") + \n geom_function( \n  fun = function(t) N / (1 + (N/I0 - 1)*exp(-beta*t)), color = \"blue\") + \n # In blue: Analytical solution for comparison\n theme_minimal(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nWhy do the graphs deviate? [The step size $dt$ must be \"infinitely\" small]{.fragment}\n\n## Numerical integration with smaller $dt$ {.smaller background-color=\"khaki\"}\n\nWe compute the solution step-by-step using small increments of, e.g. $dt = 0.05$.\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nN <- 10000\nI0 <- 1\ndI <- function(I,N,b) b*I*(N - I)/N\nbeta <- 0.3\ndt <- 0.05 # time increment, \n# supposed to be infinitesimally small\ntmax <- 75\nt <- seq(0,tmax,dt) \n# this is the vector of timesteps\nIt <- I0 # this will become the vector \n# of the number infected I(t) over time\nfor (i in 2:length(t)) { \n # We iterate over the vector of time steps \n # and incrementally compute It\n It[i] = It[i-1] + dt * dI(It[i-1], N, beta) \n # This is called Euler's method\n}\ntibble(t, It) |> ggplot(aes(t,It)) + \n geom_line(color = \"red\") +\n geom_function( \n  fun = function(t) N / (1 + (N/I0 - 1)*exp(-beta*t)), color = \"blue\") + \n # In blue: Analytical solution for comparison\n theme_minimal(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n## Mechanistic model {.smaller background-color=\"khaki\"}\n\nThe SI model is a potential answer to the **mechanistic question** *How do epidemics spread?*\n\nThe examples above show 3 different ways to explore the model:\n\n- *Agent-based simulation*\n  - We model every individual explicitly\n  - Simulation involve random numbers! So simulation runs can be different!\n\n. . .\n\n- *Numerical integration* of differential equation\n  - Needs a more abstract concept of *compartments*\n\n. . . \n\n- *Analytical solutions* of differential equation\n  - often not possible (therefore numerical integration is common)\n\n\n## Differentiation with data {.smaller}\n\n[**We can do calculus operations with data!**]{style='color:red;'}\n\nIn empirical data we can compute the increase in a vector with the function `diff`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(1,2,4,5,5,3,0)\ndiff(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1  2  1  0 -2 -3\n```\n\n\n:::\n:::\n\n\n. . . \n\nMore convenient in a data frame is to use `x - lag(x)` because the vector has the same length.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx - lag(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] NA  1  2  1  0 -2 -3\n```\n\n\n:::\n:::\n\n\n\n## The diff of our simulation output {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng1 <- sim_output |> ggplot(aes(x = t)) + geom_line(aes(y = infected))\ng1\n```\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n\n```{.r .cell-code}\ng2 <- sim_output |> \n mutate(derivative_infected = infected - lag(infected)) |> \n ggplot(aes(x = t)) + geom_line(aes(y = derivative_infected))\ng2\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-27-2.png){width=672}\n:::\n:::\n\n\n## 2nd derivative: Change of change \n\n\n::: {.cell}\n\n```{.r .cell-code}\ng3 <- sim_output |> \n mutate(derivative_infected = infected - lag(infected),\n        derivative2_infected = derivative_infected - lag(derivative_infected)) |> \n ggplot(aes(x = t)) + geom_line(aes(y = derivative2_infected))\ng3\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\nIn empirical data: Derivatives of higher order tend to show fluctuation\n\n\n## Interpretation in SI-model {.smaller  background-color=\"khaki\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\ng1 + g2 + g3\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W06_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n- $I(t)$ total number of infected\n- $I'(t)$ number of new cases per day (time step)\n- $I''(t)$ how the number of new cases has changes compared to yesterday\n  - [2nd derivatives are a good early indicator for the end of a wave.]{style='color:red;'}\n\n## Integration {.smaller background-color=\"aquamarine\"}\n\nThe **integral** of the daily new cases from the beginning to day $s$ is $\\int_{-\\infty}^s f(t)dt$ and represents the total cases at day $s$. \n\n- The integral of a function $f$ up to time $s$ is also called the **anti-derivative** $F(s) = \\int_{-\\infty}^s f(t)dt$.\n    - The symbol $\\int$ comes from an S and means \"sum\".\n- Compute the anti-derivative of data vector with `cumsum`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(1,2,4,5,5,3,0)\ncumsum(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1  3  7 12 17 20 20\n```\n\n\n:::\n:::\n\n\n- Empirically: Derivatives tend to become noisy, while integrals tend to become smooth.   \n\n\n## The fundamental theorem of calculus {.smaller background-color=\"aquamarine\"}\n\n**The integral of the derivative is the function itself.**\n\n\nThis is not a proof but shows the idea:\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- c(1,2,4,5,5,3,0)\nantiderivative <- cumsum(f)\nantiderivative\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1  3  7 12 17 20 20\n```\n\n\n:::\n\n```{.r .cell-code}\ndiff(c(0, antiderivative)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 4 5 5 3 0\n```\n\n\n:::\n\n```{.r .cell-code}\n# We have to put 0 before to regain the full vector\nderivative <- diff(f)\nderivative\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1  2  1  0 -2 -3\n```\n\n\n:::\n\n```{.r .cell-code}\ncumsum(c(1,derivative)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 4 5 5 3 0\n```\n\n\n:::\n\n```{.r .cell-code}\n# We have to put in the first value (here 1) \n# manually because it was lost during the diff\n```\n:::\n\n",
    "supporting": [
      "W06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}