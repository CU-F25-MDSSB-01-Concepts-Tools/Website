{
  "hash": "e314496b50ff4e5733acc9f817cc23d9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"W#13: Random Variables, Probability Distributions, Central Limit Theorem\"\nauthor: Jan Lorenz\nformat: \n  revealjs: \n    toc: true\n    toc-depth: 1\n    slide-number: true\n    chalkboard: \n      buttons: true\n    preview-links: true\n    logo: img/ConstructorUniversity.png\n    footer: \"MDSSB-DSCO-02: Data Science Concepts\"\nbibliography: \"/home/janlo/Documents/literature/litlorenz_zot.bib\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n# Random variables { background-color=\"aquamarine\"}\n\n## How to think about random variables {.smaller  background-color=\"aquamarine\"}\n\nIn [**statistics**]{style='color:blue;'} (that means, in **data**):   \nA theoretical assumption about a *numerical variable* in a data frame.\n\n. . .\n\nIn [**probability**]{style='color:blue;'} (that means, in **theory**):   \nA mapping of events (subsets of a sample space of atomic events) to *numerical values*. \n\n. . . \n\n[**Why?**]{style='color:blue;'}  \nFor random variables we can:   \n\n- Conceptualize meaningful values to random events like payoffs, costs, or grades\n- Compute probabilities of these numerical values\n- Compute the *expected value* of a numerical variable\n- Theorize about their distribution and their distribution and density functions (e.g. binomial, normal, lognormal, etc.)\n\n## Random variable mathematically {.smaller background-color=\"aquamarine\"}\n\nA [**random variable**]{style='color:blue;'} is\n\n- a function $X: S \\to \\mathbb{R}$ from a sample space $S$ to the real numbers $\\mathbb{R}$, \n- which assigns a value to each atomic event in the sample space. \n\nTogether with a probability function $\\text{Pr}: \\mathcal{F}(S)\\to [0,1]$ probabilities can be assigned to values of the random variable (see the *probability mass function* in explained later).\n\n::: aside\n**Fun fact:** The *random variable* is neither *random* nor a *variable* but a function. \n:::\n\n## Examples of random variables {.smaller  background-color=\"aquamarine\"}\n\n3 random processes spaces and an example of a random variable $X$:\n\n**Two coin tosses:**  \nSample space: $\\{HH, HT, TH, TT\\}$   \nWe define $X$ as the **number of HEADS**.   \nValues of $X$: $HH \\to 2$, $HT \\to 1$, $TH \\to 1$, and $TT \\to 0$.\n\n. . .\n\n**62 randomly selected organ donations:**  \nSample space: All possibilities to select 62 organ donations    \nWe define $X$ to be **the number of complications** (compare Hypothesis Testing material).   \nValues of $X$: 0, 1, 2,..., 61, 62\n\n. . .\n\n**Select a random palmer penguin:**     \nWe define $X$ as its flipper length.    \nSample space: All penguins in dataset   \nValues of $X$: `flipper_length_mm`\n\n. . . \n\n**Summary:** A random variable is a way to look at a numerical aspect of a sample space. It often *simplfies* because more atomic events may be mapped to the same number.\n\n## Discrete vs. continuous  {.smaller  background-color=\"aquamarine\"}\n\nA random variable $X$ can be either\n\n[**Discrete**]{style='color:blue;'}: $X$ can take only a finite number of possible numeric values. Or:\n\n[**Continuous**]{style='color:blue;'}: $X$ can take values from an infinite set of real numbers (for example an interval or all positive real numbers)\n\n. . . \n\n**Are these random variables discrete or continuous?**\n\n1. Number of HEADs of two coin tosses: [**Discrete**]{.fragment}\n2. Number of complications in 62 organ donations: [**Discrete**]{.fragment}\n3. Flipper length of a random row in palmer penguins data frame: [**Discrete**]{.fragment}\n4. Flipper length of a random penguin in the world: [**Continuous**]{.fragment}\n\n. . . \n\n[**For working with data:**]{style='color:blue;'} Every data frame is finite, so every random variable built on data variable dataset is technically discrete. However, it can make sense to assume it as continuous because of its *continuous nature*. (In variables of continuous nature, many or all values are unique.)\n\n\n## Probability mass function (pmf) {.smaller  background-color=\"aquamarine\"}\n\nFor \n\n- a *discrete random variable* $X$ and \n- a *probability function* $\\text{Pr}$ \n\nthe [**probability mass function**]{style='color:blue;'} $f_X: \\mathbb{R} \\to [0,1]$ is defined as\n\n$$f_X(x) = \\text{Pr}(X=x),$$ \n\nwhere $\\text{Pr}(X=x)$ is an abbreviation for $\\text{Pr}(\\{a\\in S\\text{ for which } X(a) = x\\})$. \n\n## Example pmf for 2 coin tosses {.smaller  background-color=\"aquamarine\"}\n\nTwo coin tosses $S = \\{HH, HT, TH, TT\\}$   \n\n  - We define $X$ to be the number of heads:   \n  $X(HH) = 2$, $X(TH) = 1$, $X(HT) = 1$, and $X(TT) = 0$.   \n  - We assume the probability function $\\text{Pr}$ assigns for each atomic event a probability of 0.25. \n  - Then the probability mass function is\n$$\\begin{align} f_X(0) = & \\text{Pr}(X=0) = \\text{Pr}(\\{TT\\}) & = 0.25 \\\\ \nf_X(1) = & \\text{Pr}(X=1) = \\text{Pr}(\\{HT,TH\\}) & = 0.25 + 0.25 = 0.5 \\\\\nf_X(2) = &\\text{Pr}(X=2) = \\text{Pr}(\\{HH\\}) & = 0.25\\end{align}$$\n  - Note that  $\\text{Pr}(\\{HT,TH\\}) = \\text{Pr}(\\{HT\\}) + \\text{Pr}(\\{HT\\})$ by adding the probabilities of the atomic events. \n  - For all $x$ which are not 0, 1, or 2: Obviously, $f_X(x) = 0$.\n\n<!-- In a data frame `D` with $m$ cases, we can consider a variable `\"varname\"` (of type numeric) as a random variable with -->\n<!-- $X: \\{1,2,\\dots,m\\} \\to \\mathbb{R}$ and $X(i) =$`D[i,\"varname\"]`.   -->\n\n<!-- Let us consider for that data frame that $X$ is the height of $m$ people measured very precisely. Then, the probability of a certain height, e.g. 1.6782, is $\\text{Pr}(X=1.6782) = \\frac{1}{m}$ as for any other height. This is not very interesting. More interesting is the probability that the height is between 1.6 and 1.7. Of course, these values can be computed for a data frame. Mathematically, we like to have a formal treatment for such continuous random variables. To that end, we will generalize the probability mass function to a *probability density function* later.  -->\n\n## Example: Roll two dice ðŸŽ² ðŸŽ²{.smaller  background-color=\"aquamarine\"}\n\n**Random variable:** The sum of both dice. \n\n. . .\n\n**Events:** All 36 combinations of rolls 1+1, 1+2, 1+3, 1+4, 1+5, 1+6, 2+1, 2+2, 2+3, 2+4, 2+5, 2+6, 3+1, 3+2, 3+3, 3+4, 3+5, 3+6, 4+1, 4+2, 4+3, 4+4, 4+5, 4+6, 5+1, 5+2, 5+3, 5+4, 5+5, 5+6, 6+1, 6+2, 6+3, 6+4, 6+5, 6+6     \n\n. . . \n\n**Possible values of the random variable: **\n2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 (These are numbers.)\n\n. . .\n\n**Probability mass function:**\n(Assuming each number has probability of $\\frac{1}{6}$ for each die.)\n\n:::: {.columns}\n\n::: {.column width='40%'}\n$\\text{Pr}(2) = \\text{Pr}(12) = \\frac{1}{36}$  \n$\\text{Pr}(3) = \\text{Pr}(11) = \\frac{2}{36}$  \n$\\text{Pr}(4) = \\text{Pr}(10) = \\frac{3}{36}$  \n$\\text{Pr}(5) = \\text{Pr}(9) = \\frac{4}{36}$  \n$\\text{Pr}(6) = \\text{Pr}(8) = \\frac{5}{36}$  \n$\\text{Pr}(7) = \\frac{6}{36}$  \n:::\n\n::: {.column width='60%'}\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(Value = 0:15, \n       pmf=c(0,0,1,2,3,4,5,6,5,4,3,2,1,0,0,0)/36) |> \n ggplot(aes(Value,pmf)) + geom_line() + geom_point() +\n theme_minimal(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::::\n\n## Expected value {.smaller  background-color=\"aquamarine\"}\n\n- For a discrete random variable $X$, there is only a finite set of number $X$ can take:  $\\{x_1,\\dots,x_k\\}$.   \n- So, the probability mass function has maximally $k$ positive probabilities: $p_1,\\dots,p_k$\n- Recall $p_i = f_X(x_i) = \\text{Pr}(X=x_i) = \\text{Pr}(\\{a \\in S \\text{ for which } X(a) = x_i \\})$.   \n\nThe [**expected value**]{style='color:blue;'} of $X$ is defined as $E(X) = \\sum_{i=1}^k p_i x_i = p_1x_1 + \\dots + p_kx_k.$\n\n*Think of $E(X)$ as the probability weighted arithmetic mean of all possible values of $X$.*\n\n. . . \n\n**Examples:** $X$ one roll of a die ðŸŽ².    \n[$E(X) = 1\\cdot\\frac{1}{6} + 2\\cdot\\frac{1}{6} + 3\\cdot\\frac{1}{6} + 4\\cdot\\frac{1}{6} + 5\\cdot\\frac{1}{6} + 6\\cdot\\frac{1}{6} = \\frac{21}{6} = 3.5$]{.fragment}    \n\n$X$ sum of two die rolls ðŸŽ²ðŸŽ².    \n[$E(X) = 2\\cdot\\frac{1}{36} + 3\\cdot\\frac{2}{36} + 4\\cdot\\frac{3}{36} + 5\\cdot\\frac{4}{36} + \\dots + 10\\cdot\\frac{3}{36} + 11\\cdot\\frac{2}{36} + 12\\cdot\\frac{1}{36} = 7$]{.fragment}\n\n$X$ flipper length in `penguins` from Palmer penguins: [$E(X) = 200.9152047$  \n`mean(penguins$flipper_length_mm, na.rm = TRUE)`]{.fragment}\n\n\n## Distributions of Random Variables {.smaller  background-color=\"aquamarine\"}\n\n- The **distribution** of a random variable $X$ is a *table*, *graph*, or *formula* that gives the probabilities of all its possible values.\n\nType of Random Variable | Table | Graph | Formula |\n---:|:---:|:---:|:---:|\nDiscrete | &check; | &check; | &check; |\nContinuous | &cross; | &check; | &check; |\n\n- The **probability mass function** $f_X$ defines the distribution of a random variable $X$ that is discrete.\n\n- The **probability density function** $f_X$ defines the distribution of a random variable $X$ that is continuous. (Details later)\n\n- For a column in a data frame the distribution is typically visualized by \n    - a bar plot of counts or frequencies for discrete variables\n    - a histogram for continuous variables (note, depending on the binwidth this gives a more or less detailed impression of the distribution)\n \n## Examples of data distributions {.smaller  background-color=\"aquamarine\"}\n\n:::: {.columns}\n\n::: {.column width='33%'}\n**Discrete**\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n ggplot(aes(island)) + \n geom_bar() + \n theme_minimal(base_size = 30)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nTechnically `island` is cannot be interpreted as a random variable because its values are not numbers, but we also speak about the *distribution* of the variables.\n:::\n\n::: {.column width='33%'}\n::: {.fragment}\n**Continuous** in nature   \n(technically still discrete)\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n ggplot(aes(flipper_length_mm)) + \n geom_histogram() + theme_minimal(base_size = 30)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nLarger bin width\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n ggplot(aes(flipper_length_mm)) + \n geom_histogram(binwidth = 10) + theme_minimal(base_size = 30)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n:::\n:::\n\n::: {.column width='33%'}\n::: {.fragment}\nSmallest bin width\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n ggplot(aes(flipper_length_mm)) + \n geom_histogram(binwidth = 1) + theme_minimal(base_size = 20)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n**Density** plot\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n ggplot(aes(flipper_length_mm)) + \n geom_density() + theme_minimal(base_size = 30)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n:::\n:::\n\n::::\n\n## Density plot {.smaller  background-color=\"aquamarine\"}\n\n- The density plot is a smoothed version of the histogram.\n- Each data point is replaced by a *kernel* (e.g. a normal distribution, see later) and the sum of all kernels is plotted.\n\n:::: {.columns}\n\n::: {.column width='33%'}\nWith automatic bandwidth (`bw`)\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n ggplot(aes(flipper_length_mm)) + \n geom_density() + \n theme_minimal(base_size = 30)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n:::\n::: {.column width='33%'}\n::: {.fragment}\n`bw = 0.5` means kernel has standard deviation 0.5\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n ggplot(aes(flipper_length_mm)) + \n geom_density(bw = 0.5) + \n theme_minimal(base_size = 30)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n:::\n:::\n\n::: {.column width='33%'}\n::: {.fragment}\nFor demonstration:   \n2 penguins only   \n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> slice(1:2) |> \n ggplot(aes(flipper_length_mm)) + \n geom_density(bw = 0.5) + xlim(c(170,230)) + \n theme_minimal(base_size = 30)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\nSee the two kernels\n:::\n:::\n\n::::\n\n\n# Binomial distribution { background-color=\"aquamarine\"}\n\nA first example for a theoretical random variable. \n\n## Binomial distribution {.smaller  background-color=\"aquamarine\"}\n\nThe *number of HEADS in several coin tosses* and the *number of complications in randomly selected organ donations* are examples of random variable which have a *binomial distribution*. \n\n. . .\n\n**Definition:**   \nThe [**binomial distribution**]{style='color:blue;'} \nwith *parameters* $n$ and $p$ is   \nthe *number of successes* in a sequence of $n$ independent *Bernoulli trials*    \nwhich each delivers a *success* with probability $p$ and a *failure* with probability $(1-p)$. \n\n<!-- - The default model for the number of successes drawn from a sample of size $n$ drawn from a population of size $N$ with replacement.  -->\n<!-- - When $N$ is much larger than $n$ it is also a good approximation for drawing without replacement.  -->\n\n\n## Binomial probability mass function {.smaller  background-color=\"aquamarine\"}\n\n$$f(k,n,p) = \\Pr(k;n,p) = \\Pr(X = k) = \\binom{n}{k}p^k(1-p)^{n-k}$$\n\nwhere $k$ is the number of successes, $n$ is the number of Bernoulli trials, and $p$ the success probability. \n\nProbability to have *exactly* 3 complications in 62 randomly selected organ donations with complication probability $p=0.1$ is\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# x represents k, and size represents n\ndbinom(x = 3, size = 62, prob = 0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.07551437\n```\n\n\n:::\n:::\n\n\nThe probability to have 3 complications *or less* can be computed as\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(3, 62, 0.1) + dbinom(2, 62, 0.1) + dbinom(1, 62, 0.1) + dbinom(0, 62, 0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1209787\n```\n\n\n:::\n:::\n\n\n. . . \n\n[This was the p-value we computed with simulation for the hypothesis testing example.]{style='color:blue;'} \n\n\n## Expected value binomial distribution {.smaller background-color=\"aquamarine\"}\n\nFor $X \\sim \\text{Binom}(n,p)$ (read \"$X$ has a binomial distribution with samplesize $n$ and success probability $p$\")\n\nThe expected value of $X$ is by definition\n\n$$E(X) = \\underbrace{\\sum_{k = 0}^n k}_{\\text{sum over successes}} \\cdot \\underbrace{\\binom{n}{k}p^k(1-p)^{n-k}}_{\\text{probability of successes}}$$\n\nComputation shows that $E(X) = p\\cdot n$.\n\n**Example:** For $n = 62$ organ donations with complication probability $p=0.1$, the expected number of complications is $E(X) = 6.2$. \n\n\n## Distribution functions are vectorized! {.smaller  background-color=\"aquamarine\"}\n\nCompute the p-value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(0:3, 62, 0.1) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.001455578 0.010027317 0.033981465 0.075514366\n```\n\n\n:::\n\n```{.r .cell-code}\ndbinom(0:3, 62, 0.1) |> sum()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1209787\n```\n\n\n:::\n:::\n\n\nPlotting the probability mass function\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ntibble(k = 0:62) |> \n mutate(probability = dbinom(k, \n                             size = 62, \n                             prob = 0.1)) |> \n ggplot(aes(k, probability)) + \n geom_col() + \n theme_minimal(base_size = 24) + \n scale_x_continuous(breaks = seq(0, 62, 5))\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nSee that the highest probability is achieved for $k=6$ which is close to the expected value of successes $E(X) = 6.2$ for $X \\sim \\text{Binom}(62,0.1)$.\n\n\n## Other plots of binomial mass function {.smaller  background-color=\"aquamarine\"}\n\nChanging the sample size $n$ when the success probability $p = 0.1$ and the number of successes $k=3$ is fixed:\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ntibble(samplesize = 0:62) |> \n mutate(probability = dbinom(3, \n                             size = samplesize, \n                             prob = 0.1)) |> \n ggplot(aes(samplesize, probability)) + \n geom_col() + \n theme_minimal(base_size = 24) +\n scale_x_continuous(breaks = seq(0, 62, 5))\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n[The probability of 3 successes is most likely for sample sizes around 30. Does is make sense?]{style='color:blue;'}\n\n. . . \n\nYes, because for $n=30$ the expected value for probability $p=0.1$ is $3 = pn = 0.1\\cdot 30$.\n\n## Other plots of binomial mass function {.smaller  background-color=\"aquamarine\"}\n\nChanging the sample size $p$ when the sample size $n = 62$ and the number of successes $k=3$ is fixed:\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ntibble(probs = seq(0,0.3,0.001)) |> \n mutate(probability = dbinom(3, \n                             size = 62, \n                             prob = probs)) |> \n ggplot(aes(probs, probability)) + \n geom_line() +\n scale_x_continuous(breaks = seq(0,0.3,0.05)) + \n theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n[The probability of 3 successes in 62 draws is most likely for success probabilities around 0.05.]{style='color:blue;'}\n\n. . .\n\nFor $p=0.05$ the expected value for $n=62$ is $pn = 0.05\\cdot 62 = 3.1$.\n\n\n# Distribution Functions\n\n## General systematic of functions for distributions in R {.smaller}\n\nIn R we usually have 4 function for each distribution: The `d`, `p`, `q`, and `r` version. For the binomial distribution: \n\n- `dbinom` the density function (more on the name later)\n\n- `pbinom` distribution function \n\n- `qbinom` the quantile function, and \n\n- `rbinom` random number generator.\n\n\n## Probability mass function `d`... {.smaller}\n\n- The **mass function** (or *density function*, more on this later) `dbinom`\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nk <- 0:10\ntibble(k, \n       probability = dbinom(k, \n                            size = 10, \n                            prob = 0.5)) |> \n ggplot(aes(k, probability)) + geom_col() + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n[Gives the probability for the number $x$: $\\text{Pr}(X = x)$ or $f_X(x)$.]{style='color:blue;'}\n\n\n## Distribution function `p`... {.smaller}\n\n- The **distribution function**, or cumulative probability function `pbinom`\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nk <- 0:10\ntibble(k, \n       probability = pbinom(k, \n                            size = 10, \n                            prob = 0.5))  |> \n ggplot(aes(k, probability)) + \n geom_col() + \n theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n[Gives the probability that the random variable is less or equal to $x$:  \n$\\text{Pr}(X \\leq x)$.]{style='color:blue;'}\n\n\n## Quantile function `q`... {.smaller}\n\n- The **quantile function**, `qbinom` with argument $p$ representing the fraction of lowest values of $X$ among all values for which we want the $k$ value for. \n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nprobs <- seq(0, 1, by = 0.01)\ntibble(p = probs) |> \n mutate(k = qbinom(p, size = 10, prob = 0.5)) |> \n ggplot(aes(p, k)) + \n geom_line() + \n scale_y_continuous(breaks = seq(0, 10, 2)) +\n theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n[A point $(p,k)$ means: When we want a $p$-fraction of the probability mass, we need all events with values lower or equal to $k$.]{style='color:blue;'}\n\n\n\n## Calculus relations {.smaller}\n\n- Quantile, distribution and mass function all carry the *full information* about the distribution of a random variable $X$. \n\n- The *mass function* is the **derivative** of the *distribution function*.   \n(The *distribution function* is the anti-derivative of the *mass function*.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(0:5, size = 5, prob = 0.5) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03125 0.18750 0.50000 0.81250 0.96875 1.00000\n```\n\n\n:::\n\n```{.r .cell-code}\n# Next comes its derivative (have to append a 0 before first)\npbinom(0:5, size = 5, prob = 0.5) |> append(0, after = 0) |> diff()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03125 0.15625 0.31250 0.31250 0.15625 0.03125\n```\n\n\n:::\n\n```{.r .cell-code}\ndbinom(0:5, size = 5, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03125 0.15625 0.31250 0.31250 0.15625 0.03125\n```\n\n\n:::\n\n```{.r .cell-code}\n# Next comes its anti-derivative\ndbinom(0:5, size = 5, prob = 0.5) |> cumsum()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03125 0.18750 0.50000 0.81250 0.96875 1.00000\n```\n\n\n:::\n:::\n\n\n\n## More calculus relations {.smaller}\n\n- The quantile function is the inverse of the distribution function.\n- We plot the inverse function by interchanging the `x` and `y` aesthetic.\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nprobs <- seq(0, 1, by = 0.01)\nk <- 0:10\nq <- tibble(p = probs) |> mutate(k = qbinom(p, size = 10, prob = 0.5)) \np <- tibble(k) |> mutate(p = pbinom(k, size = 10, prob = 0.5)) \nq_plot <- q |> ggplot(aes(p, k)) + geom_line() + theme_minimal(base_size = 24) + scale_y_continuous(breaks = seq(0, 10, 2)) + ggtitle(\"qbinom\")\nqinv_plot <- q |> ggplot(aes(k, p)) + geom_line() + theme_minimal(base_size = 24) + scale_x_continuous(breaks = seq(0, 10, 2)) + ggtitle(\"qbinom inverse\")\np_plot <- p |> ggplot(aes(k, p)) + geom_col() + theme_minimal(base_size = 24) + scale_x_continuous(breaks = seq(0, 10, 2)) + ggtitle(\"pbinom\")\npinv_plot <- p |> ggplot(aes(p, k)) + geom_col(orientation = \"y\") + theme_minimal(base_size = 24) + scale_y_continuous(breaks = seq(0, 10, 2)) + ggtitle(\"pbinom inverse\")\nlibrary(patchwork)\n(q_plot | p_plot) / (pinv_plot | qinv_plot)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n## Random number generator `r`... {.smaller}\n\n- Random binomial numbers are drawn with `rbinom`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 10 random binomial numbers for 62 trials with success probability 0.1\nrbinom(10, size = 62, prob = 0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  5  3  6  2  3 10  7  7  6  7\n```\n\n\n:::\n:::\n\n\n- We can reproduce the null distribution from hypothesis testing with 62 organ donations and 10% complication probability this way.\n  - We produce 100,000 random consultants\n  - Then we compute the fraction of  which have 3 or less complications\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2022)\ns <- rbinom(100000, size = 62, prob = 0.1)\nsum(s<=3)/100000\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.12038\n```\n\n\n:::\n\n```{.r .cell-code}\n# Two other samples\nsum(rbinom(100000, size = 62, prob = 0.1)<=3)/100000\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.11918\n```\n\n\n:::\n\n```{.r .cell-code}\nsum(rbinom(100000, size = 62, prob = 0.1)<=3)/100000\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.12034\n```\n\n\n:::\n:::\n\n\n## Empirical distributions {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ness_raw <- read_csv(\"data/ESS-Data-Wizard-subset-2022-09-17.csv\",\n                col_types = cols(\n                 name = col_character(),\n                 essround = col_double(),\n                 edition = col_double(),\n                 proddate = col_character(),\n                 idno = col_double(),\n                 cntry = col_character(),\n                 dweight = col_double(),\n                 pspwght = col_double(),\n                 pweight = col_double(),\n                 euftf = col_double(),\n                 gincdif = col_double(),\n                 lrscale = col_double(),\n                 polintr = col_double(),\n                 stflife = col_double(),\n                 trstplc = col_double(),\n                 vote = col_double(),\n                 imueclt = col_double(),\n                 atchctr = col_double(),\n                 atcherp = col_double(),\n                 crmvct = col_double(),\n                 pray = col_double(),\n                 rlgdgr = col_double(),\n                 gndr = col_double(),\n                 age = col_double()\n                ))\ness <- ess_raw |> filter(essround == 9) |>\n mutate(atchctr = atchctr |> na_if(77) |> na_if(88) |> na_if(99),\n        atcherp = atcherp |> na_if(77) |> na_if(88) |> na_if(99),\n        euftf = euftf |> na_if(77) |> na_if(88) |> na_if(99),\n        lrscale = lrscale |> na_if(77) |> na_if(88) |> na_if(99),\n        imueclt = imueclt |> na_if(77) |> na_if(88) |> na_if(99))\n```\n:::\n\n\n- $X$: select a random person from Europe (in 2018, willing to answer survey) and ask its attitude towards the European union from 0 to 10\n\n\n:::: {.columns}\n\n::: {.column width='40%'}\n- What is the distribution of the answer?\n\n\n::: {.cell}\n\n```{.r .cell-code}\neu <- ess |> select(euftf) |> drop_na() |> \n count(euftf) |> mutate(prob = n/sum(n)) \neu\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 Ã— 3\n   euftf     n   prob\n   <dbl> <int>  <dbl>\n 1     0  3361 0.0736\n 2     1  1787 0.0391\n 3     2  2830 0.0620\n 4     3  3586 0.0786\n 5     4  3739 0.0819\n 6     5 10286 0.225 \n 7     6  4589 0.101 \n 8     7  5165 0.113 \n 9     8  4692 0.103 \n10     9  1786 0.0391\n11    10  3826 0.0838\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width='60%'}\nMass function and distribution function\n\n::: {.cell}\n\n```{.r .cell-code}\neu_mass <- eu |> ggplot(aes(euftf, prob)) + geom_col() + theme_minimal(base_size = 24) + scale_x_continuous(breaks = seq(0, 10, 2))\neu_distr <- eu |> mutate(cumprob = cumsum(prob)) |> \n ggplot(aes(euftf, cumprob)) + geom_col() + theme_minimal(base_size = 24) + scale_x_continuous(breaks = seq(0, 10, 2))\neu_mass | eu_distr\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::::\n\n\n##  Theoretical examples {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(readxl)\ngalton <- read_csv(\"data/galton.csv\") |> mutate(true_value = 1198)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 787 Columns: 2\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\ndbl (2): Estimate, id\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nviertelfest <- read_csv(\"data/Viertelfest.csv\") |> mutate(true_value = 10788)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 1226 Columns: 3\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Date Time\ndbl (2): Losnummer, SchÃ¤tzung\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nowid <- read_csv(\"data/owid-covid-data.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 224711 Columns: 67\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr   (4): iso_code, continent, location, tests_units\ndbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\ndate  (1): date\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nowid_inds <- owid |> \n # Filter for one day and remove rows where continent is NA\n # These are rows with data for continents or world regions\n filter(date == \"2022-10-01\", !is.na(continent)) |> \n # These are the \"Other\" variables\n select(iso_code, continent, location, \n        population:human_development_index) |>\n # We remove the ones with many NA's\n select(-handwashing_facilities, -male_smokers, \n        - female_smokers, -extreme_poverty) |> \n drop_na()\ness_raw <- read_csv(\"data/ESS-Data-Wizard-subset-2022-09-17.csv\",\n                col_types = cols(\n                 name = col_character(),\n                 essround = col_double(),\n                 edition = col_double(),\n                 proddate = col_character(),\n                 idno = col_double(),\n                 cntry = col_character(),\n                 dweight = col_double(),\n                 pspwght = col_double(),\n                 pweight = col_double(),\n                 euftf = col_double(),\n                 gincdif = col_double(),\n                 lrscale = col_double(),\n                 polintr = col_double(),\n                 stflife = col_double(),\n                 trstplc = col_double(),\n                 vote = col_double(),\n                 imueclt = col_double(),\n                 atchctr = col_double(),\n                 atcherp = col_double(),\n                 crmvct = col_double(),\n                 pray = col_double(),\n                 rlgdgr = col_double(),\n                 gndr = col_double(),\n                 age = col_double()\n                ))\ness <- ess_raw |> filter(essround == 9) |>\n mutate(atchctr = atchctr |> na_if(77) |> na_if(88) |> na_if(99),\n        atcherp = atcherp |> na_if(77) |> na_if(88) |> na_if(99),\n        euftf = euftf |> na_if(77) |> na_if(88) |> na_if(99),\n        lrscale = lrscale |> na_if(77) |> na_if(88) |> na_if(99),\n        imueclt = imueclt |> na_if(77) |> na_if(88) |> na_if(99))\n```\n:::\n\n\n\n:::: {.columns}\n\n::: {.column width='48%'}\n**Discrete random variable**\n\n*Atomic event:* 20 (unfair) coin flips with HEADS probability 40%.   \n*Random Variable:* Number of HEADS. \n\n[**Binomial** distribution function]{style='color:blue;'}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n geom_function(fun = pbinom, args = list(size = 20, prob = 0.4)) + \n xlim(c(0,20)) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n\n:::\n\n::: {.column width='48%'}\n**Continuous random variable**\n\n*Atomic event:* Point on a ruler of 1 meter length. Each point is equally likely.   \n*Random Variable:* The marking on the ruler in meters (number from 0 to 1). \n\n[*Uniform* distribution function]{style='color:blue;'}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n geom_function(fun = punif) + \n xlim(c(-0.5,1.5)) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n:::\n\n::::\n\nInterpret a point of these graphs: $y$-value is the probability of the event $X \\leq x$.\n\n\n\n\n## Theoretical examples {.smaller}\n\nCorresponding mass functions:\n\n:::: {.columns}\n\n::: {.column width='48%'}\n**Discrete random variable**\n\n*Atomic event:* 20 (unfair) coin flips with HEADS probability 40%.   \n*Random Variable:* Number of HEADS. \n\n[**Binomial** density function]{style='color:blue;'}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n geom_function(fun = dbinom, args = list(size = 20, prob = 0.4)) + \n xlim(c(0,20)) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 0.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 0.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 0.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 0.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 1.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 1.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 1.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 1.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 2.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 2.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 2.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 2.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 3.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 3.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 3.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 3.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 4.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 4.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 4.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 4.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 5.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 5.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 5.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 5.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 6.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 6.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 6.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 6.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 7.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 7.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 7.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 7.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 8.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 8.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 8.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 8.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 9.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 9.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 9.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 9.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 10.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 10.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 10.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 10.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 11.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 11.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 11.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 11.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 12.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 12.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 12.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 12.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 13.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 13.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 13.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 13.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 14.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 14.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 14.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 14.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 15.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 15.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 15.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 15.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 16.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 16.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 16.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 16.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 17.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 17.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 17.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 17.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 18.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 18.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 18.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 18.800000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 19.200000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 19.400000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 19.600000\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fun(x_trans, size = 20, prob = 0.4): non-integer x = 19.800000\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width='48%'}\n**Continuous random variable**\n\n*Atomic event:* Point on a ruler of 1 meter length. Each point is equally likely.   \n*Random Variable:* The marking on the ruler in meters (number from 0 to 1). \n\n[*Uniform* density function]{style='color:blue;'}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n geom_function(fun = dunif) + \n xlim(c(-0.5,1.5)) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n:::\n\n::::\n\nNote: A more formal treatment of density functions on later slides!\n\n\n## Empirical examples {.smaller}\n\n\n:::: {.columns}\n\n::: {.column width='48%'}\n**Discrete random variable**\n\n*Atomic event:* Ask a European about attitude towards the EU.  \n*Random Variable:* The answer on the scale 0 to 10. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ness |> count(euftf) |> drop_na() |> mutate(freq = n/sum(n)) |>\n add_row(euftf = -4, freq = 0, .before = TRUE) |> add_row(euftf = 14, freq = 0) |> \n ggplot(aes(euftf,cumsum(freq))) + geom_step() + \n scale_x_continuous(breaks = 0:10) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width='48%'}\n**Continuous random variable**\n\n*Atomic event:* A visitors estimates the weight of the meat of an ox.   \n*Random Variable:* The estimated value converted to pounds. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ngalton |> mutate(freq = 1/n()) |>  \n add_row(Estimate = 800, freq = 0, .before = TRUE) |> add_row(Estimate = 1600, freq = 0) |>\n ggplot(aes(Estimate, cumsum(freq))) + geom_step() +\n theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n:::\n\n::::\n\n\n## Distributions based on empirical data {.smaller}\n\n[Empirical data is always finite, so why bother with theoretical continuous distributions?]{style='color:blue;'}\n\n. . .\n\n- Each new data point would usually create a new discrete value. \n- A discrete view is conceptually (theoretically) unfavorable. \n- We assume that there is a continuous distribution underlying. \n\n\n## Probability mass function (pmf) {.smaller}\n\nFor discrete random variables the *probability mass function* gives us the probabilities for each number. Mathematically it is \n\n$f_X(x) = \\text{Pr}(X = x)$ while $F_X(x) = \\text{Pr}(X \\leq x)$\n\nAssume the discrete values with positive probability are $x_1 < x_2 < \\dots < x_n$.\n\nThen it is easy to see the *probability mass function* is the **diff**-function of the *distribution function*. \n\n$f_X(x_i) = F_X(x_i) - F_X(x_{i-1})$\n\n\n\n## Uniform distribution theoretical vs. samples {.smaller}\n\n:::: {.columns}\n\nThe distribution function of a sample of 50 random numbers from a uniform distribution.\n\n::: {.column width='48%'}\n\nEmpirical and theoretical distribution function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunif <- runif(50) \nunif_cdf <- tibble(x = unif) %>% \n  arrange(x) %>% # We sort the data by size\n  mutate(cdf = (1:length(unif))/length(unif)) # cumulative probabilities\nunif_cdf |> ggplot(aes(x, y = cdf)) + geom_step() +\n geom_function(fun = punif, color = \"red\") + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width='48%'}\nEmpirical pmf approached with a histogram with small binwidth.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nunif_cdf|> \n ggplot(aes(x)) + \n geom_histogram(binwidth = 0.005) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::::\n::::\n\n\n## Normal distribution theoretical vs. samples {.smaller}\n\n:::: {.columns}\n\nThe distribution function of a sample of 50 random numbers from a normal distribution.\n\n::: {.column width='48%'}\n\nEmpirical and theoretical distribution function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal <- rnorm(50) \nnormal_cdf <- tibble(x = normal) %>% \n  arrange(x) %>% # We sort the data by size\n  mutate(cdf = (1:length(normal))/length(normal)) # cumulative probabilities\nnormal_cdf |> ggplot(aes(x, y = cdf)) + geom_step() +\n geom_function(fun = pnorm, color = \"red\") + xlim(c(-3,3)) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width='48%'}\nEmpirical pmf approached with a histogram with small binwidth.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal_cdf |> \n ggplot(aes(x)) + \n geom_histogram(binwidth = 0.005)  + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n[This type of pmf does not show the characteristics of the distribution well.]{style='color:red;'}\n:::\n\n::::\n::::\n\n## Approaching a solution {.smaller}\n\nThe theoretical distribution is approached better with \n\n- larger samples and\n- larger (but not too large) binwidth\n\n. . . \n\n:::: {.columns}\n\n::: {.column width='48%'}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal <- rnorm(5000) \nnormal_cdf <- tibble(x = normal) %>% \n  arrange(x) %>% # We sort the data by size\n  mutate(cdf = (1:length(normal))/length(normal)) # cumulative probabilities\nnormal_cdf |> ggplot(aes(x, y = cdf)) + geom_step() +\n geom_function(fun = pnorm, color = \"red\") + xlim(c(-4,4)) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width='48%'}\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal_cdf |> \n ggplot(aes(x)) + \n geom_histogram(binwidth = 0.01) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n:::\n\n::::\n::::\n\n\n## Solution: Probability density function {.smaller backround-color=\"aquamarine\"}\n\n- When we have a functional form, the *derivative* of the *distribution function* is the [**probability density function**]{style='color:blue;'} (pdf) $f_X(x) = \\frac{d}{dx}F_X(x)$. \n- Consequently, $F_X(x) = \\int_{-\\infty}^x f_X(\\xi)d\\xi$. \n- $\\int_a^bf(x)dx$ is the probability that a value from the random variable $X$ lies between $a$ and $b$: $\\text{Pr}(X \\geq a \\ \\&\\ X \\leq b)$ or $\\text{Pr}(X \\in [a,b])$\n\n. . . \n\n**The *pdf* is the analog of the *pmf* for continuous random variables.**\n\nInstead of the probability that $X$ takes a specific value $a$, we are interested in the probability that $X$ takes a value in an interval $[a,b]$.\n\n\n\n## Distribution Functions in R {.smaller}\n\nIdentifiers for distributions:  \n`unif` uniform distribution    \n`norm` normal distribution   \n`lnorm` lognormal distribution  \n`binom` binomial distribution\n\n##  Normal distribution in R {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x = rnorm(1000)) |> \n ggplot(aes(x)) + \n geom_histogram(aes(y =..density..), binwidth = 0.1) + \n geom_density() + \n geom_function(fun = dnorm, color = \"red\") +\n xlim(c(-5,5)) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `after_stat(density)` instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-40-1.png){width=672}\n:::\n:::\n\n\n\n## Lognormal distribution {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x = rlnorm(1000)) |> \n  ggplot(aes(x)) + geom_histogram(aes(y =..density..), binwidth = 0.1) + geom_density() +\n  geom_function(fun = dlnorm, color = \"red\") +\n  xlim(c(-1,10)) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_density()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n\n\n## Distribution parameters {.smaller}\n\nAs empirical samples of numbers also theoretical distributions have an **expected value** or **mean** and a **variance** (and a **standard deviation**). In theoretical distributions they often become (related to) parameters of the distribution.\n\nThe normal distribution has the parameters `mean` and `sd`\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n  geom_function(fun = function(x) dnorm(x, mean = 2, sd = 1)) +\n  geom_function(fun = function(x) dnorm(x, mean = -3, sd = 3), color = \"red\") +\n  geom_function(fun = function(x) dnorm(x, mean = 7, sd = 0.5), color = \"blue\") +\n  geom_function(fun = function(x) dnorm(x, mean = -1, sd = 6), color = \"green\") +\n  xlim(-15,15) + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-42-1.png){width=1920}\n:::\n:::\n\n\n\n## Measures of samples {.smaller}\n\nHere are some examples of mean and standard deviation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(1000, mean = 2, sd =5)\nmean(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.027264\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.907467\n```\n\n\n:::\n\n```{.r .cell-code}\nx <- rnorm(10000, mean = 2, sd =5)\nmean(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.05942\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.012979\n```\n\n\n:::\n\n```{.r .cell-code}\nx <- runif(10000)\nmean(x) # This should be 0.5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4998014\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(x) # This should be 1/sqrt(12) = 0.2886751\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2898095\n```\n\n\n:::\n:::\n\n\n## Galtons data {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngal_mean <- mean(galton$Estimate)\ngal_sd <- sd(galton$Estimate)\ngalton |> ggplot(aes(Estimate)) + \n geom_histogram(aes(y =..density..), binwidth = 5) + \n geom_density(color = \"blue\") +\n geom_function(fun = dnorm, args = list(mean = gal_mean, sd = gal_sd), color = \"red\") + theme_minimal(base_size = 24)\n```\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-44-1.png){width=960}\n:::\n:::\n\n\nA normal distribution fits OK. \n\n\n\n## The zoo of distributions {.smaller}\n\nThere are many probability distributions (implemented in R or not):  \n<https://en.wikipedia.org/wiki/List_of_probability_distributions>\n\n. . . \n\nWith interesting relations: (\n\n![](https://upload.wikimedia.org/wikipedia/commons/6/69/Relationships_among_some_of_univariate_probability_distributions.jpg){width=60%}\n\nSource: <https://en.wikipedia.org/wiki/Relationships_among_probability_distributions>)\n\n\n## The zoo of distributions {.smaller}\n\n- More important than knowing many distribution is to learn how to extract the idea of the **underlying probabilistic model**.\n  - Examples: \n      - *Binomial distribution* as the number of successes in repeated Bernoulli trials.\n      - *Poisson distribution* as the number of events in a given time interval.\n      - *Normal distribution* as the sum of many independent random variables.\n      - *Lognormal distribution* as the product of many independent random variables.\n\n[What does the underlying model of a normal distribution mean?]{style='color:blue;'}\n\n# Central Limit Theorem {.smaller}\n\n- Why is the normal distribution so central in theory? \n- Because of the central limit theorem, which is a great mathematical insights. \n\n**Central Limit Theorem** (colloquial version) The sum of many independent random variables (which can have various distributions) approaches the normal distribution (for ever larger sums and proper normalization).\n\n. . . \n\n$Y = X_1 + X_2 + \\dots + X_n \\to \\text{Normal distribution}$ for large $n$\n\n- This holds for $X_i$ with any distributions (except with fat tails)!\n- The mean of the evolving normal distribution of $Y$ is the sum of the expected values of the $X_i$\n- The same holds for the variance\n\n## Test with sum of uniform samples {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 10000\ntibble(X1 = runif(n),X2 = runif(n),X3 = runif(n),X4 = runif(n),X5 = runif(n),\n       X6 = runif(n),X7 = runif(n),X8 = runif(n),X9 = runif(n)) %>% \n mutate(S2 = X1 + X2,\n        S5 = X1 + X2 + X3 + X4 + X5,\n        S9 = X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 ) %>% \n ggplot() +\n geom_histogram(aes(x = X1, y =..density..), binwidth = 0.1, alpha = 0.5) +\n geom_histogram(aes(x = S2, y =..density..), binwidth = 0.1, fill = \"green\", alpha = 0.5) + \n geom_histogram(aes(x = S5, y =..density..), binwidth = 0.1, fill = \"red\", alpha = 0.5) + \n geom_histogram(aes(x = S9, y =..density..), binwidth = 0.1, fill = \"blue\", alpha = 0.5) +   xlim(c(-0.5,9)) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n\n## Sums of random variables important? {.smaller}\n\nWhy are sums of random variables important?\n\n- Sums of random variables are the theoretical foundation of linear models  $Y = \\beta_0 + \\beta_1X_1 + \\dots + \\beta_nX_n$\n- They appear also in generalized linear models as for the logistic regression. \n\n\n## Products of Random Variables? {.smaller}\n\nWhat when $Y$ is the product of many positive-valued random variable?\n\n$Y = X_1 \\cdot X_2 \\cdot \\dots \\cdot X_n$\n\n. . . \n\nThen\n\n$\\log(Y) = \\log(X_1) + \\log(X_2) + \\dots + \\log(X_n) \\to \\text{Normal distribution}$ for large $n$ (central limit theorem)\n\nSo, $\\log(Y)$ tends to become normally distributed. \n\n$Y$ is called to have a [**lognormal distribution**]{style='color:blue;'}.\n\n## Test with product of uniform samples {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 10000\ng <- tibble(X1 = 2*runif(n),X2 = 2*runif(n),X3 = 2*runif(n),X4 = 2*runif(n),X5 = 2*runif(n),\n            X6 = 2*runif(n),X7 = 2*runif(n),X8 = 2*runif(n),X9 = 2*runif(n)) %>% \n mutate(S2 = X1 * X2,\n        S5 = X1 * X2 * X3 * X4 * X5,\n        S9 = X1 * X2 * X3 * X4 * X5 * X6 * X7 * X8 * X9 ) %>% \n ggplot() +\n geom_histogram(aes(x = X1, y =..density..), binwidth = 0.1, alpha = 0.5) +\n geom_histogram(aes(x = S2, y =..density..), binwidth = 0.1, fill = \"green\", alpha = 0.5) + \n geom_histogram(aes(x = S5, y =..density..), binwidth = 0.1, fill = \"red\", alpha = 0.5) + \n geom_histogram(aes(x = S9, y =..density..), binwidth = 0.1, fill = \"blue\", alpha = 0.5) +   xlim(c(-0.5,9)) \ng\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 106 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 221 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](W13_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n:::\n\n\n## Different distributions {.smaller}\n\nDistributions \"live\" on different domains. This determines which values for random numbers are theoretically possible.\n\n- What is the domain of *Binomially distributed* random numbers? [$\\{0, ..., n\\}$]{.fragment}\n- What is the domain of *Normally distributed* random numbers? [$(-\\infty, +\\infty$)]{.fragment}\n- What is the domain of *Lognormally distributed* random numbers? [$(0, +\\infty$)]{.fragment}\n- What is the domain of *Uniformly distributed* random numbers? [$[0, 1]$]{.fragment}\n\n**Take away:**  \nFor many variables there are better or worse candidates for a theoretical distribution to assume. \n\n- Look at the empirical range and empircal distrbution of the variable\n- Think about the data generating process and how it may fit to a probability model\n\n\n<!-- **Conclusions:**  -->\n\n<!-- - When the response variable $Y$ is really a sum of several features (which all have relevant/non-zero coefficients) then $Y$ should look normally distributed (when predictors and response are not too correlated).  -->\n<!-- - If $Y$ strongly deviates from normality this is a sign that this model is not a really well representation of reality. This does not exclude using a linear model for prediction, but probably these can be improved. -->\n\n<!-- ## -->\n\n<!-- Options -->\n<!-- Normal distribution and binomial distributions are related -->\n<!-- Lognormal distribution as the product of many independent random variabl -->\n\n<!-- ## Next -->\n\n<!-- - In some statistical model, we consider variables in a data frame as *random variables*, for example the response variable in a generalized linear model.  -->\n\n<!-- Formally, a **random variable** is -->\n\n<!-- - a function $X: S \\to \\mathbb{R}$  -->\n<!-- - which assigns a value to each atomic event in the sample space.  -->\n\n<!-- Together with a probability function $\\text{Pr}: \\mathcal{F}(S)\\to [0,1]$ probabilities can be assigned to values of the random variable (see the *probability mass function* explained later). -->\n\n\n\n<!--   * Probabilistic simulations. For example bootstrapping.  -->\n<!--   Galton or Viertelfest: Quick Bootstrap examples following datascience box -->\n\n<!--   * Conditional probabilities and their relation to the confusion matrix. -->\n<!--   Quick difference between independence uncorrelated -->\n<!--   Conditional probability and relation to confusion matrix.  -->\n\n<!--   * Continuous random variables and some theoretical distributions. -->\n<!--   Normal and Lognormal, what do they mean.  -->\n\n<!--   * The central limit theorem. -->\n<!--   Sum of random variables.  -->\n<!--   Products of random variables.  -->\n\n\n\n<!-- Matrices: -->\n\n<!-- - Matrix multiplication -->\n<!-- - Ax = b -->\n<!-- - Ax = lambda x -->\n<!-- - SVD A = QDP -->\n\n\n  \n  \n\n\n\n\n\n<!-- ```{r} -->\n<!-- library(rworldmap) -->\n<!-- w <- assignments |> filter(k==5) |>  -->\n<!--  mutate(iso = owid_inds$iso_code, continent = owid_inds$continent, location = owid_inds$location, -->\n<!--         hcluster = factor(cutree(hc_owid, k = 5))) |>  -->\n<!--  select(iso, hcluster) -->\n<!-- jw <- joinCountryData2Map( w, joinCode = \"ISO3\", nameJoinColumn = \"iso\") -->\n<!-- mapCountryData( jw, nameColumnToPlot=\"hcluster\" ) -->\n<!-- ``` -->\n\n\n<!-- ```{r} -->\n<!-- ess_sel <- ess |>  -->\n<!--  select(cntry, gndr, atchctr, atcherp, euftf, lrscale, imueclt) |> na.omit()  -->\n<!-- ess_kmeans <- ess_sel |> select(-cntry, - gndr) |> kmeans(center = 5) -->\n<!-- ess_kmeans |> tidy() -->\n\n<!-- ctry <- ess_kmeans |> augment(ess_sel) |> count(.cluster,cntry) |>  -->\n<!--  group_by(cntry) |> mutate(freq = n/sum(n)) |> select(-n) |>  -->\n<!--  pivot_wider(names_from = .cluster, values_from = freq) -->\n\n<!-- ess_kmeans |> augment(ess_sel) -->\n\n<!-- ess_pca <- ess_sel |> select(-cntry, -gndr) |>  -->\n<!--  prcomp(~., data = _ , scale = TRUE) -->\n\n<!-- ess_pca |> augment(ess_sel) -->\n<!-- augment(ess_pca, ess_sel) |> mutate(.cluster = ess_kmeans$cluster) |>  -->\n<!--  ggplot(aes(.fittedPC1, .fittedPC2, color = factor(.cluster))) + geom_point(alpha =  0.1) -->\n<!-- ess_kmeans |> tidy() -->\n<!-- ess_pca -->\n<!-- ``` -->\n\n",
    "supporting": [
      "W13_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}