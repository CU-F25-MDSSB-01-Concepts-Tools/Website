[
  {
    "objectID": "lectures/W06.html#preliminaries",
    "href": "lectures/W06.html#preliminaries",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "lectures/W06.html#pca-description",
    "href": "lectures/W06.html#pca-description",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "PCA Description",
    "text": "PCA Description\nPrinciple component analysis\n\nis a dimensionality-reduction technique, that means it can be used to reduce the number of variables\ncomputes new variables which represent the data in a different way\ntransforms the data linearly to a new coordinate system where most of the variation in the data can be described with fewer variables than the original data\n\nToday: Quick walk through how to use and interpret it."
  },
  {
    "objectID": "lectures/W06.html#example-numerical-variables-of-penguins",
    "href": "lectures/W06.html#example-numerical-variables-of-penguins",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Example: Numerical variables of penguins",
    "text": "Example: Numerical variables of penguins\n\npeng &lt;-\n  penguins |&gt;\n  select(\n    species,\n    bill_length_mm,\n    bill_depth_mm,\n    flipper_length_mm,\n    body_mass_g\n  ) |&gt;\n  na.omit()\npeng |&gt; count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      151\n2 Chinstrap    68\n3 Gentoo      123\n\n\nWe have 342 penguins and 4 numeric variables."
  },
  {
    "objectID": "lectures/W06.html#two-variables",
    "href": "lectures/W06.html#two-variables",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Two Variables",
    "text": "Two Variables\nExample for the new axes.\n\n\nCode\npca1 &lt;- peng |&gt;\n  select(flipper_length_mm, bill_length_mm) |&gt;\n  prcomp(~., data = _, scale = FALSE)\npca_vec &lt;- t(pca1$rotation) |&gt; as_tibble() # Vectors with x = flipper_length, y = bill_length\nggplot(peng) +\n  geom_point(aes(x = flipper_length_mm, y = bill_length_mm, color = species)) +\n  geom_segment(\n    data = pca_vec,\n    aes(\n      x = mean(peng$flipper_length_mm),\n      y = mean(peng$bill_length_mm),\n      xend = c(pca1$sdev) * flipper_length_mm + mean(peng$flipper_length_mm),\n      yend = c(pca1$sdev) * bill_length_mm + mean(peng$bill_length_mm)\n    ),\n    arrow = arrow(length = unit(0.3, \"cm\"))\n  ) +\n  coord_fixed()\n\n\n\n\n\n\n\n\n\n\n\nThe two arrows show the two eigenvectors of the covariance matrix of the two variables scaled by the square root of the corresponding eigenvalues, and shifted so their origins are at the means of both variables."
  },
  {
    "objectID": "lectures/W06.html#computation-in-r",
    "href": "lectures/W06.html#computation-in-r",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Computation in R",
    "text": "Computation in R\nThe basic function is base-R’s prcomp (there is an older princomp which is not advisable to use).\n\n# prcomp can take a data frame with all numerical vectors as 1st argument\nP &lt;- peng |&gt;\n  select(flipper_length_mm, bill_length_mm) |&gt;\n  prcomp()\n\n\n\nThe base output\n\nP\n\nStandard deviations (1, .., p=2):\n[1] 14.549388  3.981729\n\nRotation (n x k) = (2 x 2):\n                        PC1        PC2\nflipper_length_mm 0.9637169 -0.2669266\nbill_length_mm    0.2669266  0.9637169\n\n\n\nThe summary output\n\nsummary(P)\n\nImportance of components:\n                           PC1     PC2\nStandard deviation     14.5494 3.98173\nProportion of Variance  0.9303 0.06968\nCumulative Proportion   0.9303 1.00000"
  },
  {
    "objectID": "lectures/W06.html#the-prcomp-object",
    "href": "lectures/W06.html#the-prcomp-object",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "The prcomp object",
    "text": "The prcomp object\nIncludes 4 different related entities.\n\n\nThe standard deviations related to each principal component.\n\nP$sdev\n\n[1] 14.549388  3.981729\n\n\nThe matrix of variable loadings. (It is also the matrix which rotates the original data vectors.)\n\nP$rotation\n\n                        PC1        PC2\nflipper_length_mm 0.9637169 -0.2669266\nbill_length_mm    0.2669266  0.9637169\n\n\n\nThe means for each original variable.\n\nP$center\n\nflipper_length_mm    bill_length_mm \n        200.91520          43.92193 \n\n\nNote, there are also standard deviations of original variables in $scale when this is set to be used.\nThe centered (scaled, if set) and rotated data.\n\nP$x\n\n               PC1         PC2\n  [1,] -20.4797199  0.66892267\n  [2,] -15.5543649 -0.28022355\n  [3,]  -6.6673719 -1.91158941\n  [4,]  -9.5557414 -4.84711693\n  [5,] -11.7528828 -1.54067330\n  [6,] -20.5331052  0.47617930\n  [7,]  -6.9609911 -2.97167796\n  [8,] -10.2497505 -7.35278078\n  [9,] -11.0321810  1.06136223\n [10,] -16.0081402 -1.91854222\n [11,] -21.7904413 -0.31698266\n [12,] -18.9821498  2.32942980\n [13,] -10.9760146 -2.48220170\n [14,]  -5.2977029 -8.20555532\n [15,] -17.2921689 -2.80807586\n [16,]  -7.0944544 -3.45353639\n [17,]  -4.1526997 -0.32526550\n [18,] -18.8431243 -4.66132637\n [19,]  -6.1096072  3.84852331\n [20,] -27.5727425  1.28457691\n [21,] -21.8171340 -0.41335434\n [22,] -13.6241501 -4.55038405\n [23,] -16.8650864 -1.26612888\n [24,] -21.5235147  0.64673421\n [25,] -15.7117398 -4.59476098\n [26,] -18.1518963  1.58064478\n [27,] -14.3237215  0.41656672\n [28,] -29.4734836  1.91480178\n [29,] -21.0697395  2.28505287\n [30,] -23.2640999  1.85518920\n [31,] -23.8780310 -0.36135959\n [32,] -13.6269312 -0.81407674\n [33,] -17.1081014  1.60283324\n [34,]  -7.7083856 -5.67008518\n [35,]  -5.9972743 -3.23860456\n [36,] -11.8863461 -2.02253174\n [37,] -20.6159643  3.92337154\n [38,] -20.8801098 -0.77665262\n [39,] -17.4017207  0.54274469\n [40,] -20.2100122 -2.10366777\n [41,]  -6.5339086 -1.42973098\n [42,] -16.4886080 -3.65323258\n [43,]  -4.6893340  1.48360808\n [44,] -17.1853983 -2.42258912\n [45,] -11.6728048 -1.25155824\n [46,] -18.9821498  2.32942980\n [47,] -22.8342362 -0.33917112\n [48,] -12.6337406 -4.72093895\n [49,]  -9.9883862  1.08355069\n [50,] -15.5276723 -0.18385187\n [51,] -13.4667753 -0.23584662\n [52,] -12.9006672 -5.68465582\n [53,]  -1.3950124 -1.60790371\n [54,] -15.9252810 -5.36573447\n [55,] -10.2286201  0.21620552\n [56,] -15.6878282 -0.76208199\n [57,]  -8.5147276 -1.08862116\n [58,] -21.1737290 -1.83674117\n [59,]  -8.3517906 -4.24669835\n [60,] -17.5324029 -3.67542104\n [61,]  -6.4004453 -0.94787255\n [62,] -17.0252423 -1.84435900\n [63,]  -9.3449812 -0.33983614\n [64,] -18.3092711 -2.73389264\n [65,]  -9.2115179  0.14202229\n [66,]  -7.9486195 -6.53743036\n [67,] -13.1998487  0.72787024\n [68,] -12.6604332 -4.81731064\n [69,]  -3.3758314 -1.26679390\n [70,] -13.3010571 -7.13023111\n [71,] -11.6461122 -1.15518656\n [72,]  -5.8905036 -2.85311781\n [73,]  -3.2718419  2.85500015\n [74,] -12.7672039 -5.20279739\n [75,]  -6.0000554  0.49770275\n [76,] -10.3620834 -0.26565292\n [77,] -18.0957298 -1.96291915\n [78,] -15.4715058 -3.72741580\n [79,]  -6.1869040 -0.17689906\n [80,] -13.9711547 -5.80321597\n [81,]  -5.0096459  0.32714784\n [82,] -15.3380425 -3.24555737\n [83,]  -9.9828239 -6.38906391\n [84,] -11.3230191 -3.73503363\n [85,]  -7.3641622 -0.68094595\n [86,] -12.5536626 -4.43182390\n [87,] -13.3572235 -3.58666718\n [88,] -12.9835263 -2.23746357\n [89,] -11.8596534 -1.92616005\n [90,]  -1.1492162 -8.21317314\n [91,]   3.1833380 -3.80988186\n [92,] -17.9861781 -5.31373971\n [93,] -15.5276723 -0.18385187\n [94,] -15.4715058 -3.72741580\n [95,]   5.9944106 -4.89977671\n [96,] -12.0731947 -2.69713354\n [97,]  -5.7036550 -2.17851601\n [98,] -24.9724301 -4.31259873\n [99,]  -8.7844354  1.68396928\n[100,] -10.9732334 -6.21850901\n[101,]   1.2292116 -3.37240036\n[102,] -18.9259834 -1.21413413\n[103,] -12.1532727 -2.98624860\n[104,]  -9.2354294 -3.69065670\n[105,] -17.4284133  0.44637301\n[106,]  -3.2662796 -4.61761446\n[107,] -12.0465021 -2.60076185\n[108,] -20.7466465 -0.29479419\n[109,]  -3.9658510  0.34933630\n[110,]  -4.3634598 -4.83254629\n[111,]  -9.1075284  4.26381634\n[112,]  -8.7549616 -1.95596634\n[113,]  -4.2327776 -0.61438056\n[114,] -10.7090880 -1.51848484\n[115,]  -5.0630312  0.13440447\n[116,] -13.8671651 -1.68142192\n[117,]  -3.6132842 -5.87044638\n[118,] -13.6775354 -4.74312742\n[119,] -12.2361318  0.46094364\n[120,] -15.4715058 -3.72741580\n[121,]  -4.4702304 -5.21803304\n[122,] -25.0046850  3.06364419\n[123,]   0.3722654 -2.71998702\n[124,] -16.7021493 -4.42420607\n[125,]  -2.7324265 -2.69018073\n[126,] -10.9226292 -2.28945833\n[127,]  -6.3470600 -0.75512918\n[128,] -10.8692439 -2.09671496\n[129,]   8.8027021 -2.25336424\n[130,] -11.9664241 -2.31164679\n[131,]  -3.9925437  0.25296462\n[132,]  -9.5290487 -4.75074525\n[133,]  -3.5598989 -5.67770301\n[134,] -14.9643453 -1.89635376\n[135,] -11.2724149  0.19401705\n[136,] -11.7767943 -5.37335229\n[137,]  -1.8754802 -3.34259407\n[138,] -17.1853983 -2.42258912\n[139,]  -8.7549616 -1.95596634\n[140,]  -8.6214983 -1.47410791\n[141,] -14.2970288  0.51293840\n[142,] -15.6021880 -7.94558153\n[143,] -11.3791856 -0.19146969\n[144,] -10.3593023 -4.00196022\n[145,] -16.6515451 -0.49515539\n[146,] -11.7795755 -1.63704499\n[147,] -18.2558858 -2.54114927\n[148,]  -7.8151562 -6.05557193\n[149,]  -9.2621221 -3.78702838\n[150,] -15.5248912 -3.92015917\n[151,]  -0.5647588 -2.35668874\n[152,]  10.3002722 -0.59285711\n[153,]  29.6519063 -1.90596663\n[154,]  10.0305645  2.17973333\n[155,]  18.0873039  1.29715250\n[156,]  14.5555295 -0.21498819\n[157,]   9.4433259  0.05955623\n[158,]  10.1134236 -1.26745892\n[159,]  18.1701630 -2.15003975\n[160,]   7.6254440 -2.75741114\n[161,]  14.3419882 -0.98596168\n[162,]  11.8034045 -6.40496458\n[163,]  15.8929436  0.86728882\n[164,]  13.0312668 -1.97186701\n[165,]  12.8416371  1.08983849\n[166,]   9.2564773 -0.61504558\n[167,]  16.9367385  0.88947729\n[168,]   8.2421563 -4.27716966\n[169,]  20.7649133 -0.27460078\n[170,]   8.3995311  0.03736776\n[171,]  21.5951668 -1.02338580\n[172,]  18.1406893  1.48989587\n[173,]  13.8882130 -2.62428035\n[174,]  12.3344765 -0.74122355\n[175,]  14.2085249 -1.46782012\n[176,]  13.3009745 -4.74445745\n[177,]  14.1551396 -1.66056349\n[178,]  14.6917739 -3.46943706\n[179,]  14.6089148 -0.02224482\n[180,]   9.8971012  1.69787490\n[181,]  20.0147377  0.76329931\n[182,]  21.2214696 -2.37258941\n[183,]   7.4919807 -3.23926957\n[184,]   6.1784781 -0.48886760\n[185,]  32.2144016  7.34571526\n[186,]  19.7745037 -0.10404587\n[187,]  19.5876551 -0.77864767\n[188,]  11.2934628 -4.49971932\n[189,]  17.5562319 -4.36658853\n[190,]   6.8485757 -1.81588274\n[191,]   8.1031307  2.71358652\n[192,]   6.5015712 -3.06871466\n[193,]  24.7265513 -0.95682041\n[194,]   9.1230140 -1.09690401\n[195,]  16.0530996  1.44551894\n[196,]  22.0756347  0.71130455\n[197,]  15.4152569 -4.60370884\n[198,]   9.1763994 -0.90416063\n[199,]  24.9667853 -0.08947523\n[200,]  11.9073940 -2.28317054\n[201,]  13.9149057 -2.52790867\n[202,]   9.4700186  0.15592792\n[203,]  19.6143478 -0.68227599\n[204,]   9.0696287 -1.28964738\n[205,]  24.8600146 -0.47496198\n[206,]  16.1893440 -1.80892993\n[207,]  18.6801047 -4.05528501\n[208,]   6.7951904 -2.00862611\n[209,]  18.8135680 -3.57342658\n[210,]   6.6350345 -2.58685623\n[211,]  23.9763758  0.08107968\n[212,]   7.1955803 -0.56305082\n[213,]  19.9641335 -3.16575137\n[214,]  13.0846521 -1.77912364\n[215,]  31.7634075  1.97108929\n[216,]  17.9299291 -3.01738492\n[217,]  29.5985210 -2.09871001\n[218,]  13.2181154 -1.29726521\n[219,]  28.5547261 -2.12089847\n[220,]  18.2797148 -5.50086030\n[221,]  23.0927369  0.63712133\n[222,]  15.5459390 -0.38554310\n[223,]  20.0175188 -2.97300799\n[224,]  20.4979867 -1.23831764\n[225,]  16.1893440 -1.80892993\n[226,]  15.1989345 -1.63837502\n[227,]  29.2782091 -3.25517024\n[228,]   8.7465357  1.29019969\n[229,]  20.3083569  1.82338786\n[230,]  13.9149057 -2.52790867\n[231,]  21.6246406 -4.66332142\n[232,]  12.0647688  2.03136689\n[233,]  21.6457710  2.90566487\n[234,]  11.6109936  0.39304822\n[235,]  23.8696051 -0.30440707\n[236,]  10.9436771 -2.01624394\n[237,]  27.9380138 -0.60113995\n[238,]  16.3255884 -5.06337880\n[239,]  18.4343085  2.54998442\n[240,]  11.6376863  0.48941990\n[241,]  30.2124521  0.11783878\n[242,]  17.4199874 -1.11213966\n[243,]  28.3117111  0.74806366\n[244,]  11.1038331 -1.43801382\n[245,]  23.7361418 -0.78626550\n[246,]  12.7643402 -2.93558388\n[247,]  26.0105801 -0.06728677\n[248,]  15.9997143  1.25277557\n[249,]  21.1146989 -2.75807616\n[250,]   3.2044684  3.75910443\n[251,]  25.1269412  0.48875489\n[252,]  18.6506309 -0.41534939\n[253,]  29.2993395  4.31381605\n[254,]  14.4487589 -0.60047494\n[255,]  27.4842386 -2.23945862\n[256,]  15.4391684 -0.77102985\n[257,]  14.3419882 -0.98596168\n[258,]   8.1620783 -4.56628472\n[259,]  19.9585712  4.30686324\n[260,]   6.6617271 -2.49048455\n[261,]   8.9066916  1.86842981\n[262,]  16.2933335  2.31286412\n[263,]  28.6348041 -1.83178341\n[264,]  11.5336968 -3.63237414\n[265,]  30.0522962 -0.46039134\n[266,]  16.1092660 -2.09804499\n[267,]  31.0132319  3.00898937\n[268,]  15.6554908 -3.73636366\n[269,]  21.6218595 -0.92701412\n[270,]  13.4850420 -0.33354834\n[271,]  14.3419882 -0.98596168\n[272,]  22.0489420  0.61493287\n[273,]  11.0237551 -1.72712888\n[274,]  13.2420270  2.53541378\n[275,]  -7.9035776  4.86423493\n[276,]  -3.1144671  7.16953757\n[277,]  -5.6586131  9.22314928\n[278,] -12.0520643  4.87185275\n[279,]  -1.4300484  9.50464651\n[280,]  -2.4682810  2.00984344\n[281,] -21.5023843  8.21572050\n[282,]  -1.8037456  8.15544290\n[283,]  -5.1458903  3.58159671\n[284,]  -0.8400288  7.88851631\n[285,]  -6.9131681  4.69368002\n[286,]  -4.5881256  9.34170943\n[287,] -14.5161323  7.21457952\n[288,]   2.2379704  7.76233833\n[289,]  -9.9911673  4.81985800\n[290,]   1.8375806  6.31676303\n[291,]  -2.0706722  7.19172604\n[292,] -15.4348073 18.88317139\n[293,]  -9.8577040  5.30171643\n[294,]  -4.2917252  6.66549067\n[295,] -19.5988621  3.84918832\n[296,]  -8.3334413  7.05859525\n[297,] -13.6030197  3.01860225\n[298,]  -5.8454617  8.54854747\n[299,]  -4.9590417  4.25619852\n[300,]  -1.6168970  8.83004470\n[301,]   0.8738637  6.58368963\n[302,]   0.6069371  5.61997276\n[303,]  -8.8939871  5.03478983\n[304,]   6.3063792  7.46560544\n[305,] -14.2169508  0.80205346\n[306,]   2.8252089  9.88251543\n[307,] -13.7898683  2.34400044\n[308,]   3.8984776  6.26476828\n[309,]  -4.1582619  7.14734911\n[310,]  -0.8906330  3.95946563\n[311,]  -4.7188078  5.12354369\n[312,]  10.9114222  5.35999898\n[313,]  -7.7968070  5.24972167\n[314,]   6.4932278  8.14020725\n[315,]  10.1106424  2.46884839\n[316,] -12.8022399  5.90975284\n[317,]  -2.8742331  8.03688275\n[318,]  -4.3156367  2.83281168\n[319,]  -2.8742331  8.03688275\n[320,]   1.9176585  6.60587809\n[321,]  -8.8700756  8.86746882\n[322,]  12.0380762  1.93499520\n[323,] -11.3875289 11.01745222\n[324,]  -1.2404187  6.44294101\n[325,]  -0.7304770  4.53769575\n[326,]   2.0778145  7.18410821\n[327,]  -7.1534020  3.82633484\n[328,]   3.8183996  5.97565322\n[329,] -13.7898683  2.34400044\n[330,]  -1.5635117  9.02278808\n[331,]  -9.2142990  3.87832960\n[332,]   3.4447024  4.62644961\n[333,]   2.7212194  5.76072138\n[334,]  -6.2163778  3.46303656\n[335,]   7.0298621  6.33133367\n[336,] -10.7146502  5.95412977\n[337,]  -5.2259683  3.29248165\n[338,]   9.0345927  9.82290284\n[339,]   0.9328113 -0.69618161\n[340,]  -6.1123883  7.58483061\n[341,]  10.5911103  4.20353874\n[342,]  -1.1336480  6.82842776"
  },
  {
    "objectID": "lectures/W06.html#pca-as-exploratory-data-analysis",
    "href": "lectures/W06.html#pca-as-exploratory-data-analysis",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "PCA as Exploratory Data Analysis",
    "text": "PCA as Exploratory Data Analysis\nSuppose we do a PCA with all 342 penguins (rows) and all 4 numeric variables.\n\nHow long will the vector of standard deviations be? 4\n\nWhat dimensions will the rotation matrix have? 4 x 4\n\nWhat dimensions will the rotated data frame have? 342 x 4\n\n\nWhen we do a PCA for exploration there are 3 things to look at:\n\nThe data in PC coordinates - the centered (scaled, if set) and rotated data.\n\nThe rotation matrix - the variable loadings.\nThe variance explained by each PC - based on the standard deviations."
  },
  {
    "objectID": "lectures/W06.html#all-variables",
    "href": "lectures/W06.html#all-variables",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "All variables",
    "text": "All variables\nNow, with scale = TRUE (recommended). Data will be centered and scaled (a.k.a. standardized) first.\n\npeng_PCA &lt;- peng |&gt; select(-species) |&gt; prcomp(scale = TRUE)\npeng_PCA\n\nStandard deviations (1, .., p=4):\n[1] 1.6594442 0.8789293 0.6043475 0.3293816\n\nRotation (n x k) = (4 x 4):\n                         PC1          PC2        PC3        PC4\nbill_length_mm     0.4552503 -0.597031143 -0.6443012  0.1455231\nbill_depth_mm     -0.4003347 -0.797766572  0.4184272 -0.1679860\nflipper_length_mm  0.5760133 -0.002282201  0.2320840 -0.7837987\nbody_mass_g        0.5483502 -0.084362920  0.5966001  0.5798821"
  },
  {
    "objectID": "lectures/W06.html#explore-data-in-pc-coordinates",
    "href": "lectures/W06.html#explore-data-in-pc-coordinates",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Explore data in PC coordinates",
    "text": "Explore data in PC coordinates\n\n\n\nStart plotting PC1 against PC2. By default these are the most important ones. Drill deeper later.\nAppend the original data. Here used to color by species.\n\n\n\nplotdata &lt;- peng_PCA$x |&gt;\n  as_tibble() |&gt;\n  bind_cols(peng)\nplotdata |&gt;\n  ggplot(aes(PC1, PC2, color = species)) +\n  geom_point() +\n  coord_fixed() +\n  theme_minimal(base_size = 20)"
  },
  {
    "objectID": "lectures/W06.html#variable-loadings",
    "href": "lectures/W06.html#variable-loadings",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Variable loadings",
    "text": "Variable loadings\n\nThe columns of the rotation matrix shows how the original variables load on the principle components.\nWe can interpret these loadings and give descriptive names to principal components.\nFor plotting we bring the rotation matrix to long format with PC and value column.\n\n\npeng_PCA$rotation |&gt;\n  as_tibble(rownames = \"variable\") |&gt;\n  pivot_longer(starts_with(\"PC\"), names_to = \"PC\", values_to = \"value\") |&gt;\n  ggplot(aes(value, variable)) +\n  geom_col() +\n  geom_vline(xintercept = 0, color = \"blue\") +\n  facet_wrap(~PC, nrow = 1) +\n  theme_minimal(base_size = 20)"
  },
  {
    "objectID": "lectures/W06.html#variance-explained",
    "href": "lectures/W06.html#variance-explained",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Variance explained",
    "text": "Variance explained\n\nPrinciple components are by default sorted by importance.\nThe squares of the standard deviation for each component gives its variances and variances have to sum up to the sum of the variances of the original variables.\n\nWhen original variables were standardized their original variances are all each one. Consequently, the variances of the principal components sum up to the number of original variables.\n\nA typical plot to visualize the importance of the components is to plot the percentage of the variance explained by each component.\n\n\n\ntibble(PC = 1:4, sdev = peng_PCA$sdev) |&gt;\n  mutate(percent = sdev^2 / sum(sdev^2) * 100) |&gt;\n  ggplot(aes(PC, percent)) +\n  geom_col() +\n  theme_grey(base_size = 20)"
  },
  {
    "objectID": "lectures/W06.html#interpretations-1",
    "href": "lectures/W06.html#interpretations-1",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Interpretations (1)",
    "text": "Interpretations (1)\n\n\nThe first component explains almost 70% of the variance.\n\nThe first two explain about 88% of the total variance."
  },
  {
    "objectID": "lectures/W06.html#interpretations-2",
    "href": "lectures/W06.html#interpretations-2",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Interpretations (2)",
    "text": "Interpretations (2)\n\n\nTo score high on PC1 a penguin needs to be generally large but with low bill depth.\nPenguins scoring high on PC2 are penguins with generally small bills."
  },
  {
    "objectID": "lectures/W06.html#interpretations-3",
    "href": "lectures/W06.html#interpretations-3",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Interpretations (3)",
    "text": "Interpretations (3)"
  },
  {
    "objectID": "lectures/W06.html#apply-pca",
    "href": "lectures/W06.html#apply-pca",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Apply PCA",
    "text": "Apply PCA\n\nBesides standardization, PCA may benefit from preprocessing steps of data transformation with variables with skew distributions. Use log, square-root, or Box-Cox transformation. This may result in less outliers.\nPCA is a often a useful step of exploratory data analysis when you have a large number of numerical variables to show the empirical dimensionality of the data and its structure.\nIt is related to the correlation-matrix and can “summarize” its structure.\nLimitation: PCA is only sensitive for linear relation ships (no U-shaped) or the like\nThe principal components can be used as predictors in a model instead of the raw variables."
  },
  {
    "objectID": "lectures/W06.html#properties-of-pca",
    "href": "lectures/W06.html#properties-of-pca",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Properties of PCA",
    "text": "Properties of PCA\n\nThe principal components (the columns of the rotation matrix) are maximally uncorrelated (actually they are even orthogonal).\nThis also holds for the columns of the rotated data.\nThe total variances of all prinicipal components sum up to the number of variables (when variables are standardized)\nThe PCA is unique. All principle components together are a complete representation of the data. (Unlike other technique of dimensionality reduction which may rely on starting values, random factors, or tuning parameters)\n\nTo be precise: It is unique modulo the sign of the PCs. When \\(x\\) is a PC, then \\(-x\\) is as well and can replace it."
  },
  {
    "objectID": "lectures/W06.html#relations-of-pca",
    "href": "lectures/W06.html#relations-of-pca",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Relations of PCA",
    "text": "Relations of PCA\n\nA technique similar in spirit is factor analysis (e.g. factanal). It is more theory based as it requires to specify to the theoriezed number of factors up front.\nPCA is an example of the importance of linear algebra (“matrixology”) in data science techniques.\n\n\n\n\n\nPCA is based on the eigenvalue decomposition of the covariance matrix (or correlation matrix in the standardized case) of the data.\n\n\nhttps://xkcd.com/1838/"
  },
  {
    "objectID": "lectures/W06.html#rules-for-exponentiation",
    "href": "lectures/W06.html#rules-for-exponentiation",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Rules for Exponentiation",
    "text": "Rules for Exponentiation\n\n\n\\(x^0\\)\n\\(0^x\\)\n\\(0^0\\)\n\\((x\\cdot y)^a\\)\n\\(x^{-a}\\), \\(x^{-1}\\)\n\\(x^\\frac{a}{b}\\), \\(x^\\frac{1}{2}\\)\n\\((x^a)^b\\)\n\n\n\\(x^0 = 1\\)\n\n\n\\(0^x = 0\\) for \\(x\\neq 0\\)\n\n\n\\(0^0 = 1\\) (discontinuity in \\(0^x\\))\n\n\n\\((x\\cdot y)^a = x^a\\cdot x^b\\)\n\n\n\\(x^{-a} = \\frac{1}{x^a}\\), \\(x^{-1} = \\frac{1}{x}\\)\n\n\n\\(x^\\frac{a}{b} = \\sqrt[b]{x^a} = (\\sqrt[b]{x})^a,\\ x^\\frac{1}{2} = \\sqrt{x}\\)\n\n\n\\((x^a)^b = x^{a\\cdot b} = (x^b)^a \\neq x^{a^b} = x^{(a^b)}\\)\nExample: \\((4^3)^2 = 64^2 = 4096 \\qquad 4^{3^2} = 4^9 = 262144\\)"
  },
  {
    "objectID": "lectures/W06.html#more-rules-for-exponentiation",
    "href": "lectures/W06.html#more-rules-for-exponentiation",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "More rules for exponentiation",
    "text": "More rules for exponentiation\n\n\n\\(x^a\\cdot x^b\\)\n\n\n\\(x^a\\cdot x^b = x^{a+b}\\) Multiplication of powers (with same base \\(x\\)) becomes addition of exponents.\n\n\n\n\n\n\\((x+y)^a\\)\n\n\nNo “simple” form! For \\(a\\) integer use binomial expansion. \\((x+y)^2 = x^2 + 2xy + y^2\\)\n\\((x+y)^3 = x^3 + 3x^2y + 3xy^2 + y^3\\)\n\\((x+y)^n = \\sum_{k=0}^n {n \\choose k} x^{n-k}y^k\\)\n\n\n\n\nPascal’s triangle\n\n\n\n\n\nFrom wikipedia\n\n\n\nWe meet it again in Probability:\nA row represents a binomial distribution\nWhich tends to mimics the normal distribution more and more\nand is related to the central limit theorem"
  },
  {
    "objectID": "lectures/W06.html#logarithms",
    "href": "lectures/W06.html#logarithms",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Logarithms",
    "text": "Logarithms\nDefinition: A logarithm of \\(a\\) for some base \\(b\\) is the value of the exponent which brings \\(b\\) to \\(a\\): \\(\\log_b(a) = x\\) means that \\(b^x =a\\)\nMost common:\n\n\\(\\log_{10}\\) useful for plotting data in logarithmic scales because the numbers can be interpreted easiest (number of decimals of the original values)\n\\(\\log_{e}\\) natural logarithm (also \\(\\log\\) or \\(\\ln\\)) useful in calculus and statistics because of nice mathematical properties\n\n\n\n\n\\(\\log_{10}(100) =\\)\n\n\n\\(2\\)\n\n\n\n\n\n\n\\(\\log_{10}(1) =\\)\n\n\n\\(0\\)\n\n\n\n\n\n\n\\(\\log_{10}(6590) =\\)\n\n\n\\(3.818885\\)\n\n\n\n\n\n\n\\(\\log_{10}(0.02) =\\)\n\n\n\\(-1.69897\\)"
  },
  {
    "objectID": "lectures/W06.html#rules-for-logarithms",
    "href": "lectures/W06.html#rules-for-logarithms",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Rules for logarithms",
    "text": "Rules for logarithms\nUsually only one base is used in the same context, because changing base is easy:\n\\(\\log_c(x) = \\frac{\\log_b(x)}{\\log_b(c)} = \\frac{\\log(x)}{\\log(c)}\\)\n\n\n\\(\\log(x\\cdot y)\\)\n\n\n\\(= \\log(x) + \\log(y)\\) Multiplication \\(\\to\\) addition.\n\n\n\n\n\n\\(\\log(x^y)\\)\n\n\n\\(= y\\cdot\\log(x)\\)\n\n\n\n\n\\(\\log(x+y)\\)\n\n\ncomplicated!\n\n\n\n\nAlso changing bases for powers is easy: \\(x^y = (e^{\\log(x)})^y = e^{y\\cdot\\log(x)}\\)"
  },
  {
    "objectID": "lectures/W06.html#sir-model",
    "href": "lectures/W06.html#sir-model",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "SIR model",
    "text": "SIR model\n\nAssume a population of \\(N\\) individuals.\n\nIndividuals can have different states, e.g.: Susceptible, Infectious, Recovered, …\nThe population divides into compartments of these states which change over time, e.g.: \\(S(t), I(t), R(t)\\) number of susceptible, infectious, recovered individuals\n\nNow we define dynamics like\n\nwhere the numbers on the arrows represent transition probabilities."
  },
  {
    "objectID": "lectures/W06.html#agent-based-simulation",
    "href": "lectures/W06.html#agent-based-simulation",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Agent-based Simulation",
    "text": "Agent-based Simulation\nAgent-based model: Individual agents are simulated and interact with each other.\nExplore and analyze with computer simulations.\nA tool: NetLogo https://ccl.northwestern.edu/netlogo/\n\nWe look at the model “Virus on a Network” from the model library.\nDirect Link to Virus on a Network in NetLogoWeb"
  },
  {
    "objectID": "lectures/W06.html#virus-on-a-network-6-links-initial",
    "href": "lectures/W06.html#virus-on-a-network-6-links-initial",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Virus on a Network: 6 links, initial",
    "text": "Virus on a Network: 6 links, initial\nAgents connected in a network with on average 6 links per agent. 3 are infected initially."
  },
  {
    "objectID": "lectures/W06.html#virus-on-a-network-6-links-final",
    "href": "lectures/W06.html#virus-on-a-network-6-links-final",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Virus on a Network: 6 links, final",
    "text": "Virus on a Network: 6 links, final\nThe outbreak dies out after some time."
  },
  {
    "objectID": "lectures/W06.html#virus-on-a-network-15-links-initial",
    "href": "lectures/W06.html#virus-on-a-network-15-links-initial",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Virus on a Network: 15 links, initial",
    "text": "Virus on a Network: 15 links, initial\nRepeat the simulation with 15 links per agent. 3 are infected initially."
  },
  {
    "objectID": "lectures/W06.html#virus-on-a-network-15-links-final",
    "href": "lectures/W06.html#virus-on-a-network-15-links-final",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Virus on a Network: 15 links, final",
    "text": "Virus on a Network: 15 links, final\nThe outbreak had infected most agents."
  },
  {
    "objectID": "lectures/W06.html#si-model",
    "href": "lectures/W06.html#si-model",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "SI model",
    "text": "SI model\nNow, we only treat the SI part of the model. We ignore recovery.\n\nPeople who are susceptible can become infected through contact with infectious\nPeople who are infectious stay infectious\n\nThe parameter \\(\\beta\\) is the average number of contacts per unit time multiplied with the probability that an infection happens during such a contact."
  },
  {
    "objectID": "lectures/W06.html#si-model-simulation-in-r",
    "href": "lectures/W06.html#si-model-simulation-in-r",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "SI-model: Simulation in R",
    "text": "SI-model: Simulation in R\n\nWe produce a vector of length \\(N\\) with entries representing the state of each individual as \"S\" or \"I\".\nWe model the random infection process in each step of unit time\n\nSetup\nParameters: \\(N=150, \\beta=0.3\\), a function to produce randomly infect individuals\n\n\nN &lt;- 150\nbeta &lt;- 0.3\nrandomly_infect &lt;- function(N, prob) { \n runif(N) &lt; prob \n # Gives a logical vector of length N\n # where TRUE appears with probability beta\n}\n# Test\nrandomly_infect(N, beta) |&gt; head() # First 6\n\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE  TRUE\n\n\n\n\ninit &lt;- rep(\"S\",N) # All susceptible\ninit[1] &lt;- \"I\" # Infect one individual\ninit |&gt; head() # First 6\n\n\n[1] \"I\" \"S\" \"S\" \"S\" \"S\" \"S\""
  },
  {
    "objectID": "lectures/W06.html#si-model-simulation-in-r-1",
    "href": "lectures/W06.html#si-model-simulation-in-r-1",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "SI-model: Simulation in R",
    "text": "SI-model: Simulation in R\nIteration over 75 time steps.\n\n\ntmax &lt;- 75\nsim_run &lt;- list(init) # list with one element\n# This list will collect the states of \n# all individuals over tmax time steps \nfor (i in 2:tmax) {\n # Every agents has a contact with a random other\n contacts &lt;- sample(sim_run[[i-1]], size = N)\n sim_run[[i]] &lt;- if_else( # vectorised ifelse\n  # conditions vector: contact is infected\n  # and a random infection happens\n  contacts == \"I\" & randomly_infect(N, beta), \n  true = \"I\", \n  false = sim_run[[i-1]]\n  ) # otherwise state stays the same\n}\nsim_output &lt;- tibble( # create tibble for ggplot\n # Compute a vector with length tmax \n # with the count of \"I\" in sim_run list\n t = 0:(tmax-1), # times steps\n # count of infected and output a vector\n infected = sim_run |&gt; map_dbl(\\(x) sum(x == \"I\"))) \nsim_output |&gt; \n ggplot(aes(t,infected)) + geom_line() +\n theme_minimal(base_size = 20)"
  },
  {
    "objectID": "lectures/W06.html#si-model-simulation-in-r-2",
    "href": "lectures/W06.html#si-model-simulation-in-r-2",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "SI-model: Simulation in R",
    "text": "SI-model: Simulation in R\nRun with \\(N = 10000\\)\n\n\nN &lt;- 10000\ninit &lt;- rep(\"S\",N) # All susceptible\ninit[1] &lt;- \"I\" # Infect one individual\ntmax &lt;- 75\nsim_run &lt;- list(init) # list with one element\n# This list will collect the states of \n# all individuals over tmax time steps \nfor (i in 2:tmax) {\n # Every agents has a contact with a random other\n contacts &lt;- sample(sim_run[[i-1]], size = N)\n sim_run[[i]] &lt;- if_else( # vectorised ifelse\n  # conditions vector: contact is infected\n  # and a random infection happens\n  contacts == \"I\" & randomly_infect(N, beta), \n  true = \"I\", \n  false = sim_run[[i-1]]\n  ) # otherwise state stays the same\n}\nsim_output &lt;- tibble( # create tibble for ggplot\n # Compute a vector with length tmax \n # with the count of \"I\" in sim_run list\n t = 0:(tmax-1), # times steps\n # count of infected, notice map_dbl\n infected = map_dbl(sim_run, \\(x) sum(x == \"I\"))) \nsim_output |&gt; \n ggplot(aes(t,infected)) + geom_line() +\n theme_minimal(base_size = 20)"
  },
  {
    "objectID": "lectures/W06.html#new-programming-concepts",
    "href": "lectures/W06.html#new-programming-concepts",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "New programming concepts",
    "text": "New programming concepts\nFrom base R:\nrunif random numbers from uniform distribution\nsample random sampling from a vector\nfor loop over commands with index (i) taking values of a vector (2:tmax) one by one if_else vectorized version of conditional statements"
  },
  {
    "objectID": "lectures/W06.html#motivation-si-model-with-population-compartments",
    "href": "lectures/W06.html#motivation-si-model-with-population-compartments",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Motivation: SI model with  population compartments",
    "text": "Motivation: SI model with  population compartments\nTwo compartments:\n\\(S(t)\\) is the number of susceptible people at time \\(t\\).\n\\(I(t)\\) is the number of infected people at time \\(t\\).\nIt always holds \\(S(t) + I(t) = N\\). (The total population is constant.)"
  },
  {
    "objectID": "lectures/W06.html#how-many-infections-per-time",
    "href": "lectures/W06.html#how-many-infections-per-time",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "How many infections per time?",
    "text": "How many infections per time?\nThe change of the number of infectious\n\\[\\frac{dI}{dt} = \\underbrace{\\beta}_\\text{infection prob.} \\cdot \\underbrace{\\frac{S}{N}}_\\text{frac. of $S$ still there} \\cdot \\underbrace{\\frac{I}{N}}_\\text{frac. $I$ to meet} \\cdot N = \\frac{\\beta\\cdot S\\cdot I}{N}\\]\nwhere \\(dI\\) is the change of \\(I\\) (the newly infected here) and \\(dt\\) the time interval.\n\nInterpretation: The newly infected are from the fraction of susceptible times the probability that they meet an infected times the infection probability times the total number of individuals.\nSame logic as our Simulation in R!\n\n\nUsing \\(S = N - I\\) we rewrite\n\\[\\frac{dI}{dt} = \\frac{\\beta (N-I)I}{N}\\]"
  },
  {
    "objectID": "lectures/W06.html#ordinary-differential-equation",
    "href": "lectures/W06.html#ordinary-differential-equation",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Ordinary differential equation",
    "text": "Ordinary differential equation\nWe interpret \\(I(t)\\) as a function of time which gives us the number of infectious at each point in time. The change function is now\n\\[\\frac{dI(t)}{dt} = \\frac{\\beta (N-I(t))I(t)}{N}\\]\nand \\(\\frac{dI(t)}{dt}\\) is also called the derivative of \\(I(t)\\)."
  },
  {
    "objectID": "lectures/W06.html#derivatives",
    "href": "lectures/W06.html#derivatives",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Derivatives",
    "text": "Derivatives\n\n\n\nThe derivative of a function is also a function with the same domain.\nMeasures the sensitivity to change of the function output when the input changes (a bit)\nExample from physics: The derivative of the position of a moving object is its speed. The derivative of its speed is its acceleration.\nGraphically: The derivative is the slope of a tangent line of the graph of a function."
  },
  {
    "objectID": "lectures/W06.html#differentiation",
    "href": "lectures/W06.html#differentiation",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Differentiation",
    "text": "Differentiation\nis the process to compute the derivative. For parameters \\(a\\) and \\(b\\) and other functions \\(g\\) and \\(h\\), rules of differentiation are\n\n\nFunction \\(f(x)\\)\n\nIts derivative \\(\\frac{df(x)}{dx}\\) or \\(\\frac{d}{dx}f(x)\\) or \\(f'(x)\\)\n\n\n\n\\(a\\cdot x\\)\n\\(b\\)\n\\(x^2,\\ x^{-1} = \\frac{1}{x},\\ x^k\\)\n\\(g(x) + h(x)\\)\n\\(g(x)\\cdot h(x)\\)\n\\(g(h(x))\\)\n\\(e^x,\\ 10^x  = e^{\\log(10)x}\\)\n\\(\\log(x)\\)\n\n\n\\(a\\)\n\n\n\\(0\\)\n\n\n\\(2\\cdot x,\\ -x^{-2} = -\\frac{1}{x^2},\\ k\\cdot x^{k-1}\\)\n\n\n\\(g'(x) + h'(x)\\)\n\n\n\\(g'(x)\\cdot h(x) + g(x)\\cdot h'(x)\\) (product rule)\n\n\n\\(g'(h(x))\\cdot h'(x)\\) (chain rule)\n\n\n\\(e^x,\\ 10^x = \\log(10)\\cdot10^x\\)\n\n\n\\(\\frac{1}{x}\\) (A surprising relation to me at least)"
  },
  {
    "objectID": "lectures/W06.html#differential-equation",
    "href": "lectures/W06.html#differential-equation",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Differential equation",
    "text": "Differential equation\nIn a differential equation the unknown is a function!\nWe are looking for a function which derivative is a function of the function itself.\nExample: SI-model\n\\[\\frac{dI(t)}{dt} = \\frac{\\beta (N-I(t))I(t)}{N}\\]\nWhich function \\(I(t)\\) fulfills this equation?\nThe analytical solution1\n\\(I(t) = \\frac{N}{1 + (\\frac{N}{I(0)} - 1)e^{-\\beta t}}\\)\nWhich is called the logistic equation. Note, we need to specify the initial number of infectious individuals \\(I(0)\\).\nCan you check that this is correct? Compute \\(I'(t)\\) (\\(=\\frac{dI(t)}{dt}\\)) and check if \\(I'(t) = \\frac{\\beta (N-I(t))I(t)}{N}\\). It is a bit of work, but try it! Let me know, if you want a solution."
  },
  {
    "objectID": "lectures/W06.html#si-model-logistic-equation",
    "href": "lectures/W06.html#si-model-logistic-equation",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "SI-model: Logistic Equation",
    "text": "SI-model: Logistic Equation\n\\(I(t) = \\frac{N}{1 + (\\frac{N}{I(0)} - 1)e^{-\\beta t}}\\)\nPlot the equation for \\(N = 10000\\), \\(I_0 = 1\\), and \\(\\beta = 0.3\\)\n\nN &lt;- 10000\nI0 &lt;- 1\nbeta &lt;- 0.3\nggplot() + \n geom_function( fun = function(t) N / (1 + (N/I0 - 1)*exp(-beta*t)) ) + \n xlim(c(0,75))"
  },
  {
    "objectID": "lectures/W06.html#si-model-numerical-integration",
    "href": "lectures/W06.html#si-model-numerical-integration",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "SI-model: Numerical integration",
    "text": "SI-model: Numerical integration\nAnother way of solution is numerical integration, e.g. using Euler’s method.\nWe compute the solution step-by-step using increments of, e.g. \\(dt = 1\\).\n\n\nN &lt;- 10000\nI0 &lt;- 1\ndI &lt;- function(I,N,b) b*I*(N - I)/N\nbeta &lt;- 0.3\ndt &lt;- 1 # time increment, \n# supposed to be infinitesimally small\ntmax &lt;- 75\nt &lt;- seq(0,tmax,dt) \n# this is the vector of timesteps\nIt &lt;- I0 # this will become the vector \n# of the number infected I(t) over time\nfor (i in 2:length(t)) { \n # We iterate over the vector of time steps \n # and incrementally compute It\n It[i] = It[i-1] + dt * dI(It[i-1], N, beta) \n # This is called Euler's method\n}\ntibble(t, It) |&gt; ggplot(aes(t,It)) + \n geom_line(color = \"red\") + \n geom_function( \n  fun = function(t) N / (1 + (N/I0 - 1)*exp(-beta*t)), color = \"blue\") + \n # In blue: Analytical solution for comparison\n theme_minimal(base_size = 20)\n\n\n\n\n\n\n\n\n\nWhy do the graphs deviate? The step size \\(dt\\) must be “infinitely” small"
  },
  {
    "objectID": "lectures/W06.html#numerical-integration-with-smaller-dt",
    "href": "lectures/W06.html#numerical-integration-with-smaller-dt",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Numerical integration with smaller \\(dt\\)",
    "text": "Numerical integration with smaller \\(dt\\)\nWe compute the solution step-by-step using small increments of, e.g. \\(dt = 0.05\\).\n\n\nN &lt;- 10000\nI0 &lt;- 1\ndI &lt;- function(I,N,b) b*I*(N - I)/N\nbeta &lt;- 0.3\ndt &lt;- 0.05 # time increment, \n# supposed to be infinitesimally small\ntmax &lt;- 75\nt &lt;- seq(0,tmax,dt) \n# this is the vector of timesteps\nIt &lt;- I0 # this will become the vector \n# of the number infected I(t) over time\nfor (i in 2:length(t)) { \n # We iterate over the vector of time steps \n # and incrementally compute It\n It[i] = It[i-1] + dt * dI(It[i-1], N, beta) \n # This is called Euler's method\n}\ntibble(t, It) |&gt; ggplot(aes(t,It)) + \n geom_line(color = \"red\") +\n geom_function( \n  fun = function(t) N / (1 + (N/I0 - 1)*exp(-beta*t)), color = \"blue\") + \n # In blue: Analytical solution for comparison\n theme_minimal(base_size = 20)"
  },
  {
    "objectID": "lectures/W06.html#mechanistic-model",
    "href": "lectures/W06.html#mechanistic-model",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Mechanistic model",
    "text": "Mechanistic model\nThe SI model is a potential answer to the mechanistic question How do epidemics spread?\nThe examples above show 3 different ways to explore the model:\n\nAgent-based simulation\n\nWe model every individual explicitly\nSimulation involve random numbers! So simulation runs can be different!\n\n\n\n\nNumerical integration of differential equation\n\nNeeds a more abstract concept of compartments\n\n\n\n\n\nAnalytical solutions of differential equation\n\noften not possible (therefore numerical integration is common)"
  },
  {
    "objectID": "lectures/W06.html#differentiation-with-data",
    "href": "lectures/W06.html#differentiation-with-data",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Differentiation with data",
    "text": "Differentiation with data\nWe can do calculus operations with data!\nIn empirical data we can compute the increase in a vector with the function diff:\n\nx &lt;- c(1,2,4,5,5,3,0)\ndiff(x)\n\n[1]  1  2  1  0 -2 -3\n\n\n\nMore convenient in a data frame is to use x - lag(x) because the vector has the same length.\n\nx - lag(x)\n\n[1] NA  1  2  1  0 -2 -3"
  },
  {
    "objectID": "lectures/W06.html#the-diff-of-our-simulation-output",
    "href": "lectures/W06.html#the-diff-of-our-simulation-output",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "The diff of our simulation output",
    "text": "The diff of our simulation output\n\ng1 &lt;- sim_output |&gt; ggplot(aes(x = t)) + geom_line(aes(y = infected))\ng1\n\n\n\n\n\n\n\ng2 &lt;- sim_output |&gt; \n mutate(derivative_infected = infected - lag(infected)) |&gt; \n ggplot(aes(x = t)) + geom_line(aes(y = derivative_infected))\ng2"
  },
  {
    "objectID": "lectures/W06.html#nd-derivative-change-of-change",
    "href": "lectures/W06.html#nd-derivative-change-of-change",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "2nd derivative: Change of change",
    "text": "2nd derivative: Change of change\n\ng3 &lt;- sim_output |&gt; \n mutate(derivative_infected = infected - lag(infected),\n        derivative2_infected = derivative_infected - lag(derivative_infected)) |&gt; \n ggplot(aes(x = t)) + geom_line(aes(y = derivative2_infected))\ng3\n\n\nIn empirical data: Derivatives of higher order tend to show fluctuation"
  },
  {
    "objectID": "lectures/W06.html#interpretation-in-si-model",
    "href": "lectures/W06.html#interpretation-in-si-model",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Interpretation in SI-model",
    "text": "Interpretation in SI-model\n\n\n\\(I(t)\\) total number of infected\n\\(I'(t)\\) number of new cases per day (time step)\n\\(I''(t)\\) how the number of new cases has changes compared to yesterday\n\n2nd derivatives are a good early indicator for the end of a wave."
  },
  {
    "objectID": "lectures/W06.html#integration",
    "href": "lectures/W06.html#integration",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "Integration",
    "text": "Integration\nThe integral of the daily new cases from the beginning to day \\(s\\) is \\(\\int_{-\\infty}^s f(t)dt\\) and represents the total cases at day \\(s\\).\n\nThe integral of a function \\(f\\) up to time \\(s\\) is also called the anti-derivative \\(F(s) = \\int_{-\\infty}^s f(t)dt\\).\n\nThe symbol \\(\\int\\) comes from an S and means “sum”.\n\nCompute the anti-derivative of data vector with cumsum.\n\n\nx &lt;- c(1,2,4,5,5,3,0)\ncumsum(x)\n\n[1]  1  3  7 12 17 20 20\n\n\n\nEmpirically: Derivatives tend to become noisy, while integrals tend to become smooth."
  },
  {
    "objectID": "lectures/W06.html#the-fundamental-theorem-of-calculus",
    "href": "lectures/W06.html#the-fundamental-theorem-of-calculus",
    "title": "W#06: Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus",
    "section": "The fundamental theorem of calculus",
    "text": "The fundamental theorem of calculus\nThe integral of the derivative is the function itself.\nThis is not a proof but shows the idea:\n\nf &lt;- c(1,2,4,5,5,3,0)\nantiderivative &lt;- cumsum(f)\nantiderivative\n\n[1]  1  3  7 12 17 20 20\n\ndiff(c(0, antiderivative)) \n\n[1] 1 2 4 5 5 3 0\n\n# We have to put 0 before to regain the full vector\nderivative &lt;- diff(f)\nderivative\n\n[1]  1  2  1  0 -2 -3\n\ncumsum(c(1,derivative)) \n\n[1] 1 2 4 5 5 3 0\n\n# We have to put in the first value (here 1) \n# manually because it was lost during the diff"
  },
  {
    "objectID": "lectures/W04.html#preliminaries",
    "href": "lectures/W04.html#preliminaries",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Preliminaries",
    "text": "Preliminaries\nIn this lectures we will use these packages.\n\nlibrary(nycflights13)\nlibrary(tidyverse)\n\nThe datasets used can be downloaded from:\nhttps://github.com/CU-F25-MDSSB-01-Concepts-Tools/Website/tree/main/lectures"
  },
  {
    "objectID": "lectures/W04.html#string-modification",
    "href": "lectures/W04.html#string-modification",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "String modification",
    "text": "String modification\nWe modify strings with the stringr package from the tidyverse core. All functions from stringr start with str_.\nVery few examples:\n\nc(\"x\", \"y\")\n\n[1] \"x\" \"y\"\n\nstr_c(\"x\", \"y\")\n\n[1] \"xy\"\n\n\n\n\nstr_c(\"x\", \"y\", \"z\", sep = \",\")\n\n[1] \"x,y,z\"\n\n\n\n\n\nlength(c(\"x\", \"y\", \"z\"))\n\n[1] 3\n\nstr_length(c(\"x\", \"y\", \"z\"))\n\n[1] 1 1 1\n\nstr_length(c(\"This is a string.\", \"z\"))\n\n[1] 17  1"
  },
  {
    "objectID": "lectures/W04.html#string-wrangling-with-variable-names",
    "href": "lectures/W04.html#string-wrangling-with-variable-names",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "String wrangling with variable names",
    "text": "String wrangling with variable names\nThis is a typical use case. We have data like this:\n\n\ndata &lt;- tibble(\n  Name = c(\"A\", \"B\", \"C\"),\n  Age_2020 = c(20, 30, 40),\n  Age_2021 = c(21, 31, 41),\n  Age_2022 = c(22, 32, 42)\n)\ndata\n\n\n# A tibble: 3 × 4\n  Name  Age_2020 Age_2021 Age_2022\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 A           20       21       22\n2 B           30       31       32\n3 C           40       41       42\n\n\nWe tidy that data set by creating a year variable.\n\n\n\ndata |&gt;\n  pivot_longer(\n    c(\"Age_2020\", \"Age_2021\", \"Age_2022\"),\n    names_to = \"Year\",\n    values_to = \"Age\"\n  )\n\n\n# A tibble: 9 × 3\n  Name  Year       Age\n  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n1 A     Age_2020    20\n2 A     Age_2021    21\n3 A     Age_2022    22\n4 B     Age_2020    30\n5 B     Age_2021    31\n6 B     Age_2022    32\n7 C     Age_2020    40\n8 C     Age_2021    41\n9 C     Age_2022    42\n\n\n\n\nOK, but the year variable is a string but we want numbers."
  },
  {
    "objectID": "lectures/W04.html#use-word",
    "href": "lectures/W04.html#use-word",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Use word",
    "text": "Use word\nword extracts words from a sentence.\n\nYou can specify the words from start to end. Use numbers or negative numbers to count from the last word.\nThe word separator need not be \" \" but can be any character.\n\n\n\nword(\"This is a string.\", start = 2, end = -2)\n\n\n[1] \"is a\"\n\n\n\n\nword(\"Age_2022\", start = 2, sep = \"_\")\n\n\n[1] \"2022\"\n\n\n\nIt also works vectorized.\n\n\ndata |&gt;\n  pivot_longer(\n    c(\"Age_2020\", \"Age_2021\", \"Age_2022\"),\n    names_to = \"Year\",\n    values_to = \"Age\"\n  ) |&gt;\n  mutate(\n    Year = word(Year, start = 2, sep = \"_\") |&gt; \n      as.numeric()\n      )\n\n\n# A tibble: 9 × 3\n  Name   Year   Age\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A      2020    20\n2 A      2021    21\n3 A      2022    22\n4 B      2020    30\n5 B      2021    31\n6 B      2022    32\n7 C      2020    40\n8 C      2021    41\n9 C      2022    42"
  },
  {
    "objectID": "lectures/W04.html#string-detection-regular-expressions",
    "href": "lectures/W04.html#string-detection-regular-expressions",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "String Detection / Regular Expressions",
    "text": "String Detection / Regular Expressions\nMany stringr function follow the structure (string, pattern).\nstring is in our data, pattern is a string interpreted as a Regular Expression\nA few examples show its power:\n\nfruits &lt;- c(\"apple\", \"pineapple\", \"Pear\", \"orange\", \"peach\", \"banana\")\n\n\n\nstr_detect(fruits, \"apple\")\n\n\n[1]  TRUE  TRUE FALSE FALSE FALSE FALSE\n\n\n\n\nstr_extract(fruits, \"apple\")\n\n\n[1] \"apple\" \"apple\" NA      NA      NA      NA     \n\n\n\n\nstr_extract(fruits, \"[Pp][a-z]\")\n\n\n[1] \"pp\" \"pi\" \"Pe\" NA   \"pe\" NA  \n\n\n\n\nstr_extract(fruits, \"^[Pp][a-z]\")\n\n\n[1] NA   \"pi\" \"Pe\" NA   \"pe\" NA  \n\n\n\n\nstr_extract(fruits, \"^[Pp][a-z]{3}\")\n\n\n[1] NA     \"pine\" \"Pear\" NA     \"peac\" NA    \n\n\n\n\nstr_extract(fruits, \"^[Pp][a-z]+\")\n\n\n[1] NA          \"pineapple\" \"Pear\"      NA          \"peach\"     NA         \n\n\nTest other words, like str_extract(\"Pizza Napoli\",\"^[Pp][a-z]+\"):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/W04.html#regular-expressions",
    "href": "lectures/W04.html#regular-expressions",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Regular Expressions",
    "text": "Regular Expressions\nRegular expressions (regexp or regex): Character-Sequences specifying match patterns.\n\nUseful when strings contain unstructured or semi-structured data.\nWhen you first look at a regexp, you’ll think a cat walked across your keyboard, but as your understanding improves they will start to make sense. (Or you ask an AI chatbot to give you what you need 🙂)\n\nGuess what this regexp’s are to match?\n\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$\"\n\"^[\\\\w-\\\\.]+@([\\\\w-]+\\\\.)+[\\\\w-]{2,4}$\"\n\"^[[:alnum:].-_]+@[[:alnum:].-]+$\"\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nEmail addresses! However, this is not the perfect solution. Dig deeper: Read the discussion and see the example in How can I validate an email address using a regular expression? at stackoverflow."
  },
  {
    "objectID": "lectures/W04.html#special-values",
    "href": "lectures/W04.html#special-values",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Special values",
    "text": "Special values\nYou should know the differences of special values.\n\nNA: Not available (string, number, or whatever vector entry)\nNULL: Null object, the undefined object, e.g. an empty list or an empty list element\nNaN: For numbers: Meaning “Not a Number” (when math cannot solve what you want)\nInf: For numbers: Positive infinity\n-Inf: For numbers: Negative infinity\n\nCheck some math:\n\n\n1 / 0\n\n\n[1] Inf\n\n\n\n\n-1 / 0\n\n\n[1] -Inf\n\n\n\n\n0 / 0\n\n\n[1] NaN\n\n\n\n\n1 / 0 + 1 / 0\n\n\n[1] Inf\n\n\n\n\n1 / 0 - 1 / 0\n\n\n[1] NaN"
  },
  {
    "objectID": "lectures/W04.html#nas",
    "href": "lectures/W04.html#nas",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "NAs",
    "text": "NAs\nNaN is not a number, but NA stands for genuinely unknown values.\nIt can also be in a character of logical vector.\n\nx = c(1, 2, 3, 4, NA)\nmean(x)\n\n[1] NA\n\nmean(x, na.rm = TRUE)\n\n[1] 2.5\n\nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1.00    1.75    2.50    2.50    3.25    4.00       1 \n\n\n\nThe type of NA is logical.\n\ntypeof(NA)\n\n[1] \"logical\"\n\ntypeof(NaN)\n\n[1] \"double\"\n\n\nDoes it make sense? Let us look at NA’s in logical operations."
  },
  {
    "objectID": "lectures/W04.html#nas-in-logical-operations",
    "href": "lectures/W04.html#nas-in-logical-operations",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "NAs in logical operations",
    "text": "NAs in logical operations\nNA can be TRUE or FALSE.\nUsually operations including NA results again in NA, but some not!\n\n\nNA & TRUE\n\n\n[1] NA\n\n\n\n\nNA | TRUE\n\n\n[1] TRUE\n\n\n\n\nNA & FALSE\n\n\n[1] FALSE\n\n\n\n\nNA | FALSE\n\n\n[1] NA\n\n\nUnderstanding logical operations is important!"
  },
  {
    "objectID": "lectures/W04.html#null-is-the-null-object",
    "href": "lectures/W04.html#null-is-the-null-object",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "NULL is the null object",
    "text": "NULL is the null object\n\nused to represent lists with zero length\n\n\nx &lt;- 1:10\nattributes(x)\n\nNULL\n\n\n\nused as a placeholder for missing values in lists and dataframes\n\n\nL &lt;- list(a = 1)\nL[[3]] &lt;- 5\nL\n\n$a\n[1] 1\n\n[[2]]\nNULL\n\n[[3]]\n[1] 5"
  },
  {
    "objectID": "lectures/W04.html#working-with-more-dataframes",
    "href": "lectures/W04.html#working-with-more-dataframes",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Working with more dataframes",
    "text": "Working with more dataframes\n\nData can be distributed in several dataframes which have relations which each other.\nFor example, they share variables as the five dataframes in nycflights13.\n\n\n\n\nOften variables in different dataframe have the same name, but that need not be the case! See the variable faa in airports matches origin and dest in flights."
  },
  {
    "objectID": "lectures/W04.html#data-women-in-science",
    "href": "lectures/W04.html#data-women-in-science",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Data: Women in science",
    "text": "Data: Women in science\n10 women in science who changed the world:\nAda Lovelace, Marie Curie, Janaki Ammal, Chien-Shiung Wu, Katherine Johnson, Rosalind Franklin, Vera Rubin, Gladys West, Flossie Wong-Staal, Jennifer Doudna\n\nProfessionsDatesWorks\n\n\n\nprofessions &lt;- read_csv(\"professions.csv\")\nprofessions\n\n# A tibble: 10 × 2\n   name               profession                        \n   &lt;chr&gt;              &lt;chr&gt;                             \n 1 Ada Lovelace       Mathematician                     \n 2 Marie Curie        Physicist and Chemist             \n 3 Janaki Ammal       Botanist                          \n 4 Chien-Shiung Wu    Physicist                         \n 5 Katherine Johnson  Mathematician                     \n 6 Rosalind Franklin  Chemist                           \n 7 Vera Rubin         Astronomer                        \n 8 Gladys West        Mathematician                     \n 9 Flossie Wong-Staal Virologist and Molecular Biologist\n10 Jennifer Doudna    Biochemist                        \n\n\n\n\n\ndates &lt;- read_csv(\"dates.csv\")\ndates\n\n# A tibble: 8 × 3\n  name               birth_year death_year\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;\n1 Janaki Ammal             1897       1984\n2 Chien-Shiung Wu          1912       1997\n3 Katherine Johnson        1918       2020\n4 Rosalind Franklin        1920       1958\n5 Vera Rubin               1928       2016\n6 Gladys West              1930         NA\n7 Flossie Wong-Staal       1947         NA\n8 Jennifer Doudna          1964         NA\n\n\n\n\n\nworks &lt;- read_csv(\"works.csv\")\nworks\n\n# A tibble: 9 × 2\n  name               known_for                                                  \n  &lt;chr&gt;              &lt;chr&gt;                                                      \n1 Ada Lovelace       first computer algorithm                                   \n2 Marie Curie        theory of radioactivity,  discovery of elements polonium a…\n3 Janaki Ammal       hybrid species, biodiversity protection                    \n4 Chien-Shiung Wu    confim and refine theory of radioactive beta decy, Wu expe…\n5 Katherine Johnson  calculations of orbital mechanics critical to sending the …\n6 Vera Rubin         existence of dark matter                                   \n7 Gladys West        mathematical modeling of the shape of the Earth which serv…\n8 Flossie Wong-Staal first scientist to clone HIV and create a map of its genes…\n9 Jennifer Doudna    one of the primary developers of CRISPR, a ground-breaking…\n\n\n\n\n\n\n\nSource: Discover Magazine. The data can be downloaded: professions.csv, dates.csv, works.csv"
  },
  {
    "objectID": "lectures/W04.html#we-want-this-dataframe",
    "href": "lectures/W04.html#we-want-this-dataframe",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "We want this dataframe",
    "text": "We want this dataframe\n\n\n# A tibble: 10 × 5\n   name               profession                 birth_year death_year known_for\n   &lt;chr&gt;              &lt;chr&gt;                           &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    \n 1 Ada Lovelace       Mathematician                      NA         NA first co…\n 2 Marie Curie        Physicist and Chemist              NA         NA theory o…\n 3 Janaki Ammal       Botanist                         1897       1984 hybrid s…\n 4 Chien-Shiung Wu    Physicist                        1912       1997 confim a…\n 5 Katherine Johnson  Mathematician                    1918       2020 calculat…\n 6 Rosalind Franklin  Chemist                          1920       1958 &lt;NA&gt;     \n 7 Vera Rubin         Astronomer                       1928       2016 existenc…\n 8 Gladys West        Mathematician                    1930         NA mathemat…\n 9 Flossie Wong-Staal Virologist and Molecular …       1947         NA first sc…\n10 Jennifer Doudna    Biochemist                       1964         NA one of t…"
  },
  {
    "objectID": "lectures/W04.html#joining-dataframes",
    "href": "lectures/W04.html#joining-dataframes",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Joining dataframes",
    "text": "Joining dataframes\nsomething_join(x, y)1 for dataframes x and y which have a relation\n\nleft_join(): all rows from x must remain\nright_join(): all rows from y must remain\nfull_join(): all rows from both x and y must remain\ninner_join(): all rows from x where there are matching values in y remain\n… (more exist see dplyr cheatsheet)\n\nThe notion join comes from SQL database. In other data manipulation frameworks joining is called merging."
  },
  {
    "objectID": "lectures/W04.html#simple-setup-for-x-and-y",
    "href": "lectures/W04.html#simple-setup-for-x-and-y",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Simple setup for x and y",
    "text": "Simple setup for x and y\n\nx &lt;- tibble(\n  id = c(1, 2, 3),\n  value_x = c(\"x1\", \"x2\", \"x3\")\n)\ny &lt;- tibble(\n  id = c(1, 2, 4),\n  value_y = c(\"y1\", \"y2\", \"y4\")\n)\nx\n\n# A tibble: 3 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\ny\n\n# A tibble: 3 × 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "lectures/W04.html#left_join",
    "href": "lectures/W04.html#left_join",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "left_join()",
    "text": "left_join()\n\n\n\n\n\nleft_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;"
  },
  {
    "objectID": "lectures/W04.html#right_join",
    "href": "lectures/W04.html#right_join",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "right_join()",
    "text": "right_join()\n\n\n\n\n\nright_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "lectures/W04.html#full_join",
    "href": "lectures/W04.html#full_join",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "full_join()",
    "text": "full_join()\n\n\n\n\n\nfull_join(x, y)\n\n# A tibble: 4 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "lectures/W04.html#inner_join",
    "href": "lectures/W04.html#inner_join",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "inner_join()",
    "text": "inner_join()\n\n\n\n\n\ninner_join(x, y)\n\n# A tibble: 2 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2"
  },
  {
    "objectID": "lectures/W04.html#women-in-science",
    "href": "lectures/W04.html#women-in-science",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Women in science",
    "text": "Women in science\n\nleft_join()right_joinfull_joininner_joinFinal\n\n\n\nprofessions |&gt; left_join(works)\n\n# A tibble: 10 × 3\n   name               profession                         known_for              \n   &lt;chr&gt;              &lt;chr&gt;                              &lt;chr&gt;                  \n 1 Ada Lovelace       Mathematician                      first computer algorit…\n 2 Marie Curie        Physicist and Chemist              theory of radioactivit…\n 3 Janaki Ammal       Botanist                           hybrid species, biodiv…\n 4 Chien-Shiung Wu    Physicist                          confim and refine theo…\n 5 Katherine Johnson  Mathematician                      calculations of orbita…\n 6 Rosalind Franklin  Chemist                            &lt;NA&gt;                   \n 7 Vera Rubin         Astronomer                         existence of dark matt…\n 8 Gladys West        Mathematician                      mathematical modeling …\n 9 Flossie Wong-Staal Virologist and Molecular Biologist first scientist to clo…\n10 Jennifer Doudna    Biochemist                         one of the primary dev…\n\n\n\n\n\nprofessions |&gt; right_join(works)\n\n# A tibble: 9 × 3\n  name               profession                         known_for               \n  &lt;chr&gt;              &lt;chr&gt;                              &lt;chr&gt;                   \n1 Ada Lovelace       Mathematician                      first computer algorithm\n2 Marie Curie        Physicist and Chemist              theory of radioactivity…\n3 Janaki Ammal       Botanist                           hybrid species, biodive…\n4 Chien-Shiung Wu    Physicist                          confim and refine theor…\n5 Katherine Johnson  Mathematician                      calculations of orbital…\n6 Vera Rubin         Astronomer                         existence of dark matter\n7 Gladys West        Mathematician                      mathematical modeling o…\n8 Flossie Wong-Staal Virologist and Molecular Biologist first scientist to clon…\n9 Jennifer Doudna    Biochemist                         one of the primary deve…\n\n\n\n\n\ndates |&gt; full_join(works)\n\n# A tibble: 10 × 4\n   name               birth_year death_year known_for                           \n   &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                               \n 1 Janaki Ammal             1897       1984 hybrid species, biodiversity protec…\n 2 Chien-Shiung Wu          1912       1997 confim and refine theory of radioac…\n 3 Katherine Johnson        1918       2020 calculations of orbital mechanics c…\n 4 Rosalind Franklin        1920       1958 &lt;NA&gt;                                \n 5 Vera Rubin               1928       2016 existence of dark matter            \n 6 Gladys West              1930         NA mathematical modeling of the shape …\n 7 Flossie Wong-Staal       1947         NA first scientist to clone HIV and cr…\n 8 Jennifer Doudna          1964         NA one of the primary developers of CR…\n 9 Ada Lovelace               NA         NA first computer algorithm            \n10 Marie Curie                NA         NA theory of radioactivity,  discovery…\n\n\n\n\n\ndates |&gt; inner_join(works)\n\n# A tibble: 7 × 4\n  name               birth_year death_year known_for                            \n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                                \n1 Janaki Ammal             1897       1984 hybrid species, biodiversity protect…\n2 Chien-Shiung Wu          1912       1997 confim and refine theory of radioact…\n3 Katherine Johnson        1918       2020 calculations of orbital mechanics cr…\n4 Vera Rubin               1928       2016 existence of dark matter             \n5 Gladys West              1930         NA mathematical modeling of the shape o…\n6 Flossie Wong-Staal       1947         NA first scientist to clone HIV and cre…\n7 Jennifer Doudna          1964         NA one of the primary developers of CRI…\n\n\n\n\n\nprofessions |&gt; left_join(dates) |&gt; left_join(works)\n\n# A tibble: 10 × 5\n   name               profession                 birth_year death_year known_for\n   &lt;chr&gt;              &lt;chr&gt;                           &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    \n 1 Ada Lovelace       Mathematician                      NA         NA first co…\n 2 Marie Curie        Physicist and Chemist              NA         NA theory o…\n 3 Janaki Ammal       Botanist                         1897       1984 hybrid s…\n 4 Chien-Shiung Wu    Physicist                        1912       1997 confim a…\n 5 Katherine Johnson  Mathematician                    1918       2020 calculat…\n 6 Rosalind Franklin  Chemist                          1920       1958 &lt;NA&gt;     \n 7 Vera Rubin         Astronomer                       1928       2016 existenc…\n 8 Gladys West        Mathematician                    1930         NA mathemat…\n 9 Flossie Wong-Staal Virologist and Molecular …       1947         NA first sc…\n10 Jennifer Doudna    Biochemist                       1964         NA one of t…"
  },
  {
    "objectID": "lectures/W04.html#keys",
    "href": "lectures/W04.html#keys",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Keys",
    "text": "Keys\n\nA key is a variable or a set of variables which uniquely identifies observations\nWhat was the key in the dataframe of women in science? name\n\n\nSwitching back to nycflights13 as example\n\nIn simple cases, a single variable is sufficient to identify an observation, e.g. each plane in planes is identified by tailnum.\nSometimes, multiple variables are needed; e.g. to identify an observation in weather you need five variables: year, month, day, hour, and origin"
  },
  {
    "objectID": "lectures/W04.html#how-to-check-if-a-variable-is-a-key",
    "href": "lectures/W04.html#how-to-check-if-a-variable-is-a-key",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "How to check if a variable is a key?",
    "text": "How to check if a variable is a key?\nCounting observation and filter those more than one\n\nlibrary(nycflights13)\nplanes |&gt; count(tailnum) |&gt; filter(n &gt; 1)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: tailnum &lt;chr&gt;, n &lt;int&gt;\n\nweather |&gt; count(year, month, day, hour, origin) |&gt; filter(n &gt; 1)\n\n# A tibble: 3 × 6\n   year month   day  hour origin     n\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;int&gt;\n1  2013    11     3     1 EWR        2\n2  2013    11     3     1 JFK        2\n3  2013    11     3     1 LGA        2\n\n\nOK, here 3 observations are twice, one for each airport. Probably this is related to Daylight saving time in the US. In Fall clocks are turned back 1 hour. So this hour appears twice.\n\nExample: Without hour it is not a key\n\nweather |&gt; count(year, month, day, origin) |&gt; filter(n &gt; 1)\n\n# A tibble: 1,092 × 5\n    year month   day origin     n\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;int&gt;\n 1  2013     1     1 EWR       22\n 2  2013     1     1 JFK       22\n 3  2013     1     1 LGA       23\n 4  2013     1     2 EWR       24\n 5  2013     1     2 JFK       24\n 6  2013     1     2 LGA       24\n 7  2013     1     3 EWR       24\n 8  2013     1     3 JFK       24\n 9  2013     1     3 LGA       24\n10  2013     1     4 EWR       24\n# ℹ 1,082 more rows\n\n\nWhy do we have only 22 and 23 on day 1 of month 1? No idea. Dig deeper yourself!"
  },
  {
    "objectID": "lectures/W04.html#primary-and-foreign-keys",
    "href": "lectures/W04.html#primary-and-foreign-keys",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Primary and foreign keys",
    "text": "Primary and foreign keys\n\nA primary key uniquely identifies an observation in its own table. E.g, planes$tailnum in planes.\nA foreign key uniquely identifies an observation in another dataframe E.g. flights$tailnum is a foreign key in flights because it matches each flight to a unique plane in planes.\nA primary key and a foreign key form a relation.\n\nOften a 1-to-many relation. Each plane has many flights.\n\nImplication: Joining flights with planes duplicates the rows of planes for each flight of that plane.\n\n\nRelations can also be many-to-many. Airlines can fly to many airports; airport can host many airplanes."
  },
  {
    "objectID": "lectures/W04.html#joining-when-key-names-differ",
    "href": "lectures/W04.html#joining-when-key-names-differ",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Joining when key names differ?",
    "text": "Joining when key names differ?\nWe have to specify the key relation with a named vector in the by argument.\n\ndim(flights)\n\n[1] 336776     19\n\nflights |&gt; left_join(airports, by = c(\"dest\" = \"faa\"))\n\n# A tibble: 336,776 × 26\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 18 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, name &lt;chr&gt;, lat &lt;dbl&gt;,\n#   lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, dst &lt;chr&gt;, tzone &lt;chr&gt;\n\n\nThe alternative (new default) version is to use the join_by function using the comparison sign ==.\n\nflights |&gt; left_join(airports, join_by(\"dest\" == \"faa\"))\n\n# A tibble: 336,776 × 26\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 18 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, name &lt;chr&gt;, lat &lt;dbl&gt;,\n#   lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, dst &lt;chr&gt;, tzone &lt;chr&gt;\n\n\nWhy does the number of rows stays the same after joining?\n\nfaa is a primary key in airports. It is matched with dest as the foreign key in flights."
  },
  {
    "objectID": "lectures/W04.html#left_join-is-essentially-right_join-with-switched-dataframes",
    "href": "lectures/W04.html#left_join-is-essentially-right_join-with-switched-dataframes",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "left_join is essentially right_join with switched dataframes",
    "text": "left_join is essentially right_join with switched dataframes\n\nairports_right_flights &lt;- airports |&gt;\n  right_join(flights, by = c(\"faa\" = \"dest\"))\nairports_right_flights\n\n# A tibble: 336,776 × 26\n   faa   name       lat   lon   alt    tz dst   tzone  year month   day dep_time\n   &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;\n 1 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10     1     1955\n 2 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10     2     2010\n 3 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10     3     1955\n 4 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10     4     2017\n 5 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10     5     1959\n 6 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10     6     1959\n 7 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10     7     2002\n 8 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10     8     1957\n 9 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10     9     1957\n10 ABQ   Albuque…  35.0 -107.  5355    -7 A     Amer…  2013    10    10     2011\n# ℹ 336,766 more rows\n# ℹ 14 more variables: sched_dep_time &lt;int&gt;, dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;,\n#   sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,\n#   minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nDifferences\n\nIn a join where keys have different column names the name of the first dataframe survives (unless you use keep = TRUE). Here, faa survived instead of dest\nThe columns from the first dataframe come first\nThe order of rows is taken from the first dataframe, while duplication and dropping of variables is determined by the second dataframe (because it is a right_join)\n\nUsing the fact that flights seem to be ordered by year, month, day, dep_time we can re-arrange:\n\nairports_right_flights |&gt;\n  rename(dest = faa) |&gt;\n  select(names(flights)) |&gt; # Use order of flights\n  arrange(year, month, day, dep_time)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      924            917\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nNote of caution: A deeper analysis shows that the order is still not exactly the same."
  },
  {
    "objectID": "lectures/W04.html#left_join-with-reversed-dataframes",
    "href": "lectures/W04.html#left_join-with-reversed-dataframes",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "left_join with reversed dataframes",
    "text": "left_join with reversed dataframes\nLet us do this test to understand joins better\n\ndim(airports)\n\n[1] 1458    8\n\ndim(flights)\n\n[1] 336776     19\n\nairports |&gt;\n  left_join(flights, by = c(\"faa\" = \"dest\"))\n\n# A tibble: 330,531 × 26\n   faa   name      lat    lon   alt    tz dst   tzone  year month   day dep_time\n   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;\n 1 04G   Lansdo…  41.1  -80.6  1044    -5 A     Amer…    NA    NA    NA       NA\n 2 06A   Moton …  32.5  -85.7   264    -6 A     Amer…    NA    NA    NA       NA\n 3 06C   Schaum…  42.0  -88.1   801    -6 A     Amer…    NA    NA    NA       NA\n 4 06N   Randal…  41.4  -74.4   523    -5 A     Amer…    NA    NA    NA       NA\n 5 09J   Jekyll…  31.1  -81.4    11    -5 A     Amer…    NA    NA    NA       NA\n 6 0A9   Elizab…  36.4  -82.2  1593    -5 A     Amer…    NA    NA    NA       NA\n 7 0G6   Willia…  41.5  -84.5   730    -5 A     Amer…    NA    NA    NA       NA\n 8 0G7   Finger…  42.9  -76.8   492    -5 A     Amer…    NA    NA    NA       NA\n 9 0P2   Shoest…  39.8  -76.6  1000    -5 U     Amer…    NA    NA    NA       NA\n10 0S9   Jeffer…  48.1 -123.    108    -8 A     Amer…    NA    NA    NA       NA\n# ℹ 330,521 more rows\n# ℹ 14 more variables: sched_dep_time &lt;int&gt;, dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;,\n#   sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,\n#   minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nWe have much more rows in than in airports. However, we have less rows than when we flight |&gt; left_join(airports). Why?\nWhy does the number of rows changes after joining?\n\ndest is not a primary key in flights. There are more flights with the same destination so rows of airports get duplicated.\nWhy is the number of rows then less than the number of rows in flights?\n\n\n336776 flights and 330531 airports left joined by flights.\nLet us do some checks:\n\nlength(unique(airports$faa)) # Unique turns out to be redundant because faa is a primary key\n\n[1] 1458\n\nlength(unique(flights$dest))\n\n[1] 105\n\n\nThere are much more airports then destinations in flights!\n… but the rows of airports prevail when it is the first in a left_join.\nSo, the dataframe should even increase because we get several rows of airports without flights.\n\n\nLet us dig deeper.\n\nsetdiff(unique(airports$faa), unique(flights$dest)) |&gt; length()\n\n[1] 1357\n\nsetdiff(unique(flights$dest), unique(airports$faa)) |&gt; length()\n\n[1] 4\n\n\n1,357 airports have no flights!\nThere are four destinations in flights, which are not in the airports list!\nHow many flights are to these?\n\nflights |&gt;\n  filter(dest %in% setdiff(unique(flights$dest), unique(airports$faa))) |&gt;\n  nrow()\n\n[1] 7602\n\n\n7,602 flights go to destinations not listed as airport\n\nnrow(airports |&gt; left_join(flights, by = c(\"faa\" = \"dest\"))) ==\n  nrow(flights) + 1357 - 7602\n\n[1] TRUE\n\n\nOK, now we have a clear picture:\nairport with left_joined flights duplicates the rows of airports for each flight flying to it. So the total number of rows is\n\nthe number of flights\nplus the number of airport which do not appear as a destination\nminus the flights which go to destinations which are not listed in airports\n\nLearning: The new number of observation after a join can be a complex combination of duplication and dropping.\nIt is your responsibility to understand what is happening!"
  },
  {
    "objectID": "lectures/W04.html#definition-sets-and-vectors",
    "href": "lectures/W04.html#definition-sets-and-vectors",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Definition: Sets and vectors",
    "text": "Definition: Sets and vectors\nA set is mathematical model for the unordered collection of different things (elements).\nExamples\n\n\\(\\{3, \\text{Hi}, 😀, 🖖 \\}\\)\n\\(\\{1,3,5\\}\\)\nThe natural numbers \\(\\mathbb{N} = \\{1, 2, 3, \\dots\\}\\) (infinite!)\n\\(\\{\\mathtt{\"EWR\"}, \\mathtt{\"LGA\"}, \\mathtt{\"JFK\"}\\}\\)\nthese are origin airports in flights"
  },
  {
    "objectID": "lectures/W04.html#math-sets-and-vectors-1",
    "href": "lectures/W04.html#math-sets-and-vectors-1",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Math: Sets and vectors",
    "text": "Math: Sets and vectors\nA vector is an ordered collection of things (components) of the same type.\nIn a set, each thing can only be once and the order does not matter!\n\n\\(\\{1,3,5\\} = \\{3,5,1\\} = \\{1,1,1,3,5,5\\}\\)\nFor vectors:\n\\([1\\ 3\\ 5] \\neq [3\\ 5\\ 1]\\) because we compare component-wise, so we cannot even compare with those with the vector \\([1\\ 1\\ 1\\ 3\\ 5\\ 5]\\)"
  },
  {
    "objectID": "lectures/W04.html#math-set-operations",
    "href": "lectures/W04.html#math-set-operations",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Math: Set operations",
    "text": "Math: Set operations\nSets \\(A = \\{🐺, 🦊, 🐶\\}\\) and \\(B = \\{🐶, 🐷, 🐹\\}\\), \\(C = \\{🐶, 🐷\\}\\):\n\nSet union \\(A \\cup B\\) = {🐺, 🦊, 🐶, 🐷, 🐹}\n\\(x \\in A \\cup B\\) when \\(x \\in A\\) | (or) \\(x\\in B\\)\nSet intersection \\(A \\cap B\\) = {🐶}\n\\(x \\in A \\cap B\\) when \\(x \\in A\\) & (and) \\(x\\in B\\)\nSet difference \\(A \\setminus B = \\{🐺, 🦊\\}\\), \\(B \\setminus A\\) = {🐷, 🐹}\nSubset: \\(C \\subset B\\) but \\(C \\not\\subset A\\)\n\n\nSee the analogy of set operations and logical operations."
  },
  {
    "objectID": "lectures/W04.html#set-operations-in-r",
    "href": "lectures/W04.html#set-operations-in-r",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Set operations in R",
    "text": "Set operations in R\nunique shows the set of elements in a vector\n\nunique(flights$origin)\n\n[1] \"EWR\" \"LGA\" \"JFK\"\n\n\n\nsetequal tests for set equality\n\nsetequal(c(\"EWR\", \"LGA\", \"JFK\"), c(\"EWR\", \"EWR\", \"LGA\", \"JFK\"))\n\n[1] TRUE\n\n\n\n\nunion, intersect, setdiff treat vectors as sets and operate as expected\n\nunion(1:5, 3:7)\n\n[1] 1 2 3 4 5 6 7\n\nintersect(1:5, 3:7)\n\n[1] 3 4 5\n\nsetdiff(1:5, 3:7)\n\n[1] 1 2\n\n\nRelations to joins: full_join() is like the union, inner_join() is like the intersection."
  },
  {
    "objectID": "lectures/W04.html#sets-take-away",
    "href": "lectures/W04.html#sets-take-away",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Sets: Take-away",
    "text": "Sets: Take-away\n\nSet operations are not a daily business in data science\nHowever, they are useful for data exploration!\nKnowing set operations is key to understand probability:\n\nA sample space is the set of all atomic events.\nAn event is a subset of the sample space\nA probability function assigns probabilities to all events."
  },
  {
    "objectID": "lectures/W04.html#functions-mathematically",
    "href": "lectures/W04.html#functions-mathematically",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Functions mathematically",
    "text": "Functions mathematically\nConsider two sets: The domain \\(X\\) and the codomain \\(Y\\).\nA function \\(f\\) assigns each element of \\(X\\) to exactly one element of \\(Y\\).\n\n\nWe write \\(f : X \\to  Y\\)\n“\\(f\\) maps from \\(X\\) to \\(Y\\)”\nand \\(x \\mapsto f(x)\\)\n“\\(x\\) maps to \\(f(x)\\)”\nThe yellow set is called the image of \\(f\\).\n\n\n\n\n\nPicture from wikipedia."
  },
  {
    "objectID": "lectures/W04.html#conventions-in-mathematical-text",
    "href": "lectures/W04.html#conventions-in-mathematical-text",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Conventions in mathematical text",
    "text": "Conventions in mathematical text\n\nSets are denoted with capital letters.\nTheir elements with (corresponding) small letters.\nFunctions are often called \\(f\\), \\(g\\), or \\(h\\).\nOther terminology can be used!\n\n\nImportant in math\n\nWhen you read math:\nKeep track of what objects are! What are functions, what are sets, what are numbers, …1\nWhen you write math: Define what objects are.\n\n\nWatch: How to read math https://www.youtube.com/watch?v=Kp2bYWRQylk"
  },
  {
    "objectID": "lectures/W04.html#is-this-a-mathematical-function",
    "href": "lectures/W04.html#is-this-a-mathematical-function",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Is this a mathematical function?",
    "text": "Is this a mathematical function?\n \\(\\ \\mapsto\\ \\) \nInput from \\(X = \\{\\text{A picture where a face can be recognized}\\}\\).\nFunction: Upload input at https://funny.pho.to/lion/ and download output.\nOutput from \\(Y = \\{\\text{Set of pictures with a specific format.}\\}\\)\n\nYes, it is a function. Important: Output is the same for the same input!"
  },
  {
    "objectID": "lectures/W04.html#is-this-a-mathematical-function-1",
    "href": "lectures/W04.html#is-this-a-mathematical-function-1",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Is this a mathematical function?",
    "text": "Is this a mathematical function?\nInput a text snippet. Function: Enter text at https://www.craiyon.com. Output a picture.\n\n\n\n\nOther examples:\n\n“Nuclear explosion broccoli”\n“The Eye of Sauron reading a newspaper”\n“The legendary attack of Hamster Godzilla wearing a tiny Sombrero”\n\n  \n\n\nNo, it is not a function. It has nine outcomes and these change when run again. Same for answers of LLMs to the same prompt."
  },
  {
    "objectID": "lectures/W04.html#graphs-of-functions",
    "href": "lectures/W04.html#graphs-of-functions",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Graphs of functions",
    "text": "Graphs of functions\n\nA function is characterized by the set all possible pairs \\((x,f(x))\\).\nThis is called its graph.\nWhen domain and codomain are real numbers then the graph can be shown in a Cartesian coordinate system. Example \\(f(x) = x^3 - x^2\\)"
  },
  {
    "objectID": "lectures/W04.html#some-functions-f-mathbbr-to-mathbbr",
    "href": "lectures/W04.html#some-functions-f-mathbbr-to-mathbbr",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Some functions \\(f: \\mathbb{R} \\to \\mathbb{R}\\)",
    "text": "Some functions \\(f: \\mathbb{R} \\to \\mathbb{R}\\)\n\n\n\\(f(x) = x\\) identity function\n\\(f(x) = x^2\\) square function\n\\(f(x) = \\sqrt{x}\\) square root function\n\\(f(x) = e^x\\) exponential function\n\\(f(x) = \\log(x)\\) natural logarithm\n\nSquare and square root function are inverse of each other. Exponential and natural logarithm, too.\n\n\\(\\sqrt[2]{x}^2 = \\sqrt[2]{x^2} = x\\), \\(\\log(e^x) = e^{\\log(x)} = x\\)\n\nIdentity function graph as mirror axis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(e\\) is Euler’s number \\(2.71828\\dots\\). The natural logarithm is also often called \\(\\ln\\). The square root function is \\(\\mathbb{R}_{\\geq 0} \\to \\mathbb{R}\\), the logarithm \\(\\mathbb{R}_{&gt;0} \\to \\mathbb{R}\\)."
  },
  {
    "objectID": "lectures/W04.html#shifts-and-scales",
    "href": "lectures/W04.html#shifts-and-scales",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Shifts and scales",
    "text": "Shifts and scales\nHow can we shift, stretch, or shrink a graph vertically and horizontally?\n\n\n\\(y\\)-shift\\(x\\)-shift\\(y\\)-scale\\(x\\)-scale\n\n\n\n\nAdd a constant to the function.\n\\(f(x) = x^3 - x^2 \\leadsto\\)\n\\(\\quad f(x) = x^3 - x^2 + a\\)\nFor \\(a =\\) -2, -0.5, 0.5, 2\n\n\n\nCode\na = c(1, 0.5, 2, -0.5, -2)\nggplot() +\n  geom_function(fun = function(x) x^3 - x^2, size = 2, alpha = 0.5) +\n  geom_function(fun = function(x) x^3 - x^2 + a[2], color = \"blue4\", size = 2) +\n  geom_function(fun = function(x) x^3 - x^2 + a[3], color = \"blue\", size = 2) +\n  geom_function(fun = function(x) x^3 - x^2 + a[4], color = \"red4\") +\n  geom_function(fun = function(x) x^3 - x^2 + a[5], color = \"red\") +\n  coord_fixed() +\n  xlim(c(-3, 3)) +\n  ylim(c(-3, 3)) +\n  xlab(\"x\") +\n  theme_minimal(base_size = 24)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubtract a constant from all \\(x\\) within the function definition.\n\\(f(x) = x^3 - x^2 \\leadsto\\)\n\\(\\quad f(x) = (x - a)^3 - (x - a)^2\\)\nFor \\(a =\\) -2, -0.5, 0.5, 2\nAttention:\nShifting \\(a\\) units to the right needs subtracting \\(a\\)!\nYou can think of the coordinate system being shifted in direction \\(a\\) while the graph stays.\n\n\n\nCode\na = c(1, 0.5, 2, -0.5, -2)\nggplot() +\n  geom_function(fun = function(x) x^3 - x^2, size = 2, alpha = 0.5) +\n  geom_function(\n    fun = function(x) (x - a[2])^3 - (x - a[2])^2,\n    color = \"blue4\",\n    size = 2\n  ) +\n  geom_function(\n    fun = function(x) (x - a[3])^3 - (x - a[3])^2,\n    color = \"blue\",\n    size = 2\n  ) +\n  geom_function(fun = function(x) (x - a[4])^3 - (x - a[4])^2, color = \"red4\") +\n  geom_function(fun = function(x) (x - a[5])^3 - (x - a[5])^2, color = \"red\") +\n  coord_fixed() +\n  xlim(c(-3, 3)) +\n  ylim(c(-3, 3)) +\n  xlab(\"x\") +\n  theme_minimal(base_size = 24)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiply a constant to all \\(x\\) within the function definition.\n\\(f(x) = x^3 - x^2 \\leadsto\\)\n\\(\\quad f(x) = a(x^3 - x^2)\\)\nFor \\(a =\\) -2, -0.5, 0.5, 2\nNegative numbers flip the graph around the \\(x\\)-axis.\n\n\n\nCode\na = c(1, 0.5, 2, -0.5, -2)\nggplot() +\n  geom_function(fun = function(x) x^3 - x^2, size = 2, alpha = 0.5) +\n  geom_function(\n    fun = function(x) a[2] * ((x)^3 - (x)^2),\n    color = \"blue4\",\n    size = 2\n  ) +\n  geom_function(\n    fun = function(x) a[3] * ((x)^3 - (x)^2),\n    color = \"blue\",\n    size = 2\n  ) +\n  geom_function(fun = function(x) a[4] * ((x)^3 - (x)^2), color = \"red4\") +\n  geom_function(fun = function(x) a[5] * ((x)^3 - (x)^2), color = \"red\") +\n  coord_fixed() +\n  xlim(c(-3, 3)) +\n  ylim(c(-3, 3)) +\n  xlab(\"x\") +\n  theme_minimal(base_size = 24)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDivide all \\(x\\) within the function definition by a constant.\n\\(f(x) = x^3 - x^2 \\leadsto\\)\n\\(\\quad f(x) = (x/a)^3 - (x/a)^2\\)\nFor \\(a =\\) -2, -0.5, 0.5, 2\nNegative numbers flip the graph around the \\(y\\)-axis.\nAttention: Stretching needs a division by \\(a\\)!\nYou can think of the coordinate system being stretched multiplicatively by \\(a\\) while the graph stays.\n\n\n\nCode\na = c(1, 0.5, 2, -0.5, -2)\nggplot() +\n  geom_function(fun = function(x) x^3 - x^2, size = 2, alpha = 0.5) +\n  geom_function(\n    fun = function(x) (x / a[2])^3 - (x / a[2])^2,\n    color = \"blue4\",\n    size = 2\n  ) +\n  geom_function(\n    fun = function(x) (x / a[3])^3 - (x / a[3])^2,\n    color = \"blue\",\n    size = 2\n  ) +\n  geom_function(fun = function(x) (x / a[4])^3 - (x / a[4])^2, color = \"red4\") +\n  geom_function(fun = function(x) (x / a[5])^3 - (x / a[5])^2, color = \"red\") +\n  coord_fixed() +\n  xlim(c(-3, 3)) +\n  ylim(c(-3, 3)) +\n  xlab(\"x\") +\n  theme_minimal(base_size = 24)"
  },
  {
    "objectID": "lectures/W04.html#math-polynomials-and-exponentials",
    "href": "lectures/W04.html#math-polynomials-and-exponentials",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Math: Polynomials and exponentials",
    "text": "Math: Polynomials and exponentials\nA polynomial is a function which is composed of (many) addends of the form \\(ax^n\\) for different values of \\(a\\) and \\(n\\).\nIn an exponential the \\(x\\) appears in the exponent. \\(f(x) = x^2\\) vs. \\(f(x) = 2^x\\)\n\n\n\n\nCode\nggplot() +\n  geom_function(fun = function(x) x^2) +\n  geom_function(fun = function(x) 2^x - 1, color = \"red\") +\n  xlim(c(0, 1.5)) +\n  xlab(\"x\") +\n  theme_minimal(base_size = 24)\n\n\n\n\n\n\n\n\n\nNote: We use \\(f(x) = 2^x - 1\\) to have both functions start at (0,0).\n\nSame graph but for a larger range of \\(x\\):\n\n\nCode\nggplot() +\n  geom_function(fun = function(x) x^2) +\n  geom_function(fun = function(x) 2^x - 1, color = \"red\") +\n  xlim(c(0, 5)) +\n  xlab(\"x\") +\n  theme_minimal(base_size = 24)\n\n\n\n\n\n\n\n\n\n\n\nFor \\(x\\to\\infty\\), any exponential will finally “overtake” any polynomial."
  },
  {
    "objectID": "lectures/W04.html#input-to-output",
    "href": "lectures/W04.html#input-to-output",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Input \\(\\to\\) output",
    "text": "Input \\(\\to\\) output\n\n\nMetaphorically, a function is a machine or a blackbox that for each input yields an output.\nThe inputs of a function are also called arguments.\n\n\nDifference to math terminolgy:\nThe output need not be the same for the same input.\n\n\n\nPicture from wikipedia."
  },
  {
    "objectID": "lectures/W04.html#function-as-objects-in-r",
    "href": "lectures/W04.html#function-as-objects-in-r",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Function as objects in R",
    "text": "Function as objects in R\nfunction is a class of an object in R\n\nclass(c)\n\n[1] \"function\"\n\nclass(ggplot2::ggplot)\n\n[1] \"function\"\n\n\nCalling the function without brackets writes its code or some information.\n\nsd # This function is written in R, and we see its code\n\nfunction (x, na.rm = FALSE) \nsqrt(var(if (is.vector(x) || is.factor(x)) x else as.double(x), \n    na.rm = na.rm))\n&lt;bytecode: 0x5b1458f76288&gt;\n&lt;environment: namespace:stats&gt;\n\nc # This function is not written in R but is a R primitive\n\nfunction (...)  .Primitive(\"c\")\n\nggplot2::ggplot # This function is not written solely in R\n\nfunction (data = NULL, mapping = aes(), ..., environment = parent.frame()) \n{\n    UseMethod(\"ggplot\")\n}\n&lt;bytecode: 0x5b1459a25790&gt;\n&lt;environment: namespace:ggplot2&gt;"
  },
  {
    "objectID": "lectures/W04.html#define-your-own-functions-in-r",
    "href": "lectures/W04.html#define-your-own-functions-in-r",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Define your own functions! (in R)",
    "text": "Define your own functions! (in R)\n\nadd_one &lt;- function(x) {\n  x + 1\n}\n# Test it\nadd_one(10)\n\n[1] 11\n\n\nThe skeleton for a function definition is\nfunction_name &lt;- function(input){\n  # do something with the input(s)\n  # return something as output\n}\n\nfunction_name should be a short but evocative verb.\nThe input can be empty or one or more name or name=expression terms as arguments.\nThe last evaluated expression is returned as output.\nWhen the body or the function is only one line {} can be omitted. For example\nadd_one &lt;- function(x) x + 1"
  },
  {
    "objectID": "lectures/W04.html#flexibility-of-inputs-and-outputs",
    "href": "lectures/W04.html#flexibility-of-inputs-and-outputs",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Flexibility of inputs and outputs",
    "text": "Flexibility of inputs and outputs\n\nArguments can be specified by name=expression or just expression (then they are taken as the next argument)\nDefault values for arguments can be provided. Useful when an argument is a parameter.\n\n\n\nmymult &lt;- function(x = 2, y = 3) x * (y - 1)\nmymult(3, 4)\n\n\n[1] 9\n\n\n\n\nmymult()\n\n\n[1] 4\n\n\n\n\nmymult(y = 3, x = 6)\n\n\n[1] 12\n\n\n\n\nmymult(5)\n\n\n[1] 10\n\n\n\n\nmymult(y = 2)\n\n\n[1] 2\n\n\n\nFor complex output use a list\n\n\nmymult &lt;- function(x = 2, y = 3) {\n  list(out1 = x * (y - 1), out2 = x * (y - 2))\n}\nmymult()\n\n\n$out1\n[1] 4\n\n$out2\n[1] 2"
  },
  {
    "objectID": "lectures/W04.html#vectorized-functions",
    "href": "lectures/W04.html#vectorized-functions",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Vectorized functions",
    "text": "Vectorized functions\nMathematical functions in programming are often “vectorized”:\n\nOperations on a single value are applied to each component of the vector.\nOperations on two values are applied “component-wise” (for vectors of the same length)\n\n\nlog10(c(1, 10, 100, 1000, 10000))\n\n\n\n[1] 0 1 2 3 4\n\n\n\nc(1, 1, 2) + c(3, 1, 0)\n\n\n\n[1] 4 2 2\n\n\n\n(0:5)^2\n\n\n\n[1]  0  1  4  9 16 25"
  },
  {
    "objectID": "lectures/W04.html#recall-vector-creation-functions",
    "href": "lectures/W04.html#recall-vector-creation-functions",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Recall: Vector creation functions",
    "text": "Recall: Vector creation functions\n\n1:10\n\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nseq(from = -0.5, to = 1.5, by = 0.1)\n\n\n\n [1] -0.5 -0.4 -0.3 -0.2 -0.1  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9\n[16]  1.0  1.1  1.2  1.3  1.4  1.5\n\n\n\nseq(from = 0, to = 1, length.out = 10)\n\n\n\n [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n [8] 0.7777778 0.8888889 1.0000000\n\n\n\nrep(1:3, times = 3)\n\n\n\n[1] 1 2 3 1 2 3 1 2 3\n\n\n\nrep(1:3, each = 3)\n\n\n\n[1] 1 1 1 2 2 2 3 3 3"
  },
  {
    "objectID": "lectures/W04.html#plotting-and-transformation",
    "href": "lectures/W04.html#plotting-and-transformation",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Plotting and transformation",
    "text": "Plotting and transformation\nVector creation and vectorized functions are key for plotting and transformation.\n\nfunc &lt;- function(x) x^3 - x^2 # Create a vectorized function\ndata &lt;- tibble(x = seq(-0.5, 1.5, by = 0.01)) |&gt; # Vector creation\n  mutate(y = func(x)) # Vectorized transformation using the function\ndata |&gt; ggplot(aes(x, y)) + geom_line() + theme_minimal(base_size = 20)"
  },
  {
    "objectID": "lectures/W04.html#conveniently-ggploting-functions",
    "href": "lectures/W04.html#conveniently-ggploting-functions",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Conveniently ggploting functions",
    "text": "Conveniently ggploting functions\n\nggplot() +\n  geom_function(fun = log) +\n  geom_function(fun = function(x) 3 * x - 4, color = \"red\") +\n  theme_minimal(base_size = 20)\n\n\nCode line 3 shows another important concept: anonymous functions. The function function(x) 3*x - 4 is defined on the fly without a name."
  },
  {
    "objectID": "lectures/W04.html#conditional-statements",
    "href": "lectures/W04.html#conditional-statements",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Conditional statements",
    "text": "Conditional statements\n\nif executes a code block if a condition is TRUE\nelse executes a code block if the condition is FALSE\n\nSkeleton\nif (condition) {\n  # code block\n} else {\n  # code block\n}\nExample: A piece-wise defined function\n\n\n\npiecewise &lt;- function(x) {\n  if (x &lt; 2) {\n    0.5 * x\n  } else {\n    x - 1\n  }\n}\n\n\n\npiecewise(1)\n\n[1] 0.5\n\npiecewise(2)\n\n[1] 1\n\npiecewise(3)\n\n[1] 2\n\n\n\n\nProblem: piecewise is not vectorized. piecewise(c(1,2,3)) does not work!"
  },
  {
    "objectID": "lectures/W04.html#vectorized-operations-with-map",
    "href": "lectures/W04.html#vectorized-operations-with-map",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Vectorized operations with map",
    "text": "Vectorized operations with map\n\nmap functions apply a function to each element of a vector.1\nmap(.x, .f, ...) applies the function .f to each element of the vector of .x and returns a list.\nmap_dbl returns a double vector (other variants exist)\n\n\n\n\nmap(c(1, 2, 3), piecewise)\n\n[[1]]\n[1] 0.5\n\n[[2]]\n[1] 1\n\n[[3]]\n[1] 2\n\nmap_dbl(c(1, 2, 3), piecewise)\n\n[1] 0.5 1.0 2.0\n\npiecewise_vectorized &lt;-\n  function(x) map_dbl(x, piecewise)\n\n\n\npiecewise_vectorized(seq(0, 3, by = 0.5))\n\n[1] 0.00 0.25 0.50 0.75 1.00 1.50 2.00\n\ntibble(x = seq(0, 3, by = 0.5)) |&gt;\n  mutate(y = piecewise_vectorized(x)) |&gt;\n  ggplot(aes(x, y)) +\n  geom_line() +\n  theme_minimal(base_size = 20)\n\n\n\n\n\n\n\n\n\nIn tidyverse they are provided in the package purrr"
  },
  {
    "objectID": "lectures/W04.html#reduce",
    "href": "lectures/W04.html#reduce",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "reduce",
    "text": "reduce\nInstead of a list or a vector reduce returns a single value.\nTo that end it needs a function with two arguments. It applies it to the first two elements of the vector, then to the result and the third element, then the result and the fourth element, and so on.\n\n1:10 |&gt; reduce(\\(x, y) x + y)\n\n[1] 55\n\n\nNote: \\(x) is a short way to write an anonymous function as function(x).\n\nExample: Reading multiple files\n\n\nInstead of\na &lt;-read_csv(\"a.csv\")\nb &lt;-read_csv(\"b.csv\")\nc &lt;-read_csv(\"c.csv\")\nd &lt;-read_csv(\"d.csv\")\ne &lt;-read_csv(\"e.csv\")\nf &lt;-read_csv(\"f.csv\")\ng &lt;-read_csv(\"g.csv\")\n\nbind_rows(a,b,c,d,e,f,g)\n\nWrite\nletter[1:7] |&gt; \n map(\\(x) read_csv(paste0(x,\".csv\"))) |&gt; \n reduce(bind_rows)"
  },
  {
    "objectID": "lectures/W04.html#map-and-reduce",
    "href": "lectures/W04.html#map-and-reduce",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "map and reduce",
    "text": "map and reduce\n\nmap applies a function to each element of a vector (or list) and returns a list (or vector if map_dbl or other vaeriants are used)\n\nThe output has the same length as the input\n\nreduce applies a function taking two arguments and then summarizes the list by applying them two element 1 and 2 and then again the result with element 3 and then the result with element 4, …\n\nThe output is one object\n\nRemark: The problem of vectorizing a function which has an if and else statement (see the example piecewise_vectorized) can also be solved using the vectorized version of it:\nif_else(condition = *condition*, true = *value-if_TRUE*, false = *value-if_FALSE*)\nHere every argument can be a vector!"
  },
  {
    "objectID": "lectures/W04.html#function-programming-take-away",
    "href": "lectures/W04.html#function-programming-take-away",
    "title": "W#04: Relational Data, Math: Sets and Functions, Programming Functions",
    "section": "Function programming: Take away",
    "text": "Function programming: Take away\n\nFunctions are the most important building blocks of programming.\nFunctions can and often should be vectorized.\nVectorized functions are the basis for plotting and transformation.\nmap functions are powerful tools for iterative tasks!\nExpect to not get the idea first but to love them later."
  },
  {
    "objectID": "lectures/W02.html#let-us-walk-through-the-workflow",
    "href": "lectures/W02.html#let-us-walk-through-the-workflow",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Let us walk through the workflow",
    "text": "Let us walk through the workflow\nWe need the tidyverse packages\n\nlibrary(tidyverse)\n\nWe use the mpg dataset which is in the ggplot library. Let’s take a look:\n\nglimpse(mpg)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;chr&gt; \"auto(l5)\", \"manual(m5)\", \"manual(m6)\", \"auto(av)\", \"auto…\n$ drv          &lt;chr&gt; \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"4\", \"4\", \"4\", \"4\", \"4…\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;chr&gt; \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p…\n$ class        &lt;chr&gt; \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"c…"
  },
  {
    "objectID": "lectures/W02.html#use-mpg-for-more-information-about-mpg-dataset",
    "href": "lectures/W02.html#use-mpg-for-more-information-about-mpg-dataset",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Use ?mpg for more information about mpg dataset",
    "text": "Use ?mpg for more information about mpg dataset\n?mpg\nmpg                  package:ggplot2                   R Documentation\n\nFuel economy data from 1999 to 2008 for 38 popular models of cars\n\nDescription:\n\n     This dataset contains a subset of the fuel economy data that the\n     EPA makes available on &lt;https://fueleconomy.gov/&gt;. It contains\n     only models which had a new release every year between 1999 and\n     2008 - this was used as a proxy for the popularity of the car.\n\nUsage:\n\n     mpg\n     \nFormat:\n\n     A data frame with 234 rows and 11 variables:\n\n     manufacturer manufacturer name\n\n     model model name\n\n     displ engine displacement, in litres\n\n     year year of manufacture\n\n     cyl number of cylinders\n\n     trans type of transmission\n\n     drv the type of drive train, where f = front-wheel drive, r = rear\n          wheel drive, 4 = 4wd\n\n     cty city miles per gallon\n\n     hwy highway miles per gallon\n\n     fl fuel type\n\n     class \"type\" of car\n\n\nFor best learning, go through these slides and test the code!"
  },
  {
    "objectID": "lectures/W02.html#first-plot-in-a-basic-specification",
    "href": "lectures/W02.html#first-plot-in-a-basic-specification",
    "title": "W#02 Data Visualization Data Formats",
    "section": "First plot in a basic specification",
    "text": "First plot in a basic specification\nWe take cty = “city miles per gallon” as x and hwy = “highway miles per gallon” as y\n\nggplot(data = mpg) + geom_point(mapping = aes(x = cty, y = hwy))\n\n\nCompare to “The complete template” from the cheat sheet\nIt has all the required elements: We specify the data in the ggplot command, and the aesthetics (what variable is x and what variable is y) as mapping in the geom-function."
  },
  {
    "objectID": "lectures/W02.html#data-and-mapping-where",
    "href": "lectures/W02.html#data-and-mapping-where",
    "title": "W#02 Data Visualization Data Formats",
    "section": "data and mapping where?",
    "text": "data and mapping where?\nLooking at ?ggplot and ?geom_point we find that both need to specify data and mapping.\nWhy do we have it only once here?\nggplot(data = mpg) + geom_point(mapping = aes(x = cty, y = hwy))\n\n\nThe “+” in ggplot specifies that specifications will be taken from the object defined before the +.\nTechnically ggplot() creates an ggplot object (the graphic) and +geom_point() adds more information to it.\nSo, data was taken from the ggplot call, and mapping from geom_point"
  },
  {
    "objectID": "lectures/W02.html#it-also-works-this-way",
    "href": "lectures/W02.html#it-also-works-this-way",
    "title": "W#02 Data Visualization Data Formats",
    "section": "It also works this way",
    "text": "It also works this way\n\nggplot() + geom_point(data = mpg, mapping = aes(x = cty, y = hwy)) # Same output as before ...\n\n\n\nIn principle, we can specify new data and aesthetics in each geom-function in the same ggplot! Usually, we only have one dataset and one specification of aesthetics"
  },
  {
    "objectID": "lectures/W02.html#and-also-this-way",
    "href": "lectures/W02.html#and-also-this-way",
    "title": "W#02 Data Visualization Data Formats",
    "section": "And also this way",
    "text": "And also this way\n\nggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() # Same output as before ...\n\n\n\n\n\n\n\n\n\n\nThis is arguably the most common way."
  },
  {
    "objectID": "lectures/W02.html#even-shorter",
    "href": "lectures/W02.html#even-shorter",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Even shorter",
    "text": "Even shorter\nAs common practice we can shorten the code and remove the data = and the mapping = because the first argument will be taken as data (if not specified otherwise) and the second as mapping (if not specified otherwise). See function documentation ?ggplot\n\nggplot(mpg, aes(x = cty, y = hwy)) + geom_point() # Same output as before ..."
  },
  {
    "objectID": "lectures/W02.html#the-shortest",
    "href": "lectures/W02.html#the-shortest",
    "title": "W#02 Data Visualization Data Formats",
    "section": "The shortest",
    "text": "The shortest\nWe can even remove the “x =” and “y =” if we look at the specification of aes() in ?aes\n\nggplot(mpg, aes(cty, hwy)) + geom_point() # Same output as before ..."
  },
  {
    "objectID": "lectures/W02.html#testing-do-the-following-lines-work",
    "href": "lectures/W02.html#testing-do-the-following-lines-work",
    "title": "W#02 Data Visualization Data Formats",
    "section": "TESTING: Do the following lines work?",
    "text": "TESTING: Do the following lines work?\nIf not, why not? If yes, why?\nggplot(aes(x = cty, y = hwy), mpg) + geom_point()\nggplot(aes(x = cty, y = hwy), data = mpg) + geom_point()\nggplot(mapping = aes(x = cty, y = hwy)) + geom_point(mpg)\nggplot(aes(x = cty, y = hwy)) + geom_point(data = mpg)\nggplot(mpg,aes(hwy, x = cty)) + geom_point() \nggplot(mapping = aes(y = hwy, x = cty)) + geom_point(mpg) \n\nSolutions:\n1 No, data must be first\n2 Yes, with named argument data = works also as second argument\n3 No, data is missing\n4 No, aes() is take wrongly as data in ggplot\n5 Yes, x is specified with named argument, so the unnamed first argument is take as the second default argument\n6 No, in geom_point the first argument is mapping, so it must be aes()"
  },
  {
    "objectID": "lectures/W02.html#more-aesthetics",
    "href": "lectures/W02.html#more-aesthetics",
    "title": "W#02 Data Visualization Data Formats",
    "section": "More aesthetics",
    "text": "More aesthetics\ncolor, shape, size, fill …\nThese need to be specified by name and cannot be left out.\nLet us color the manufacturer, and make size by cylinders\n\nggplot(mpg, aes(cty, hwy, color = manufacturer, size = cyl)) + geom_point()"
  },
  {
    "objectID": "lectures/W02.html#do-you-like-the-plot",
    "href": "lectures/W02.html#do-you-like-the-plot",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Do you like the plot?",
    "text": "Do you like the plot?\nSome critique:\n\nToo many colors\nLooks like several points are in the same place but we do not see it.\nSizes look “unproportional” (4 is too small)"
  },
  {
    "objectID": "lectures/W02.html#effective-visualization-is-your-task",
    "href": "lectures/W02.html#effective-visualization-is-your-task",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Effective visualization is your task!",
    "text": "Effective visualization is your task!\n\nThe three problems are not technical problems of ggplot.\n\nThe grammar of graphics works fine.\nFinding effective visualization is a core skill for a data scientist.\nIt develops naturally with practice.\nIt needs programming skills, but the essence of it is not programming!"
  },
  {
    "objectID": "lectures/W02.html#work-with-scale_...-to-modify-aesthetics-look",
    "href": "lectures/W02.html#work-with-scale_...-to-modify-aesthetics-look",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Work with scale_... to modify aesthetic’s look",
    "text": "Work with scale_... to modify aesthetic’s look\nExample: Scale the size differently\n\nggplot(mpg, aes(cty, hwy, color = manufacturer, size = cyl)) +\n  geom_point() +\n  scale_size_area()"
  },
  {
    "objectID": "lectures/W02.html#check-overplotting-with-a-jitter",
    "href": "lectures/W02.html#check-overplotting-with-a-jitter",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Check overplotting with a jitter",
    "text": "Check overplotting with a jitter\n\nggplot(mpg, aes(cty, hwy)) + geom_point() + geom_jitter(color = \"green\")\n\n\nHere, we do two new things:\n\nWe added another geom-function to an existing one. That is a core idea of the grammar of graphics. (However, for a final version, we would probably not do geom_point together with geom_jitter.)\nWe specify the color by a word. Important: This is not within an aes() command!"
  },
  {
    "objectID": "lectures/W02.html#another-example-for-two-geoms",
    "href": "lectures/W02.html#another-example-for-two-geoms",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Another example for two geoms",
    "text": "Another example for two geoms\nAdd a smooth line as summary statistic\n\nggplot(mpg, aes(cty, hwy)) + geom_point() + geom_smooth()"
  },
  {
    "objectID": "lectures/W02.html#puzzle",
    "href": "lectures/W02.html#puzzle",
    "title": "W#02 Data Visualization Data Formats",
    "section": "PUZZLE",
    "text": "PUZZLE\nWhat happens here? Why does green become red???\n\nggplot(mpg, aes(cty, hwy, color = \"green\")) + geom_point() # Shows dots supposed to be \"green\" in red?\n\n\n\nThis is because “green” is taken here as a variable (with only one value for all data points).\nSo, “green” is not a color but a string and ggplot chooses color automatically.\n\n\nThis makes green points:\nggplot(mpg, aes(cty, hwy), color = \"green\") + geom_point()"
  },
  {
    "objectID": "lectures/W02.html#ggplot-objects",
    "href": "lectures/W02.html#ggplot-objects",
    "title": "W#02 Data Visualization Data Formats",
    "section": "ggplot-Objects",
    "text": "ggplot-Objects\n\nour_plot &lt;- ggplot(mpg, aes(cty, hwy)) + geom_point(aes(color = manufacturer))\n\nThis creates no output!\nThe graphic information is stored in the object our_plot."
  },
  {
    "objectID": "lectures/W02.html#call-the-object",
    "href": "lectures/W02.html#call-the-object",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Call the object",
    "text": "Call the object\nAs with other objects, when we write it in the console as such it provides an answer. In the case of ggplot-objects the answer is not some printed text in the console but a graphic output.\n\nour_plot"
  },
  {
    "objectID": "lectures/W02.html#ggplot-objects-altered-by-more",
    "href": "lectures/W02.html#ggplot-objects-altered-by-more",
    "title": "W#02 Data Visualization Data Formats",
    "section": "ggplot-Objects altered by more “+…”",
    "text": "ggplot-Objects altered by more “+…”\nExample\n\nour_plot + geom_smooth()"
  },
  {
    "objectID": "lectures/W02.html#coordinate-system-specification",
    "href": "lectures/W02.html#coordinate-system-specification",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Coordinate system specification",
    "text": "Coordinate system specification\nExample\n\nour_plot + coord_flip() # flip x and y"
  },
  {
    "objectID": "lectures/W02.html#coordinate-system-specification-1",
    "href": "lectures/W02.html#coordinate-system-specification-1",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Coordinate system specification",
    "text": "Coordinate system specification\nExample\n\nour_plot + coord_polar() # weird here but useful for some things"
  },
  {
    "objectID": "lectures/W02.html#faceting-based-on-another-variable",
    "href": "lectures/W02.html#faceting-based-on-another-variable",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Faceting based on another variable",
    "text": "Faceting based on another variable\nExample\n\nour_plot + facet_wrap(\"manufacturer\")"
  },
  {
    "objectID": "lectures/W02.html#faceting-based-on-two-other-variables",
    "href": "lectures/W02.html#faceting-based-on-two-other-variables",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Faceting based on two other variables",
    "text": "Faceting based on two other variables\nExample\n\nour_plot + facet_grid(cyl ~ fl) # fl is the fuel type"
  },
  {
    "objectID": "lectures/W02.html#scaling",
    "href": "lectures/W02.html#scaling",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Scaling",
    "text": "Scaling\nExample\n\nour_plot +\n  scale_x_log10() +\n  scale_y_reverse() +\n  scale_colour_hue(l = 70, c = 30)"
  },
  {
    "objectID": "lectures/W02.html#axis-limits-and-labels",
    "href": "lectures/W02.html#axis-limits-and-labels",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Axis limits and labels",
    "text": "Axis limits and labels\nExample\n\nour_plot +\n  xlim(c(0, 40)) +\n  xlab(\"City miles per gallon\") +\n  ylab(\"Highway miles per gallon\")"
  },
  {
    "objectID": "lectures/W02.html#themes",
    "href": "lectures/W02.html#themes",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Themes",
    "text": "Themes\nExample\n\nour_plot + theme_bw()"
  },
  {
    "objectID": "lectures/W02.html#themes-1",
    "href": "lectures/W02.html#themes-1",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Themes",
    "text": "Themes\nExample\n\nour_plot + theme_void()"
  },
  {
    "objectID": "lectures/W02.html#themes-2",
    "href": "lectures/W02.html#themes-2",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Themes",
    "text": "Themes\nExample\n\nour_plot + theme_dark()"
  },
  {
    "objectID": "lectures/W02.html#let-us-test-coercion",
    "href": "lectures/W02.html#let-us-test-coercion",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Let us test coercion",
    "text": "Let us test coercion\n\nx &lt;- TRUE\ny &lt;- 2L\nz &lt;- 3\na &lt;- \"4\"\n\n\n\nc(x, y)\n\n\n[1] 1 2\n\n\n\n\nc(y, z) |&gt; typeof()\n\n\n[1] \"double\"\n\n\n\n\nc(z, a)\n\n\n[1] \"3\" \"4\"\n\n\n\n\nc(x, a)\n\n\n[1] \"TRUE\" \"4\"   \n\n\n\n\nc(c(x, y), a)\n\n\n[1] \"1\" \"2\" \"4\"\n\n\n\n\nx + y\n\n\n[1] 3\n\n\n\n\nas.numeric(a)\n\n\n[1] 4\n\n\n\n\nx == 1\n\n\n[1] TRUE\n\n\n\n\nas.character(y)\n\n\n[1] \"2\"\n\n\nWhat about\nz + a\n\nNot possible, because stings cannot be added."
  },
  {
    "objectID": "lectures/W02.html#danger-floating-point-numbers",
    "href": "lectures/W02.html#danger-floating-point-numbers",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Danger! Floating point numbers",
    "text": "Danger! Floating point numbers\nWe define a and b such that their are both 0.1 mathematically.\n\na &lt;- 0.1 + 0.2 - 0.2\na\n\n[1] 0.1\n\n\n\nb &lt;- 0.1\nb\n\n[1] 0.1\n\n\nBut why is this false?\n\n(a - b) == 0\n\n[1] FALSE\n\n\n\n\na - b\n\n[1] 2.775558e-17\n\n\nAha, the difference is about \\(2.8 \\times 10^{-17}\\) (The e stands for scientific notation, learn to read it!) Such problems can happen when subtracting and comparing floating point numbers!"
  },
  {
    "objectID": "lectures/W02.html#tidying",
    "href": "lectures/W02.html#tidying",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Tidying",
    "text": "Tidying\nWhat is tidy depends to some extent on the purpose you want to use the data for.\nLet us practice the two important commands\npivot_longer\npivot_wider"
  },
  {
    "objectID": "lectures/W02.html#pivot_longer",
    "href": "lectures/W02.html#pivot_longer",
    "title": "W#02 Data Visualization Data Formats",
    "section": "pivot_longer",
    "text": "pivot_longer\n\ndata_wide &lt;- tibble(\n  id = 1:3,\n  height_2023 = c(150, 160, 170),\n  height_2024 = c(152, 162, 172)\n)\ndata_wide\n\n# A tibble: 3 × 3\n     id height_2023 height_2024\n  &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1     1         150         152\n2     2         160         162\n3     3         170         172\n\n\n\ndata_longer &lt;- pivot_longer(\n  data = data_wide,\n  cols = c(height_2023, height_2024),\n  names_to = \"year\",\n  values_to = \"height\"\n)\ndata_longer\n\n# A tibble: 6 × 3\n     id year        height\n  &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n1     1 height_2023    150\n2     1 height_2024    152\n3     2 height_2023    160\n4     2 height_2024    162\n5     3 height_2023    170\n6     3 height_2024    172"
  },
  {
    "objectID": "lectures/W02.html#input-the-pipe",
    "href": "lectures/W02.html#input-the-pipe",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Input: The pipe |>",
    "text": "Input: The pipe |&gt;\nIn data wrangling it is common to do various data manipulations one after the other.\nA common tool is to use the pipe to give it an ordered structure in the writing.\nThe basic idea is:\nPut what is before the pipe |&gt; as the first argument of the function coming after.\nWhen do_this is a function and to_this is an object like a dataframe then\ndo_this(to_this)\n```R\n\nis the same as \n```R\nto_this |&gt; do_this()\n\nIt also works for longer nested functions:\nfunction3(function2(function1(data)))\nis the same as\ndata |&gt; function1() |&gt; function2() |&gt; function3()"
  },
  {
    "objectID": "lectures/W02.html#with-the-pipe",
    "href": "lectures/W02.html#with-the-pipe",
    "title": "W#02 Data Visualization Data Formats",
    "section": "With the pipe",
    "text": "With the pipe\n\n\n# A tibble: 6 × 3\n     id year        height\n  &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n1     1 height_2023    150\n2     1 height_2024    152\n3     2 height_2023    160\n4     2 height_2024    162\n5     3 height_2023    170\n6     3 height_2024    172\n\n\n\nyear does not look good! We want numbers.\n\n\nLet’s do a string mutate:\n\ndata_longer &lt;- data_longer |&gt;\n  mutate(year = str_remove(year, \"height_\"))\ndata_longer\n\n# A tibble: 6 × 3\n     id year  height\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n1     1 2023     150\n2     1 2024     152\n3     2 2023     160\n4     2 2024     162\n5     3 2023     170\n6     3 2024     172"
  },
  {
    "objectID": "lectures/W02.html#but-year-still-a-character-variable",
    "href": "lectures/W02.html#but-year-still-a-character-variable",
    "title": "W#02 Data Visualization Data Formats",
    "section": "But year still a character variable!",
    "text": "But year still a character variable!\nWe mutate further:\n\ndata_longer &lt;- data_longer |&gt;\n  mutate(year = as.numeric(year))\ndata_longer\n\n# A tibble: 6 × 3\n     id  year height\n  &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     1  2023    150\n2     1  2024    152\n3     2  2023    160\n4     2  2024    162\n5     3  2023    170\n6     3  2024    172\n\n\nThat is fine."
  },
  {
    "objectID": "lectures/W02.html#back-to-wide-pivot_wider",
    "href": "lectures/W02.html#back-to-wide-pivot_wider",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Back to wide: pivot_wider",
    "text": "Back to wide: pivot_wider\n\ndata_longer |&gt;\n  pivot_wider(names_from = year, values_from = height)\n\n# A tibble: 3 × 3\n     id `2023` `2024`\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     1    150    152\n2     2    160    162\n3     3    170    172\n\n\n\nOK, but now we have just numbers as variable names. Can we get height_ prefix back?\n\n\n\ndata_longer |&gt;\n  pivot_wider(names_from = year, values_from = height, names_prefix = \"height_\")\n\n# A tibble: 3 × 3\n     id height_2023 height_2024\n  &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1     1         150         152\n2     2         160         162\n3     3         170         172"
  },
  {
    "objectID": "lectures/W02.html#summary-piping-and-tidying",
    "href": "lectures/W02.html#summary-piping-and-tidying",
    "title": "W#02 Data Visualization Data Formats",
    "section": "Summary piping and tidying",
    "text": "Summary piping and tidying\nA small data science task often boils down to one line of code using pipes like\ndata |&gt; wrangling_functions(*specifications*) |&gt; tidying(*to_bring_in_shape*) |&gt; ggpplot()\n(For R it is one line, but we may break it into several for a better overview.)\n\nPiping is a natural way of thinking in data science, so we also program that way.\nTidying (for example pivot_longer) is often needed directly before a ggplot command.\nTidying often require some string manipulations making new variables and variable names nice.\n\n\nHow can I learn all this? Practice, practice, practice, …\nDo I need to learn it again for python?? Yes, but it is easier knowing the concept!\n\n\nWhen learning, learn the concept not just get the code done!"
  },
  {
    "objectID": "material/M05.html",
    "href": "material/M05.html",
    "title": "W#05",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself. Work on the Homework Projects reach out for help if you get stuck.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#05"
    ]
  },
  {
    "objectID": "material/M05.html#descriptive-statistics-exploratory-data-analysis",
    "href": "material/M05.html#descriptive-statistics-exploratory-data-analysis",
    "title": "W#05",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself. Work on the Homework Projects reach out for help if you get stuck.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#05"
    ]
  },
  {
    "objectID": "material/M05.html#lecture-material",
    "href": "material/M05.html#lecture-material",
    "title": "W#05",
    "section": "1 Lecture Material",
    "text": "1 Lecture Material\nSlides: Direct Link\n\nFind the live recording in the Course’s Team’s Recording Folder.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#05"
    ]
  },
  {
    "objectID": "material/M05.html#additional-readings-and-material",
    "href": "material/M05.html#additional-readings-and-material",
    "title": "W#05",
    "section": "2 Additional Readings and Material",
    "text": "2 Additional Readings and Material\nLeek, Jeffery T., and Peng, Roger D. 2015. “What Is the Question?” Science 347 (6228): 1314–15. https://doi.org/10.1126/science.aaa6146.\nRead the following sections in R for Data Science\n\nCh 10: Exploratory Data Analysis",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#05"
    ]
  },
  {
    "objectID": "material/M05.html#achievements",
    "href": "material/M05.html#achievements",
    "title": "W#05",
    "section": "3 Achievements",
    "text": "3 Achievements\nYou\n\ncan compute and interpret the mean, median, variance, and standard deviation of a vector of numbers\ncan create and interpret histogram plots\ncan compute and interpret quantiles of a data set\ncan create and interpret boxplots\ncan compute and interpret the correlation between two vectors of numbers\nyou have done a first exploratory data analysis and have a first feeling of why it is not a fully standardized process\nyou can classify data science research questions according to the six types of questions of Leek and Peng (2015)",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#05"
    ]
  },
  {
    "objectID": "material/M05.html#homework-projects-progress-guides",
    "href": "material/M05.html#homework-projects-progress-guides",
    "title": "W#05",
    "section": "4 Homework Projects Progress Guides",
    "text": "4 Homework Projects Progress Guides\nFind the Repositories of your Homework Projects in the Course’s GitHub-Organization’s CU-F25-MDSSB-01-Concepts-Tools &gt; Repositories.\nProject’s INSTRUCTIONS you should have completed:\nProject_NYCFlights: 1., 2., 3., 4. 5., 6., 7. (This is an open question to practice exploratory data analysis.)\nProject_COVID19: 1.1, 1.2, 1.3, 1.4, 1.5, 2.1\n\n\n\n\n\n\nNote\n\n\n\nDon’t panic, if you fell behind, just do it later. Find your own learning path. Better step by step than randomly skipping things. It is about learning not just completing!",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#05"
    ]
  },
  {
    "objectID": "material/M03.html",
    "href": "material/M03.html",
    "title": "W#03",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself. Work on the Homework Projects reach out for help if you get stuck.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#03"
    ]
  },
  {
    "objectID": "material/M03.html#data-import-data-wrangling",
    "href": "material/M03.html#data-import-data-wrangling",
    "title": "W#03",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself. Work on the Homework Projects reach out for help if you get stuck.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#03"
    ]
  },
  {
    "objectID": "material/M03.html#lecture-material",
    "href": "material/M03.html#lecture-material",
    "title": "W#03",
    "section": "1 Lecture Material",
    "text": "1 Lecture Material\nSlides: Direct Link\n\nFind the live recording in the Course’s Team’s Recording Folder.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#03"
    ]
  },
  {
    "objectID": "material/M03.html#additional-readings-and-material",
    "href": "material/M03.html#additional-readings-and-material",
    "title": "W#03",
    "section": "2 Additional Readings and Material",
    "text": "2 Additional Readings and Material\nThe following sections in R for Data Science\n\nCh 3: Data transformation\nCh 5: Tidy Data\nCh 7: Data Import",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#03"
    ]
  },
  {
    "objectID": "material/M03.html#achievements",
    "href": "material/M03.html#achievements",
    "title": "W#03",
    "section": "3 Achievements",
    "text": "3 Achievements\nYou\n\nhave read in a csv-file, you can interpret the output of column type guessing, and use it to adjust and correct it for your needs if necessary\ncan take a statement with a pipe operator and translate it into a nested function call without the pipe operator (and the other way round)\nyou have used the dplyr functions select, slice, and filter\nyou understood the concept of logical indexing, vectorized logical operation (in particular AND, OR, and NOT), and how it relates to filtering data\nyou know if R or python is 0- or 1-indexed and what this means\nyou have used the dplyr functions distinct, and arrange\nyou understood how you use mutate and summarize to gather with the .by = specification (or group_by) to create new variables and data frames with aggregated data\nyou know about the practical importance of the special data types factor and date",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#03"
    ]
  },
  {
    "objectID": "material/M03.html#homework-projects-progress-guides",
    "href": "material/M03.html#homework-projects-progress-guides",
    "title": "W#03",
    "section": "4 Homework Projects Progress Guides",
    "text": "4 Homework Projects Progress Guides\nFind the Repositories of your Homework Projects in the Course’s GitHub-Organization’s CU-F25-MDSSB-01-Concepts-Tools &gt; Repositories.\nProject’s INSTRUCTIONS you should have completed:\nProject_NYCFlights: 1., 2., 3., 4. 5., 6.\nProject_COVID19: 1.1 and 1.2\n\n\n\n\n\n\nNote\n\n\n\nDon’t panic, if you fell behind, just do it later. Find your own learning path. Better step by step than randomly skipping things. It is about learning not just completing!",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#03"
    ]
  },
  {
    "objectID": "material/M01.html",
    "href": "material/M01.html",
    "title": "W#01",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#01"
    ]
  },
  {
    "objectID": "material/M01.html#what-is-data-science",
    "href": "material/M01.html#what-is-data-science",
    "title": "W#01",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#01"
    ]
  },
  {
    "objectID": "material/M01.html#lecture-material",
    "href": "material/M01.html#lecture-material",
    "title": "W#01",
    "section": "1 Lecture Material",
    "text": "1 Lecture Material\nSlides: Direct Link\n\nFind the live recording in the Course’s Team’s Recording Folder.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#01"
    ]
  },
  {
    "objectID": "material/M01.html#additional-readings-and-material",
    "href": "material/M01.html#additional-readings-and-material",
    "title": "W#01",
    "section": "2 Additional Readings and Material",
    "text": "2 Additional Readings and Material\n\nQuarto: Watch https://www.youtube.com/watch?v=_f3latmOhew from Mine Çetinkaya-Rundel (co-developer of quarto, R for Data Science, datasciencebox).\nR: Read the following sections in R for Data Science\n\nIntroduction\nWhole Game (the outline of the part)",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#01"
    ]
  },
  {
    "objectID": "material/M01.html#achievements",
    "href": "material/M01.html#achievements",
    "title": "W#01",
    "section": "3 Achievements",
    "text": "3 Achievements\nYou\n\nhave read the Syllabus and understood the course organization and the relations between Data Science Concepts and Data Science Tools\nhave a running R with Positron installation on you computer and can check all marks on the Checklist Technical Setup\nhave done the git-GitHub dance and know what the tools are in principle\nhave rendered quarto documents and understood its idea\nhave made your first steps with R\nhave filled out the Data Science Profile Survey",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#01"
    ]
  },
  {
    "objectID": "material/M01.html#homework-projects-progress-guides",
    "href": "material/M01.html#homework-projects-progress-guides",
    "title": "W#01",
    "section": "4 Homework Projects Progress Guides",
    "text": "4 Homework Projects Progress Guides\nFind the Repositories of your Homework Projects in the Course’s GitHub-Organization’s CU-F25-MDSSB-01-Concepts-Tools &gt; Repositories.\nProject’s INSTRUCTIONS you should have completed:\nProject_NYCFlights: 1. (one successful step of the git-GitHub-dance)\n\n\n\n\n\n\nNote\n\n\n\nDon’t panic, if you fell behind, just do it later. Find your own learning path. Better step by step than randomly skipping things. It is about learning not just completing!",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#01"
    ]
  },
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "Learning Resources",
    "section": "",
    "text": "All the materials here are freely accessible, many are community standards. The Schedule might refer to specific sections in these materials.",
    "crumbs": [
      "Syllabus",
      "Learning Resources"
    ]
  },
  {
    "objectID": "literature.html#r",
    "href": "literature.html#r",
    "title": "Learning Resources",
    "section": "1 R",
    "text": "1 R\n\nR for Data Science (2nd Edition) https://r4ds.hadley.nz// by Hadley Wickham, Garrett Grolemand, Mine Çetinkaya-Rundel and the R data science community around is our core resource for self-learning data science with R using tidyverse tools.\nTidy Modeling with R https://www.tmwr.org/ by Max Kuhn and Julia Silge is the resource for learning to work with tidymodels building upon the tidyverse tools.\nPart of the course builds on or be inspired by material in Data Science in the Box https://datasciencebox.org/ by Mine Çetinkaya-Rundel and the data science education community around. You can also use the website for accompanying self-study on selected topics.",
    "crumbs": [
      "Syllabus",
      "Learning Resources"
    ]
  },
  {
    "objectID": "literature.html#python",
    "href": "literature.html#python",
    "title": "Learning Resources",
    "section": "2 python",
    "text": "2 python\n\nPython Data Science Handbook https://jakevdp.github.io/PythonDataScienceHandbook/ by Jake VanderPlas is a core resource for data science with python. Also there is a good video playlist https://www.youtube.com/playlist?list=PLWKjhJtqVAbkmRvnFmOd4KhDdlK1oIq23 and a 4-hour “full-course” video https://youtu.be/rfscVS0vtbw.",
    "crumbs": [
      "Syllabus",
      "Learning Resources"
    ]
  },
  {
    "objectID": "literature.html#data-visualization",
    "href": "literature.html#data-visualization",
    "title": "Learning Resources",
    "section": "3 Data Visualization",
    "text": "3 Data Visualization\nggplot2: Elegant Graphics for Data Analysis https://ggplot2-book.org is a resource on understanding the logic of ggplot better.\nA great source for Graphic Design with ggplot2: https://rstudio-conf-2022.github.io/ggplot2-graphic-design/. Look at the Introduction to see what cool things are possible. Work through Concepts of the ggplot2 Package Pt. 1 and Concepts of the ggplot2 Package Pt. 2 for a full introduction to all of ggplot2.\nWebsites on how to decide for what visualization to choose:\nhttps://www.data-to-viz.com/\nhttps://datavizcatalogue.com/search.html",
    "crumbs": [
      "Syllabus",
      "Learning Resources"
    ]
  },
  {
    "objectID": "literature.html#mathematics",
    "href": "literature.html#mathematics",
    "title": "Learning Resources",
    "section": "4 Mathematics",
    "text": "4 Mathematics\nA video on how to read math https://www.youtube.com/watch?v=Kp2bYWRQylk. Essential to start reading text including math.\nAs a data scientist it is necessary to be able to delve into mathematical concepts in some depth. It is not necessary to become a mathematician and proof theorems. A lot can be learned when needed using short videos, wikipedia, and practice and play using your favorite programming environment. However, it makes sense to have an accessible text books to look up and learn some topics in a more systematic way.\nThe Open Intro project and their partner programs provide such math textbooks for free (you may need to “buy” the pdf of 0 EUR or a donation of your choice).\n\nStudy Pre-Calculus to refresh your basic math skill on functions including polynomials; root, radical, and power function, and exponential and logarithmic functions.\nGain the basic concepts of Calculus including limits, derivatives, and integrals.\nGain the basic concepts of Linear Algebra and how to read and understand matrix-language. Linear models, PCA and many other data science tools are most systematically understood using matrix language. On linear algebra this is a good video resource about the essence of linear algebra: https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab.\n\nFor Probability Theory the open textbook for the course Probability for Data Science is very useful.",
    "crumbs": [
      "Syllabus",
      "Learning Resources"
    ]
  },
  {
    "objectID": "literature.html#statistics",
    "href": "literature.html#statistics",
    "title": "Learning Resources",
    "section": "5 Statistics",
    "text": "5 Statistics\nSome statisticians say that data science is statistics. There is some truth in it. However, data science is more than statistics and statiscics has a certain view point. To get a deeper understanding of it is useful to study data science concepts through the lense of statistics.\nThe Open Intro project also provide good open and free statistics textbooks.\nMany concepts in data science can be described as statistical learning. A core and very accessible resource for it is\nAn Introduction to Statistical Learning which provides a version with code in R as well as in python.",
    "crumbs": [
      "Syllabus",
      "Learning Resources"
    ]
  },
  {
    "objectID": "literature.html#project-based-learning",
    "href": "literature.html#project-based-learning",
    "title": "Learning Resources",
    "section": "6 Project-based learning",
    "text": "6 Project-based learning\nProject-based learning (especially in programming) means to learn things by reproducing a project (or make your own project in a very similar way). This is a resource for various projects in various languages: https://github.com/practical-tutorials/project-based-learning/tree/master",
    "crumbs": [
      "Syllabus",
      "Learning Resources"
    ]
  },
  {
    "objectID": "literature.html#the-art-of-data-science",
    "href": "literature.html#the-art-of-data-science",
    "title": "Learning Resources",
    "section": "7 The Art of Data Science",
    "text": "7 The Art of Data Science\nThe Art of Data Science https://bookdown.org/rdpeng/artofdatascience/ is a great resource for learning about the process of data science and how to communicate about it.",
    "crumbs": [
      "Syllabus",
      "Learning Resources"
    ]
  },
  {
    "objectID": "final.html",
    "href": "final.html",
    "title": "Final Project",
    "section": "",
    "text": "Caution\n\n\n\nProject check-in starts in the second half of the semester! Before there is no need to register or contact instructors on your project teams or ideas. However, you can start thinking about it and read the guidelines below.\nThese are specifications and guidelines for the final Data Science Project and the Project report, the assessment for the Data Science Tools (see Syllabus): How to write it, when and how to deliver it, and how it will be graded.",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#how-to-write-a-project-report-in-a-nutshell",
    "href": "final.html#how-to-write-a-project-report-in-a-nutshell",
    "title": "Final Project",
    "section": "1 How to write a project report in a nutshell",
    "text": "1 How to write a project report in a nutshell\n\nYou find a team,\n\npick a dataset,\nregister your project,\ndo some interesting question-driven data analysis with it,\npresent a draft version at the end of the semester, and\nwrite up a well-structured and nicely formatted report about the analysis in your team’s repository.",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#work-in-teams-and-register-your-project",
    "href": "final.html#work-in-teams-and-register-your-project",
    "title": "Final Project",
    "section": "2 Work in Teams and Register your Project",
    "text": "2 Work in Teams and Register your Project\nProjects should be done in teams of 2-3 students. This serves two additional learning goals:\n\nLearning to pursue and coordinate data science workflows collaboratively.\nLearning to work collaboratively on code with git and GitHub.\n\nSingle teams and teams with more the 3 members are possible upon request when there are reasons for it.\n\n\n\n\n\n\nThe team’s work is graded as one piece.\n\n\n\n\n\nAll members receive the same grade for it. However, the module grade can be different because of the bonus for fully complete homework. A dysfunctional team can be split upon request by individual members.\n\n\n\nHow to form a team and register your project:\n\nForm a team on your own with fellow students.\nGo through this guidelines together.\n\nFind a suitable dataset (see below).\nCome up with a few initial questions.\nAll team members should write to the instructors.\n\nOne member should write to the Jan Lorenz and Armin Müller and provide\n\nall names of the team members,\ninformation about the dataset,\nthe initial questions, and\na short working title for the repository name.\n\nAll other members should write to the instructors for confirmation.",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#advice-for-data-science-team-work-with-git",
    "href": "final.html#advice-for-data-science-team-work-with-git",
    "title": "Final Project",
    "section": "3 Advice for data science team work (with git)",
    "text": "3 Advice for data science team work (with git)\n\nSelect your language R or python!\nPut the data you need into a folder data. For large data sets better not to commit and push it, but to document where the data can be retrieved and where it should be put to load it with your code.\n\nAll team members need to clone the repository to their local computers.\nTry both:\n\nWorking together at the same time with realtime communction.\nWorking together remotely based on a plan who should do what. Feel free to use GitHub issues in your repository for this!\n\nEvery team member should finally have pushed some work to GitHub!\nCommit early and often! Then we can help you when you have questions or need directions.\nBefore you start to work as a team member: Always do git pull first to receive potentially new content!\nTry to finish an individual work session with comments on next steps and open questions. Push the files in a state such that it renders.\nConflicts in git: Git conflicts will probably occur when you work in teams while pulling and pushing. These can be solved. If you do not manage, ask for help.\nConflicts in the team. Please communicate about tensions in your team and try to solve them. However, you are not obliged to finish your project as a dysfunctional team. To avoid being bound to the same grade in a dysfunctional team, every team member has the right to leave the team and continue independently. This can only be realized upon prior communication with team members and consequently with the instructors!",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#delivery",
    "href": "final.html#delivery",
    "title": "Final Project",
    "section": "4 Delivery",
    "text": "4 Delivery\n\nDelivery is via GitHub in a private repository (the same way as Homework Projects).\nThe repository for the final project will be created in the CU-F25-MDSSB-01-Concepts-Tools by the instructors upon team and project approval.\nThe source file as well as the rendered html-file should be included.\nThe assessment will start after the deadline with the latest commit.\nAssessment will be done based on reading the HTML-file. Additionally and if necessary, the Quarto Markdown File and other provided files may be looked at. Ideally, the HTML-Report is sufficient to assess the project! (To test if the HTML file looks good for the instructors do the following: Clone the repository anew to a temporaty directory on your computer, open the HTML file from this newly cloned directory. Check if it looks good. This is what instructors will do.)",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#deadline",
    "href": "final.html#deadline",
    "title": "Final Project",
    "section": "5 Deadline",
    "text": "5 Deadline\nSee Schedule",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#grading",
    "href": "final.html#grading",
    "title": "Final Project",
    "section": "6 Grading",
    "text": "6 Grading\n\nThe reports will be graded jointly by the instructor of Data Science Tools and Data Science Concepts.\n\nThe presentation in class is informal and will not be graded.\nAll team members receive the same grade for the project report. In case of a dysfunctional team, members can leave or split the team upon prior communication with the team and the instructors.\n\nAssessment rubric\nProject reports can be quite different depending on the data used and the type of question(s) (Descriptive, Exploratory, Inferential, Predictive, Causal, Mechanistic). Therefore, there will not be a fixed rubric. We will communicate back the final percentage grade (compare Constructor University’s Grading Table. Additionally, we aim to give short textual feedback about strong and weak points.\nNevertheless, the assessment goes along some criteria with some approximate weights:\n\nIntroduction/Questions (10%)\nData Handling/Preparation (10%)\nModeling (20%)\nComprehensiveness/Visualizations (20%)\nResults/Conclusion (20%)\nProgramming style (10%)\nDocument Structure and Layout (10%)",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#how-to-define-a-project",
    "href": "final.html#how-to-define-a-project",
    "title": "Final Project",
    "section": "7 How to define a project?",
    "text": "7 How to define a project?\nPart of the work is to define a good project for question-driven data analysis.\nEssentially there are two approaches to coming to a project setup:\n\nFind and select data that interests you, do some question-driven data exploration, and focus and narrow the question.\nStart with a question and search data to answer it.\n\nYou can build on topics and datasets of the Homework.",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#guidelines-for-drafting-your-project",
    "href": "final.html#guidelines-for-drafting-your-project",
    "title": "Final Project",
    "section": "8 Guidelines for drafting your project",
    "text": "8 Guidelines for drafting your project\n\nFind a manageable dataset: at least 50 cases (rows), good is 10-20 variables (columns) with a mix of categorical and numeric. Deviations are allowed based on your interest and capability.\nGo through the visualizations, statistics, and models we had in lectures and homework and think if similar things would be interesting.\nThe goal is not an exhaustive data analysis with every method! Do not calculate every statistic and procedure you have learned for every variable, but rather show that you can ask meaningful questions and answer them with results of data analysis and proficient interpretation and presentation of the results.\nDo NOT blindly do all visualization and all statistics on all variables in the data set! You may do that in your data exploration. But not all exploratory data analysis goes into your report. At some point, you have to focus on what is needed to answer your questions. Your report is not a documentation of all your exploratory steps. Throw out what is not needed anymore, improve the remaining visualizations, and explain well in the text what you want to communicate.\nA single high-quality visualization that shows a point clearly will receive a much higher appreciation than a large number of poor-quality visualizations without an explanation of what they should communicate.",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#making-your-project-public",
    "href": "final.html#making-your-project-public",
    "title": "Final Project",
    "section": "9 Making your project public",
    "text": "9 Making your project public\nBy default, project repositories are private and only visible to team members and instructors. The repositories can be made public such that students can use it as part of their portfolio, for example for referring to it in applications for internships and student jobs. Please let the instructors know if you want to make the repository public.\nAdditionally, the HTML file can be made accessible directly as a webpage with a few tweaks from quarto using the service of GitHub Pages. See the documentation.",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#frequently-asked-questions-may-be-extended",
    "href": "final.html#frequently-asked-questions-may-be-extended",
    "title": "Final Project",
    "section": "10 Frequently Asked Questions (may be extended)",
    "text": "10 Frequently Asked Questions (may be extended)\n\nDo we need to stick to methods and visualizations treated in lectures?\nNo, you are invited to use other data analysis and visualization methods (from other courses or packages which you self-learn)! We are happy to give advice if we can.\nAre we only allowed to use one dataset?\nNo, you can also merge data from different sources. This is a more challenging project because the data wrangling work would be a bit more. If your question calls for it we encourage you to use another data source. The additional effort will be recognized.",
    "crumbs": [
      "Syllabus",
      "Final Project"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Important\n\n\n\nRoom Change! Come to SH-229 Video Conference in South Hall from Sep 29 on!\n\n\n\n\n\n\n\n\nDeveloping Schedule\n\n\n\n\n\nThe schedule will be continuously updated also with additional readings, homework, lecture slides, and achievement check lists.\n\n\n\n\nTabular Schedule\nDate format MM-DD (month-day) (09-05 is Sep, 5)\nData Science Tools is Thursdays. First meeting: 09-04.\nData Science Concepts is Mondays. First meeting: 09-08.\n\n\n\nWeek\nDates Concepts\nConcepts Topics\nDates Tools\nTools Topic\n\n\n\n\n1\n09-01\nNo class, Academic Opening\n09-04\nR\n\n\n2\n09-08\nW#1 What is Data Science?\n09-11\nR\n\n\n3\n09-15\nW#2 Data Visualization, Data Formats\n09-18\nR\n\n\n4\n09-22\nW#3 Data Import, Data Wrangling\n09-25\nR\n\n\n5\n09-29\nRoom Change! Come to SH-229 Video Conference in South Hall from now on!  W#4 Relational Data, Math: Sets and Functions, Shift-Scale Transformation, Function Programming\n10-02\nR\n\n\n6\n10-06\nW#5 Descriptive Statistics, Exploratory Data Analysis\n10-09\nR\n\n\n7\n10-13\nW#6 Principal Component Analysis, Math: Exponentiations and Logarithms, Epidemic Modeling, Calculus\n10-16\nR\n\n\n8\n10-20\nW#07 Models in Science, Linear Model, Interaction Effects, Nonlinear Models\n10-23\npython\n\n\n9\n10-27\nW#08 Predicting Categorical Variables, Logistic Regression, Classification Problems\n10-30\npython\n\n\n10\n11-03\nFinal Projects Info Hypothesis Testing, Classification and Regression with Decision Trees, Overfitting\n11-06\npython\n\n\n11\n11-10\nW#10 Overfitting, Clustering Algorithms\n11-13\npython\n\n\n12\n11-17\nW#11 Collaborative Git, Bootstrapping, Cross validation, Bias-Variance Tradeoff\n11-20\npython\n\n\n13\n11-24\nW#12 Probability, Random Variables, Probability Distributions, Central Limit Theorem\n11-27\npython / R\n\n\n14\n12-01\nNo Class Exam Preparation with a Mock Exam\n12-04\nStudent projects\n\n\nExtra\n12-08\nQ&A Session before the exam\n\n\n\n\nExam\ntbd\nThe exam takes place as an online exam in the date range marked in the academic calendar (to be scheduled by admin)\n\n\n\n\nProject\n\nDeadline for submission of the Final Project marked in the academic calendar\n\n\n\n\n\n\n2025\n\n\n\n\n2nd  Exam\n\nThose who fail the exam and those who are officially excused can sit in the second exam end of January 2025.  Date range marked in the academic calendar (to be scheduled by admin)",
    "crumbs": [
      "Syllabus",
      "Schedule"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "",
    "text": "Important\n\n\n\nRoom Change! Come to SH-229 Video Conference in South Hall from Sep 29 on!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#module-names",
    "href": "index.html#module-names",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "1 Module Names",
    "text": "1 Module Names\nThis syllabus is for two modules which require each other.\n\nMDSSB-DSOC-02 Data Science Concepts (Core area, 5 credits)\nMDSSB-MET-01 Data Science Tools (Methods area, 5 credits)\n\nOffered in the Master program: Data Science for Society and Business (DSSB). See the module description in the DSSB Handbook.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#module-components",
    "href": "index.html#module-components",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "2 Module Components",
    "text": "2 Module Components\n\nData Science Concepts (5 Credits)\nData Science Tools in R (2.5 credits)\nData Science Tools in python (2.5 credits)\n\nAll are courses offered in the Fall term and have no entry requirement.\nData Science Concepts and Data Science Tools are co-requirements.\nThe Concepts treated in the lectures are applied in exercises and homework in the Tools course.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#class-meeting-information",
    "href": "index.html#class-meeting-information",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "3 Class Meeting Information",
    "text": "3 Class Meeting Information\nData Science Concepts:\nMon 9:45 - 11:00\nMon 11:15 - 12:30\nLocation: Room Change! SH-229 Video Conference in South Hall from Sep 29 on! in-person\nVideo streaming and recording in Microsoft Teams is provided for late-arriving students: Team F25_MDSSB-DSOC-02_Data Science Concepts, General Channel\nData Science Tools:\nThu 9:45 - 11:00\nThu 11:15 - 12:30\nLocation: see campusnet in-person\nVideo streaming and recording in Microsoft Teams is provided for late-arriving students. Coordinates tba, you should also find them in Teams\nNote: The R and python courses are provided in the same time slot. Details in the schedule.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "4 Instructors",
    "text": "4 Instructors\nConcepts: Jan Lorenz Email: jlorenz@constructor.univeristy\nTools in R and python:\nArmin Müller Email: armmueller@constructor.university\nStudent Assistants:\nMatvei Trifanov Email: mtrifanov@constructor.university\nMustafa Ansari Email: muansari@constructor.university",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#format-and-workload",
    "href": "index.html#format-and-workload",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "5 Format and Workload",
    "text": "5 Format and Workload\nConcepts: Lectures, sometimes with aspects of Tutorials (35 hours in presence, total expected workload 125 hours)\nTools: Tutorials, sometimes with aspects of Lectures (35 hours in presence, total expected workload 125 hours)\nBesides homework, both modules require a decent amount of self-study.\nWorkload homework and self-study is expect to be 90/125 = 72% of the total workload.\nHomework assignments are given along the concepts treated in Concepts to be solved with the tools treated in Tools.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#intended-learning-outcomes",
    "href": "index.html#intended-learning-outcomes",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "6 Intended Learning Outcomes",
    "text": "6 Intended Learning Outcomes\nThe module descriptions can be found in the DSSB Handbook.\n\n6.1 From the handbook\nBy the end of the Concepts module, you will be able to:\n\nunderstand and use the mathematical foundations of statistical learning algorithms\nexplain and classify data science problems\nexplain and classify data-driven approaches\nunderstand the application of data science techniques to typical situations and tasks in business and societal research, including the search, retrieval, preparation, and statistical analysis of data\ninterpret complexity analysis and performance evaluation of data science problems and algorithms\n\nBy the end of the Tools module, you will be able to:\n\nexplain basic concepts of imperative and object-oriented programming\nwrite, test, and debug programs\nperform data handling and data manipulation tasks in R and Python\napply your knowledge to implement own functions in R and Python\neffectively use core packages and libraries of R and Python for data analysis\nknow about the typical applications of R and Python in data science\nimplement and apply advanced data mining methods with appropriate tools\nperform a full cycle of data analysis\n\n\n\n6.2 Main Learning Goal\nOur main goal to help you build a good basis for your more and more independent work in the whole study program. That means you can\n\nlearn core concepts in data science on your own, for example\n\nconcepts to explore data (import, wrangle, visualize)\nlearn and explore mathematics and statistics through the data science lens\nlearn concepts to model and draw conclusions from data (model, infer, predict)\n\ncreate and maintain a digital working environment on your computer to do data science\nlearn to program in the data science languages R and python, and become able to learn new skills in these independently\ndo a data science project of your own interest",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#examination-and-assessment",
    "href": "index.html#examination-and-assessment",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "7 Examination and Assessment",
    "text": "7 Examination and Assessment\n\n\n\n\n\n\nFor students of DSSB (online)\n\n\n\n\n\nThese information does NOT apply for you, check your handbook.\n\n\n\n\n7.1 Concepts Module\nAssessment Type: Written Examination\nDuration: 120 min\nWeight: 100%\nScope: All intended learning outcomes of the module.\nCompletion: to pass this module, the examination has to be passed with at least 45%\nAn exam will take place after all lectures in December. The date will be published by the university adminstration later.\nThere are no additional achievements necessary and there are no bonus options.\n\n\n7.2 Tools Module\nModule achievement: 50% of the assignments correctly solved\nProgramming and analysis assignments will appear step by step during the courses as Homework Projects.\nTo pass the module you have to solve half of them by the end of the semester.\nAssessment Type: Project Report\nLength: 4000 - 5000 words (This is a guideline, not a strict rule! Content counts, we will not count words.)\nWeight: 100%\nScope: All intended learning outcomes of the module.\nMore information of project formats and grading rubric: Final Projects\nBonus option: Students receive 0.33 points grade improvements on their project grade on the numerical grade as specified in the Grading Table when all assignments are solved by the end of the semester. (Note, the bonus is not necessary to reach the best grade in the module.)\nAll assignments and the final project must be delivered in personalized repositories in the GitHub organization.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#module-policies",
    "href": "index.html#module-policies",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "8 Module Policies",
    "text": "8 Module Policies\nThere are no formal requirement about attendance and active participation. However, we rely on your engagement in a many-facted way including:\n\nPreparation (looking at readings and material before and after class, being informed about syllabus and course material)\nFocus (avoid distraction during in class and self-learning activities)\nPresence (listening and responding during group activities)\nAsking questions (in class, out of class, online, offline, when you get stuck conclude by writing a question)\nSpecificity (being as specific as possible when describing your problem or question)\nSynthesizing (making connections between concepts from reading and discussion)\nPersistence (you don’t need to understand everything immediately, but stay engaged, try again, confusion shows that you pay attention)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#academic-integrity",
    "href": "index.html#academic-integrity",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "9 Academic Integrity",
    "text": "9 Academic Integrity\nAll involved parties (professors and lecturers, instructors and students) are expected to abide by the word and spirit of the “Code of Academic Integrity”. Violations of the Code might be brought to the attention of the Academic Integrity Committee.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#artifical-intelligence-ai-use-policy",
    "href": "index.html#artifical-intelligence-ai-use-policy",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "10 Artifical Intelligence (AI) Use Policy",
    "text": "10 Artifical Intelligence (AI) Use Policy\nThis policy covers any generative AI tool, such as ChatGPT, Elicit, Gemini, Claude, CoPilot, etc. This includes text, code, slides, artwork/graphics/video/audio and other products.\nWe instructors encourage exploring AI tools for these purposes:\n\nLearning by dialog with a chatbot. AI chatbots can be helpful to explain you concepts on your desired level and get a feeling about how topics are treated. You can ask for an easier or more detailed explanation or focus on certain aspects. Note: The capabilities are limited and you likely receive also false information! An AI chat can be a good entry point to learn about a specific topic but the more specific it gets the more likely it is that AI will start to deliver useless or wrong answers. Using chatbots should remain a small part of your learning process. Rule of thumb: Spend not more than 25% of the learning time with chatting with AI. There is no way around reading textbooks, reading software documentation, learning and understanding concepts, searching for help online, asking instructors or fellow students.\nHave code snippets written. Tools like GitHub Copilot can be a great help in coding! Try them, many coders do it. Maybe the GitHub Copilot is stil free to use for students and teachers who join GitHub Education), they can be integrated in your programming IDE like RStudio and VSCode. Copilots can speed up writing. However, they may deliver bad code. There is no way around understanding yourself what code is doing! Do not spend endless hours asking for new code with new prompts, spend time understanding a language and the functions and objects you are using! AI chatbots and Copilots can also help you to understand code. Copilots can be a great help to get a skeleton of code and an idea how your solution might look. They rarely deliver the complete code. Expect that the code does not work, expect that the code seems to works but the results are wrong! You are 100% accountable for the code you produce, with or without the help of a copilot! When a task in a Homework project can be well solved by Copilot we are happy if you drop us a note, same when it is totally off, it is interesting to explore what AI can do well and what not.\nHave a draft text snippet written. I do not recommend to use AI for writing. Writing is to a large extent thinking and this is important. It is not “forbidden” to use AI for writing. However, you are 100% accountable for the text you deliver. You are expected to know what your text is about and to be able to answer questions about what your text means! With text generated purely by chatbots, it is often evident for us that students do not understand. We consider such cases worse than incomplete but sensible self-written text. Text written by chatbots is often very generic and not specific. In general, we value more specific text higher than generic text. Generic text is considered worse than specific self-written text.\n\nNote: Philosophical and legal questions around the training and use of chatbots and code copilots are controversially contested and re-examined constantly! We encourage to engage with such questions and become aware of arguments and debates.\nIf any part of this AI policy is confusing or uncertain, please reach out to us for a conversation before submitting your work.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#schedule-and-homework",
    "href": "index.html#schedule-and-homework",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "11 Schedule and Homework",
    "text": "11 Schedule and Homework\nThe Schedule is on an extra page and will be updated continuously with\n\nLinks to slides\nWhat homework you are expected to do\nSome questions which you should be able to answer after each week.\n\nRead about the concepts of our Homework Projects.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#feedback-from-students",
    "href": "index.html#feedback-from-students",
    "title": "Data Science Concepts / Data Science Tools",
    "section": "12 Feedback from Students",
    "text": "12 Feedback from Students\nWe are eager to constantly improve the quality of our teaching. We would be glad to obtain your feedback at any time of the course to improve your learning experience.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Checklist Technical Setup",
    "section": "",
    "text": "I have made a GitHub account and submitted it\nI have installed R\nI have installed git\nI have installed positron\nI have tested that R runs in positron\nI have installed the tidyverse package in R\nIf any of this does not work, read the details below and try to solve it. Many problems will depend on specific things of your operating system. Many problems may be easy once you got what the problem is. Some maybe harder. If it does not work, write to the instructors or assistants (Teams chat or email) describing exactly what you have done and where you get stuck. A clear and specific description of the problem is essential for getting help!",
    "crumbs": [
      "Syllabus",
      "Checklist Technical Setup"
    ]
  },
  {
    "objectID": "setup.html#details",
    "href": "setup.html#details",
    "title": "Checklist Technical Setup",
    "section": "Details",
    "text": "Details\nYou need a GitHub account and become member of the GitHub Organization: CU-F25-MDSSB-01-Concepts-Tools of the course. Follow the instructions on the linked page of the organization. - You need a computer with Windows, MacOS, or Linux (maybe also other exotic operating systems). A tablet, phone or Chromebook is probably not sufficient. - You need to install software on your computer. Here is what you need including links where to download and find instructions for you operating system: - Statistical Programming Language: R, later we will alos use python. Instructions will come in class. - Version Control System: Git - Integrated Development Environments (IDE): The instructors uses positron. All instructions will be based on this. In the past the instructors used RStudio. Positron is developed by the same people and is somehow its modern version.\nWhen R, Git, positron are installed, open positron and test that everything works together:\n\nIs R running? On the top right you should see the R-symbol and its version numbers. That should be your current session. If not click on it, maybe it lists a python session or Start Session. Then a Select Interpreter Session dialog should pop up and you can start a new one and find R. If R is not offered solve this first by finding out how Positron can find the R installation. Usually it is detected automatically.\nAnother check: Go the CONSOLE tab (usually at the bottom). Scroll to the beginning. It should start with something like R 4.5.1 started. At the end of the console you should see a &gt;-prompt. Type version and hit ENTER. You should see the version of printed.\nDo you have access to the tidyverse? In R, you will use packages in the package family tidyverse. You can install it by running install.packages(\"tidyverse\") in the CONSOLE.\nDo git and quarto run from the TERMINAL? Go to the TERMINAL tab besides the CONSOLE. Type git --version and hit ENTER. You should see the version of git printed. Then type quarto --version and hit ENTER. You should see the version of quarto printed.\nNote: You can also write R and hit ENTER. You start an R session in the Terminal. We do not need it, so type q() and ENTER to leave R again. (No need to save the workspace, just hit ENTER again if asked.)\n\nLearning: Understand the difference between the CONSOLE and the TERMINAL! Both are command line interfaces (CLI).\n\nThe CONSOLE is for R commands in the current session in positron.\nThe TERMINAL is for system commands. It is also called SHELL (or also Console …, but that is confusing here). It also works outside of positron. You can control your whole computer using the TERMINAL. It does not start with a simple &gt; but first with a name of your machine and then with the current working directory. Working directory means where in your file system the computer will operate your next command. We the command line tools mainly for git and quarto. For both we will also use short cuts and convenient click and point interfaces in positron. But it is important to understand what happens in the background and that you can always use the TERMINAL directly for all the things of git and quarto.",
    "crumbs": [
      "Syllabus",
      "Checklist Technical Setup"
    ]
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "Homework Projects",
    "section": "",
    "text": "Homework Projects are essential for mastering the Data Science Concets and Tools courses!\n\n\n\nRead the following to understand its purpose, format, workflow, and its role in the assessment. Start right a way to work on homework projects! That’s doing data science.",
    "crumbs": [
      "Syllabus",
      "Homework Projects"
    ]
  },
  {
    "objectID": "homework.html#homework-projects-list",
    "href": "homework.html#homework-projects-list",
    "title": "Homework Projects",
    "section": "1 Homework Projects List",
    "text": "1 Homework Projects List\nAs a registered student, you will find personalized repositories for your Homework Projects in the GitHub-Organization. These projects will appear here once they are deployed:\n\n\n\nPlease read the next sections.",
    "crumbs": [
      "Syllabus",
      "Homework Projects"
    ]
  },
  {
    "objectID": "homework.html#purpose",
    "href": "homework.html#purpose",
    "title": "Homework Projects",
    "section": "2 Purpose",
    "text": "2 Purpose\nYou learn to\n\nunderstand and answer data science questions\napply data science concepts and use the basic data science skills\n\nimporting data\ntidying data\ntransforming data\nvisualizing data\napplying models for different purposes like\n\ndescribing, exploring, and predicting data\nunderstanding the data generating process\ninferring insights about the world from data\n\n\ndelve into a certain domain with each project\ndevelop, ask, and answer your own data science questions\ncommunicate your results and insights in a reproducible way with quarto\ncreate a professionally looking Project Report for each Homework Project\nget into the basics of version control with git and GitHub",
    "crumbs": [
      "Syllabus",
      "Homework Projects"
    ]
  },
  {
    "objectID": "homework.html#format",
    "href": "homework.html#format",
    "title": "Homework Projects",
    "section": "3 Format",
    "text": "3 Format\nA Homework Project is a mix of a simple Homework Assignment to apply what you just learned and a fully fledged Data Science Project.\nYou work on projects towards milestones. All projects require some data import, some tidying of data, some exploratory data analysis with visualizations and computations of summary statistics. You will start with basic things as first milestones in more than one project. You do not need to finish one project after the other but you pick up work on some projects again when you learned new methods. Homework Projects and Milestones will be provided along the course. Finally, a Homework Project develop towards a readable Project Report on a certain topic.\nTask of the Homework can range from\n\nguided tasks to learn basic things, over\ntasks to answer a particular data science question (where you choose analysis, visualization and other output yourself), to\nopen tasks where you formulate data science questions yourself.",
    "crumbs": [
      "Syllabus",
      "Homework Projects"
    ]
  },
  {
    "objectID": "homework.html#technical-setup-the-data-science-process-in-practice",
    "href": "homework.html#technical-setup-the-data-science-process-in-practice",
    "title": "Homework Projects",
    "section": "4 Technical Setup: The data science process in practice!",
    "text": "4 Technical Setup: The data science process in practice!\n\n\n\n\n\n\nNeeded infrastructure\n\n\n\n\n\nOn your computer:\n\nA terminal as Command Line Interface (CLI) where you can run git, quarto, R, and python3\nIntegrated Development Environments (IDE): For R and python we use positron, for python you may also use VS Code. When well configured, you have a termin and can run git and quarto within the IDE.\n\nIn the cloud:\n\nBe registered in Data Science Concepts and Data Science Tools at Constructor University\nHave a GitHub account\nHave your GitHub user registered as a member of the GitHub-Organization\n\n\n\n\n\nHomework Projects are git-repositories hosted on GitHub in the GitHub-Organization of the courses.\n\nEvery registered student receives one individual repository for each project. Only the student and the instructors can see these repositories. You need to become a member of the GitHub-Organization!\nThe Tasks and Questions for the project are written in the README.md file in each project repository.\nWorkflow for each project repository:\n\ngit clone the Project Repository to your local computer\nWork and the Project’s main quarto markdown document (.qmd-file)\nWhat does working on the project document mean?\n\nYou structure the markdown document with headlines\nYou draft plain markdown text to explain what you analyze or report your results\nYou write code chunks either for loading packages, importing data and computations, or for producing visualizations and tables in the output document\nWhile you do this you work a lot using the programming console in which you execute part of your written code to test it or modify it to explore other options until you develop something which goes into your file\n\n(Sometimes/Optionally) Create an additional script-file, for example for downloading data, or performing lengthy calculation and creating intermediate datasets.\nquarto render the main Project’s quarto markdown document and create a HTML-file with your Project Report (Guide for postitron)\nYou repeat step 2.-4. and repeatedly check if your (local) HTML-output looks good. You repeat until you are done for the session. Ideally, you leave the document such that it renders well and with a short list of problems to solve and next steps to do.\n\ngit add your (intermediate) markdown file, your additional scripts, the HTML-file, and (if necessary) all additional automatically created files or directories necessary to view the report properly to the git staging area of your repository on your computer\nCreate a git commit of the (intermediate) state of your project and\ngit push the commit to the remote repository at http://github.com/ such that it can be viewed by the instructors\nRepeat steps 2.-8. until your Project Report reaches a Milestone or is final and end with a commit with commit message “Milestone 1” (or other number), or “Final”.\n\n\nOrganization Advise: Create a folder for all projects on your computer. In this folder you will have all the subfolders created by the cloning of the project repositories.",
    "crumbs": [
      "Syllabus",
      "Homework Projects"
    ]
  },
  {
    "objectID": "homework.html#assessment",
    "href": "homework.html#assessment",
    "title": "Homework Projects",
    "section": "5 Assessment",
    "text": "5 Assessment\nHomework Projects are mostly for your learning! Use them as that.\nNevertheless, they also play a role in the assessment of the Module “Data Science Tools” in the following forms:\n\nSome tasks are requirements. You need to have solved more than 50% of these required tasks correctly to be eligible to pass the module! The percentage does not affect the grade, it is a requirement.\nWhen you solve 100% of the required tasks you can receive a bonus of 0.33 for your grade.\n\nThe grade of the Module “Data Science Tools” is made for your final project. This can depart and build on topics and data of Homework Projects.\nWhatever the data and topic for your final project will be, it is assumed to have the same format as a Homework Project: A private repository provided by the instructors.\nThe Module “Data Science Concepts” is assessed with an exam. It does not rely on the Homework Projects. However, some examples in the exam maybe relate to content of Homework Projects, so familiarity with Homework content will be of help.",
    "crumbs": [
      "Syllabus",
      "Homework Projects"
    ]
  },
  {
    "objectID": "homework.html#feedback",
    "href": "homework.html#feedback",
    "title": "Homework Projects",
    "section": "6 Feedback",
    "text": "6 Feedback\nTogether with teaching assistant the instructors will try to give feedback on your work.\nThe preferred way is via GitHub Issues. An Issues-Section is part of every repository. They are used to organize collaborative work and organize user interaction. You can also use issues for yourself as a project-specific To-Do-List.\nInstructors and Teaching Assistants may use Issues to give you some feedback on the current state of your work in the project.\nIf you require feedback:\n\nFile an issue and describe on what you need feedback or help as specific as possible.\nPoint the instructors to your issue.",
    "crumbs": [
      "Syllabus",
      "Homework Projects"
    ]
  },
  {
    "objectID": "homework.html#making-a-homework-project-repository-public",
    "href": "homework.html#making-a-homework-project-repository-public",
    "title": "Homework Projects",
    "section": "7 Making a Homework Project repository public",
    "text": "7 Making a Homework Project repository public\nYou may want to use your Homework Projects in your portfolio. The repositories can be made public from where they are. If you want to do so, please inform the instructors. In the case of publication, the README should tell in a “License” how I think it should be done in line with Academic Integrity.",
    "crumbs": [
      "Syllabus",
      "Homework Projects"
    ]
  },
  {
    "objectID": "help.html",
    "href": "help.html",
    "title": "Need help for Homework?",
    "section": "",
    "text": "Go through the Checklist Technical Setup and make sure everything works.",
    "crumbs": [
      "Syllabus",
      "Need help for Homework?"
    ]
  },
  {
    "objectID": "help.html#setting-up-the-basic-toolkit",
    "href": "help.html#setting-up-the-basic-toolkit",
    "title": "Need help for Homework?",
    "section": "",
    "text": "Go through the Checklist Technical Setup and make sure everything works.",
    "crumbs": [
      "Syllabus",
      "Need help for Homework?"
    ]
  },
  {
    "objectID": "help.html#good-practices",
    "href": "help.html#good-practices",
    "title": "Need help for Homework?",
    "section": "2 Good practices",
    "text": "2 Good practices\n\nDo homework together with other students. Working together is encouraged!\nCommit and push your intermediate results often, instructors may check your code directly.\nRead error messages carefully! Often they are informative or even tell you what to do! (Hint: Uninformative error messages are also common. Maybe you get at least a hint where the problem lies. You will become more advanced on this, error messages which are not helpful now may become helpful in the future.)\nDo the homework before the next Data Science Tools Session and prepare questions to ask in class.",
    "crumbs": [
      "Syllabus",
      "Need help for Homework?"
    ]
  },
  {
    "objectID": "help.html#good-ways-to-ask-for-help",
    "href": "help.html#good-ways-to-ask-for-help",
    "title": "Need help for Homework?",
    "section": "3 Good ways to ask for help",
    "text": "3 Good ways to ask for help\n\nAsk your fellow students, but show willingness to learn by being prepared. Do not “abuse” your students to fix your computer problems.\n\nIt is absolutely OK to ask instructors for help outside of class. We try to care, if we are not too busy with other things. If you do, please do first: Document and describe where you get stuck as precise as possible. Try to find out why as much as possible. Use Teams chat (or email)!",
    "crumbs": [
      "Syllabus",
      "Need help for Homework?"
    ]
  },
  {
    "objectID": "help.html#problems-with-the-git-github-dance",
    "href": "help.html#problems-with-the-git-github-dance",
    "title": "Need help for Homework?",
    "section": "4 Problems with the git-GitHub-dance",
    "text": "4 Problems with the git-GitHub-dance\nHappy Git with R is a great resource for helping you practically and for learning the version control concepts better. The site is well suited for our purpose of data science! Git was developed for software development and a lot of the advice and good practices you find by searching the internet are targeted for software engineering. Whenever you consult Happy Git with R for solutions for a problem, try to learn a bit about the basics. Git is not something to learn in one course but step by step while doing.\nProblems with getting started are likely related to the installation of software and connecting git and GitHub. Reading in Sections 4 - 14.\n\nAfter installing git, you need to Introduce yourself to Git (Use the email associated with your GitHub account.)\nThen you have to make the communication with GitHub possible as outlined by the introduction Can you here me now?. The default is to communicate via HTTPS (instead of SSH).\n\nIn the past you could authenticate via your GitHub-user password, now you need a personal access token which is something like a password created by GitHub which you can see and copy only once. (No worries, if loose the connection you can create a new one.)\nThese are the instructions for Personal access token for HTTPS. Ideally it works following the instructions in “TL;DR”. (Install the packages usethis and gitcreds in R.)\nNow, you should be able to clone the Homework repos analog to Connect RStudio to Git and GitHub.\nSometimes you have git installed but RStudio does not find it. Usually it works out of the box. If not, read Detect Git from RStudio\nFinally there is a page for problems which appear sometimes which you can scroll through looking if it is related to your problem: https://happygitwithr.com/troubleshooting\n\n\nFor problems appearing after your first successful git-GitHub-dance operations helpful sections are for example:\n\nYou want to bring your new versions to GitHub but when you push it does not work: Dealing with push rejection\nYou need to pull (to synchronize remote and local) but you made changes locally and get warnings: Pull, but you have local work\nIf you can not properly push and pull anymore and there are conflicts all over the place: Consider Burn it all down (Meaning to start again by cloning again …)",
    "crumbs": [
      "Syllabus",
      "Need help for Homework?"
    ]
  },
  {
    "objectID": "material/M02.html",
    "href": "material/M02.html",
    "title": "W#02",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#02"
    ]
  },
  {
    "objectID": "material/M02.html#data-visualization-data-formats",
    "href": "material/M02.html#data-visualization-data-formats",
    "title": "W#02",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#02"
    ]
  },
  {
    "objectID": "material/M02.html#lecture-material",
    "href": "material/M02.html#lecture-material",
    "title": "W#02",
    "section": "1 Lecture Material",
    "text": "1 Lecture Material\nSlides: Direct Link Part 1\n\nSlides: Direct Link Part 2\n\nFind the live recording in the Course’s Team’s Recording Folder.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#02"
    ]
  },
  {
    "objectID": "material/M02.html#additional-readings-and-material",
    "href": "material/M02.html#additional-readings-and-material",
    "title": "W#02",
    "section": "2 Additional Readings and Material",
    "text": "2 Additional Readings and Material\n\nggplot: The following sections in R for Data Science\n\nCh 1: Data Visualization\nIf you want to go deeper already now, chapter Ch 9: Layers",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#02"
    ]
  },
  {
    "objectID": "material/M02.html#achievements",
    "href": "material/M02.html#achievements",
    "title": "W#02",
    "section": "3 Achievements",
    "text": "3 Achievements\nYou\n\nhave understood the data science process, in particular you can describe with examples what is understood as data wrangling and data exploration, and you can describe two different purposes of data visualization in the data science process\nhave identified and can explain when a pie chart is a bad visualization (when the pieces do not add up to 100%) and when a truncated y-axis is a bad visualization (when it is used to make a small difference look big).\nhave understood the basic idea of the grammar of graphics and can explain what the role of a mapping and and geom is\nhave made a bar chart, a scatter plot, and a line plot with ggplot\nknow how many rows and columns an \\(m\\times n\\) data frame has\ncan explain the basic data types, in particular character, logical, and double\nknow what coercion of data is (what happens when different data types are combined in a vector)\nhave understood the concept of the tidy data format and can argue why a certain form of data representation is more or less tidy\nmade a data frame longer and wider",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#02"
    ]
  },
  {
    "objectID": "material/M02.html#homework-projects-progress-guides",
    "href": "material/M02.html#homework-projects-progress-guides",
    "title": "W#02",
    "section": "4 Homework Projects Progress Guides",
    "text": "4 Homework Projects Progress Guides\nFind the Repositories of your Homework Projects in the Course’s GitHub-Organization’s CU-F25-MDSSB-01-Concepts-Tools &gt; Repositories.\nProject setup: Follow the HOW-TO in your project repositry. Also: Watch the first part of the Recording of Data Science Concepts to see how the process of cloning the repository, previewing the report, and committing and pushing work back to GitHub looks.\nProject’s INSTRUCTIONS you should have completed:\nProject_NYCFlights: 1., 2., 3.\n\n\n\n\n\n\nNote\n\n\n\nDon’t panic, if you fell behind, just do it later. Find your own learning path. Better step by step than randomly skipping things. It is about learning not just completing!",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#02"
    ]
  },
  {
    "objectID": "material/M02.html#questions-on-coercion",
    "href": "material/M02.html#questions-on-coercion",
    "title": "W#02",
    "section": "5 Questions on Coercion",
    "text": "5 Questions on Coercion\nWhat happens when you combine different data types in a vector?\n\n5.1 What does this return?\nc(TRUE, 1)\n\nCharacters \"TRUE\" \"1\"\nNumericals 1 1\nLogicals TRUE, TRUE\nNumericals 0 1\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n\n\n\n\n\n\n\n5.2 What does this return?\nc(\"1\", FALSE)\n\nCharacters \"1\" \"FALSE\nNumericals 1 0\nLogicals TRUE, FALSE\nNumericals \"FALSE\" \"FALSE\"\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n\n\n\n\n\n\n\n5.3 What does this return?\n1 + TRUE\n\nError\n1\n2\nTRUE\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n\n\n\n\n\n\n\n5.4 What does this return?\n1 + \"TRUE\"\n\nError\n1\n2\nTRUE\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#02"
    ]
  },
  {
    "objectID": "material/M04.html",
    "href": "material/M04.html",
    "title": "W#04",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself. Work on the Homework Projects reach out for help if you get stuck.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#04"
    ]
  },
  {
    "objectID": "material/M04.html#relational-data-math-sets-and-functions-programming-functions",
    "href": "material/M04.html#relational-data-math-sets-and-functions-programming-functions",
    "title": "W#04",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself. Work on the Homework Projects reach out for help if you get stuck.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#04"
    ]
  },
  {
    "objectID": "material/M04.html#lecture-material",
    "href": "material/M04.html#lecture-material",
    "title": "W#04",
    "section": "1 Lecture Material",
    "text": "1 Lecture Material\nSlides: Direct Link\n\nFind the live recording in the Course’s Team’s Recording Folder.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#04"
    ]
  },
  {
    "objectID": "material/M04.html#additional-readings-and-material",
    "href": "material/M04.html#additional-readings-and-material",
    "title": "W#04",
    "section": "2 Additional Readings and Material",
    "text": "2 Additional Readings and Material\nSections in R for Data Science\n\nCh 14: Strings\nCh 19: Joins\nCh 25: Functions\nCh 26: Iteration",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#04"
    ]
  },
  {
    "objectID": "material/M04.html#achievements",
    "href": "material/M04.html#achievements",
    "title": "W#04",
    "section": "3 Achievements",
    "text": "3 Achievements\nYou\n\nknow the difference between NaN and NA\nhave used the dplyr functions left_join, and full_join to combine data frames\nknow what is meant by primary and foreign key\nknow the difference between a vector (ordered elements, duplicates possible) and a set (no order, no duplicates) and have used the functions unique, union, intersect, and setdiff\ncan program a function with various arguments and default values\ncan program a function which does a shift and scale transformation to data\nknow about the value of vectorized functions for data operations\nhave used the concept of the function map (for iteration over values of a list or vector) and reduce (for aggregation over values of a list or vector)",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#04"
    ]
  },
  {
    "objectID": "material/M04.html#homework-projects-progress-guides",
    "href": "material/M04.html#homework-projects-progress-guides",
    "title": "W#04",
    "section": "4 Homework Projects Progress Guides",
    "text": "4 Homework Projects Progress Guides\nFind the Repositories of your Homework Projects in the Course’s GitHub-Organization’s CU-F25-MDSSB-01-Concepts-Tools &gt; Repositories.\nProject’s INSTRUCTIONS you should have completed:\nProject_NYCFlights: 1., 2., 3., 4. 5., 6.\nProject_COVID19: 1.1, 1.2, 1.3, 1.4, 1.5\n\n\n\n\n\n\nNote\n\n\n\nDon’t panic, if you fell behind, just do it later. Find your own learning path. Better step by step than randomly skipping things. It is about learning not just completing!",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#04"
    ]
  },
  {
    "objectID": "material/M06.html",
    "href": "material/M06.html",
    "title": "W#06",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself. Work on the Homework Projects reach out for help if you get stuck.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#06"
    ]
  },
  {
    "objectID": "material/M06.html#descriptive-statistics-exploratory-data-analysis",
    "href": "material/M06.html#descriptive-statistics-exploratory-data-analysis",
    "title": "W#06",
    "section": "",
    "text": "Reconsider the Lecture Material, consider the Additional Readings and Material, and check the Achievements for yourself. Work on the Homework Projects reach out for help if you get stuck.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#06"
    ]
  },
  {
    "objectID": "material/M06.html#lecture-material",
    "href": "material/M06.html#lecture-material",
    "title": "W#06",
    "section": "1 Lecture Material",
    "text": "1 Lecture Material\nSlides: Direct Link\n\nFind the live recording in the Course’s Team’s Recording Folder.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#06"
    ]
  },
  {
    "objectID": "material/M06.html#additional-readings-and-material",
    "href": "material/M06.html#additional-readings-and-material",
    "title": "W#06",
    "section": "2 Additional Readings and Material",
    "text": "2 Additional Readings and Material\nFor more mathematical details about PCA read Chapter 12.2 in An Introduction to Statistical Learning. You can read the PDF for R to have the examples coded in R. The content is largely the same when you read the python version.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#06"
    ]
  },
  {
    "objectID": "material/M06.html#achievements",
    "href": "material/M06.html#achievements",
    "title": "W#06",
    "section": "3 Achievements",
    "text": "3 Achievements\nYou\n\nyou can create and interpret a principal component analysis, in particular you can\n\nlook at the principle components,\nthe data in PCA coordinates, and\nthe explained variance of the principle components\n\nand relate them to each other\ncan handle computations with exponents and logarithms\nunderstood why logarithms appear mostly as the natural logarithm (with base \\(e = 2.718...\\)) or the logarithm with base 10\ncan interpret the numbers in a vector after a \\(\\log_{10}\\) transformation\ncan operationalize the concept of differentiation and integration of calculus to data science operations, e.g. with time series data:\n\nYou can visualize on paper the ideas that\n\nthe derivative represents the slope of a function at a certain \\(x\\)-value, and\nthe integral represents the area under the curve of a function from \\(x=0\\) up to a certain \\(x\\)-value.\n\nWith time series data you can compute the change and the cumulative sum of a variable over time.\n\nknow how the fundamental theorem of calculus relates the derivative and the integral of a function and how you can show it with data.",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#06"
    ]
  },
  {
    "objectID": "material/M06.html#homework-projects-progress-guides",
    "href": "material/M06.html#homework-projects-progress-guides",
    "title": "W#06",
    "section": "4 Homework Projects Progress Guides",
    "text": "4 Homework Projects Progress Guides\nFind the Repositories of your Homework Projects in the Course’s GitHub-Organization’s CU-F25-MDSSB-01-Concepts-Tools &gt; Repositories.\nProject’s INSTRUCTIONS you should have completed:\nProject_NYCFlights: 1., 2., 3., 4. 5., 6., 7.\nProject_COVID19: 1.1, 1.2, 1.3, 1.4, 1.5, 2.1, 2.2 (Make a PCA!)\n\n\n\n\n\n\nNote\n\n\n\nDon’t panic, if you fell behind, just do it later. Find your own learning path. Better step by step than randomly skipping things. It is about learning not just completing!",
    "crumbs": [
      "Syllabus",
      "Schedule",
      "W#06"
    ]
  },
  {
    "objectID": "lectures/W03.html#readr-and-readxl",
    "href": "lectures/W03.html#readr-and-readxl",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "readr and readxl",
    "text": "readr and readxl\n\n\nreadr is loaded with tidyverse\n\n\nread_csv() - comma delimited files\nread_csv2() - semicolon delimited files (common where “,” is used as decimal place)\nread_tsv() - tab delimited files\nread_delim() - reads in files with any delimiter\n…\n\n\nreadxl has to be installed and loaded separately\n\n\nread_excel() read xls or xlsx files from MS Excel\n…\n\n\n\n\nThere are also packages to write data from R to excel files (writexl, openxlsx, xlsx, …)."
  },
  {
    "objectID": "lectures/W03.html#importing-data-from-other-sources",
    "href": "lectures/W03.html#importing-data-from-other-sources",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Importing data from other sources",
    "text": "Importing data from other sources\nR packages for some cases. They provide function to read from the source into dataframes.\n\nData collected in a Google Spreadsheet: googlesheets4\nData in native formats of SPSS, Stata, or SAS: haven\nData in SQL Databases: DBI, together with a database specific backend (RMySQL, RSQLite, RPostgreSQL)\nData in JSON or XML format as often used by web applications (e.g. written in JavaScript): jsonlite and xml2\nScraping data directly from websites: rvest\nUsing Appache Arrow, e.g. .parquet files: arrow\n\n\n\nAnalog libraries will exist for python"
  },
  {
    "objectID": "lectures/W03.html#comma-separated-values-csv",
    "href": "lectures/W03.html#comma-separated-values-csv",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Comma-separated values (CSV)",
    "text": "Comma-separated values (CSV)\nCSV files are delimited text file\n\nCan be viewed with any text editor\nShow each row of the dataframe in a line\nSeparates the content of columns by commas (or the delimiter character)\nEach cell could be surrounded by quotes (when long text with commas (!) is in cells)\nThe first line is interpreted as listing the variable names by default\n\nreadr tries to guess the data type of variables\nYou can also customize it yourself!\nWe use CSV file when there is no certain reason to do otherwise. Reasons are: CSV is not provided or the dataset being very larger and hard-disk storage is an issue. Other formats or more space efficient."
  },
  {
    "objectID": "lectures/W03.html#data-import-workflow",
    "href": "lectures/W03.html#data-import-workflow",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Data import workflow",
    "text": "Data import workflow\n\nYou download your CSV file to the data/ directory. You may use download.file() for this, but make sure you do not download large amounts of data each time you render your file!\nRead the data with data &lt;- read_csv(\"data/FILENAME.csv\") and read the report in the console.\nExplore if you are happy and iterate by customizing the data import line using specifications until the data is as you want it to be.\n\nGood practices to document the data download:\n\nOne or low number of files: Put the download line(s) in you main document, but comment out # after usage.\nWrite a script (data-download.r) to document the download commands.\nMake your code check first if the file already exist, like this if (!(file.exists(\"DATA_FILE.csv\"))) {DOWNLOAD-CODE}"
  },
  {
    "objectID": "lectures/W03.html#download-2.-read",
    "href": "lectures/W03.html#download-2.-read",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "1. Download, 2. Read",
    "text": "1. Download, 2. Read\nThis downloads data only if the file does not exist. Then it loads it.\n\nlibrary(tidyverse)\nif (!file.exists(\"hotels.csv\")) {\n  download.file(\n    url = \"https://raw.githubusercontent.com/rstudio-education/datascience-box/main/course-materials/_slides/u2-d06-grammar-wrangle/data/hotels.csv\",\n    destfile = \"hotels.csv\"\n  )\n}\nhotels &lt;- read_csv(\"hotels.csv\")\n\nRows: 119390 Columns: 32\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (13): hotel, arrival_date_month, meal, country, market_segment, distrib...\ndbl  (18): is_canceled, lead_time, arrival_date_year, arrival_date_week_numb...\ndate  (1): reservation_status_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nOutput is a summary how read_csv guessed the data types of columns."
  },
  {
    "objectID": "lectures/W03.html#explore-using-spec",
    "href": "lectures/W03.html#explore-using-spec",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "3. Explore using spec()",
    "text": "3. Explore using spec()\nAll details to check or customize:\n\nspec(hotels)\n\ncols(\n  hotel = col_character(),\n  is_canceled = col_double(),\n  lead_time = col_double(),\n  arrival_date_year = col_double(),\n  arrival_date_month = col_character(),\n  arrival_date_week_number = col_double(),\n  arrival_date_day_of_month = col_double(),\n  stays_in_weekend_nights = col_double(),\n  stays_in_week_nights = col_double(),\n  adults = col_double(),\n  children = col_double(),\n  babies = col_double(),\n  meal = col_character(),\n  country = col_character(),\n  market_segment = col_character(),\n  distribution_channel = col_character(),\n  is_repeated_guest = col_double(),\n  previous_cancellations = col_double(),\n  previous_bookings_not_canceled = col_double(),\n  reserved_room_type = col_character(),\n  assigned_room_type = col_character(),\n  booking_changes = col_double(),\n  deposit_type = col_character(),\n  agent = col_character(),\n  company = col_character(),\n  days_in_waiting_list = col_double(),\n  customer_type = col_character(),\n  adr = col_double(),\n  required_car_parking_spaces = col_double(),\n  total_of_special_requests = col_double(),\n  reservation_status = col_character(),\n  reservation_status_date = col_date(format = \"\")\n)"
  },
  {
    "objectID": "lectures/W03.html#finalize-data-import-option-1",
    "href": "lectures/W03.html#finalize-data-import-option-1",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Finalize data import, option 1",
    "text": "Finalize data import, option 1\nWhen\n\nall columns are how they should\nyou consider it not necessary to document the specifications\n\nThen use show_col_types = FALSE to quiet the reading message.\n\nhotels &lt;- read_csv(\"hotels.csv\", show_col_types = FALSE)"
  },
  {
    "objectID": "lectures/W03.html#finalize-data-import-option-2",
    "href": "lectures/W03.html#finalize-data-import-option-2",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Finalize data import, option 2",
    "text": "Finalize data import, option 2\n\nCopy the spec(hotels) output into the col_types argument\nIf necessary, customize it\n\n\nhotels &lt;- read_csv(\n  \"hotels.csv\",\n  col_types = cols(\n    hotel = col_character(),\n    is_canceled = col_logical(),\n    lead_time = col_integer(),\n    arrival_date_year = col_integer(),\n    arrival_date_month = col_character(),\n    arrival_date_week_number = col_integer(),\n    arrival_date_day_of_month = col_integer(),\n    stays_in_weekend_nights = col_integer(),\n    stays_in_week_nights = col_integer(),\n    adults = col_integer(),\n    children = col_integer(),\n    babies = col_integer(),\n    meal = col_character(),\n    country = col_character(),\n    market_segment = col_character(),\n    distribution_channel = col_character(),\n    is_repeated_guest = col_logical(),\n    previous_cancellations = col_integer(),\n    previous_bookings_not_canceled = col_integer(),\n    reserved_room_type = col_character(),\n    assigned_room_type = col_character(),\n    booking_changes = col_integer(),\n    deposit_type = col_character(),\n    agent = col_integer(),\n    company = col_integer(),\n    days_in_waiting_list = col_integer(),\n    customer_type = col_character(),\n    adr = col_double(),\n    required_car_parking_spaces = col_integer(),\n    total_of_special_requests = col_integer(),\n    reservation_status = col_character(),\n    reservation_status_date = col_date(format = \"\")\n  )\n)"
  },
  {
    "objectID": "lectures/W03.html#columns-types",
    "href": "lectures/W03.html#columns-types",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Columns types",
    "text": "Columns types\n\n\n\ntype function\ndata type\n\n\n\n\ncol_character()\ncharacter\n\n\ncol_date()\ndate\n\n\ncol_datetime()\nPOSIXct (date-time)\n\n\ncol_double()\ndouble (numeric)\n\n\ncol_factor()\nfactor\n\n\ncol_guess()\nlet readr guess (default)\n\n\ncol_integer()\ninteger\n\n\ncol_logical()\nlogical\n\n\ncol_number()\nnumbers mixed with non-number characters\n\n\ncol_skip()\ndo not read\n\n\ncol_time()\ntime"
  },
  {
    "objectID": "lectures/W03.html#hotels-data",
    "href": "lectures/W03.html#hotels-data",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Hotels data",
    "text": "Hotels data\n\nData from two hotels: one resort and one city hotel\nObservations: Each row represents a hotel booking"
  },
  {
    "objectID": "lectures/W03.html#first-look-on-data",
    "href": "lectures/W03.html#first-look-on-data",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "First look on data",
    "text": "First look on data\nType the name of the dataframe\n\n\n\nhotels\n\n# A tibble: 119,390 × 32\n   hotel        is_canceled lead_time arrival_date_year arrival_date_month\n   &lt;chr&gt;        &lt;lgl&gt;           &lt;int&gt;             &lt;int&gt; &lt;chr&gt;             \n 1 Resort Hotel FALSE             342              2015 July              \n 2 Resort Hotel FALSE             737              2015 July              \n 3 Resort Hotel FALSE               7              2015 July              \n 4 Resort Hotel FALSE              13              2015 July              \n 5 Resort Hotel FALSE              14              2015 July              \n 6 Resort Hotel FALSE              14              2015 July              \n 7 Resort Hotel FALSE               0              2015 July              \n 8 Resort Hotel FALSE               9              2015 July              \n 9 Resort Hotel TRUE               85              2015 July              \n10 Resort Hotel TRUE               75              2015 July              \n# ℹ 119,380 more rows\n# ℹ 27 more variables: arrival_date_week_number &lt;int&gt;,\n#   arrival_date_day_of_month &lt;int&gt;, stays_in_weekend_nights &lt;int&gt;,\n#   stays_in_week_nights &lt;int&gt;, adults &lt;int&gt;, children &lt;int&gt;, babies &lt;int&gt;,\n#   meal &lt;chr&gt;, country &lt;chr&gt;, market_segment &lt;chr&gt;,\n#   distribution_channel &lt;chr&gt;, is_repeated_guest &lt;lgl&gt;,\n#   previous_cancellations &lt;int&gt;, previous_bookings_not_canceled &lt;int&gt;, …\n\n\n\n\nLook are the number of rows and columns\nLook at the column names, types, and first entries for the first columns\nNotice how many more columns are there and decide what to look for next"
  },
  {
    "objectID": "lectures/W03.html#look-on-variable-names",
    "href": "lectures/W03.html#look-on-variable-names",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Look on variable names",
    "text": "Look on variable names\n\nnames(hotels)\n\n [1] \"hotel\"                          \"is_canceled\"                   \n [3] \"lead_time\"                      \"arrival_date_year\"             \n [5] \"arrival_date_month\"             \"arrival_date_week_number\"      \n [7] \"arrival_date_day_of_month\"      \"stays_in_weekend_nights\"       \n [9] \"stays_in_week_nights\"           \"adults\"                        \n[11] \"children\"                       \"babies\"                        \n[13] \"meal\"                           \"country\"                       \n[15] \"market_segment\"                 \"distribution_channel\"          \n[17] \"is_repeated_guest\"              \"previous_cancellations\"        \n[19] \"previous_bookings_not_canceled\" \"reserved_room_type\"            \n[21] \"assigned_room_type\"             \"booking_changes\"               \n[23] \"deposit_type\"                   \"agent\"                         \n[25] \"company\"                        \"days_in_waiting_list\"          \n[27] \"customer_type\"                  \"adr\"                           \n[29] \"required_car_parking_spaces\"    \"total_of_special_requests\"     \n[31] \"reservation_status\"             \"reservation_status_date\"       \n\n\nThis gives you a vector of column names."
  },
  {
    "objectID": "lectures/W03.html#second-look-with-glimpse",
    "href": "lectures/W03.html#second-look-with-glimpse",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Second look with glimpse",
    "text": "Second look with glimpse\n\nglimpse(hotels)\n\nRows: 119,390\nColumns: 32\n$ hotel                          &lt;chr&gt; \"Resort Hotel\", \"Resort Hotel\", \"Resort…\n$ is_canceled                    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ lead_time                      &lt;int&gt; 342, 737, 7, 13, 14, 14, 0, 9, 85, 75, …\n$ arrival_date_year              &lt;int&gt; 2015, 2015, 2015, 2015, 2015, 2015, 201…\n$ arrival_date_month             &lt;chr&gt; \"July\", \"July\", \"July\", \"July\", \"July\",…\n$ arrival_date_week_number       &lt;int&gt; 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,…\n$ arrival_date_day_of_month      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ stays_in_weekend_nights        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ stays_in_week_nights           &lt;int&gt; 0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 4, 4, 4, …\n$ adults                         &lt;int&gt; 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ children                       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ babies                         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ meal                           &lt;chr&gt; \"BB\", \"BB\", \"BB\", \"BB\", \"BB\", \"BB\", \"BB…\n$ country                        &lt;chr&gt; \"PRT\", \"PRT\", \"GBR\", \"GBR\", \"GBR\", \"GBR…\n$ market_segment                 &lt;chr&gt; \"Direct\", \"Direct\", \"Direct\", \"Corporat…\n$ distribution_channel           &lt;chr&gt; \"Direct\", \"Direct\", \"Direct\", \"Corporat…\n$ is_repeated_guest              &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ previous_cancellations         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ previous_bookings_not_canceled &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ reserved_room_type             &lt;chr&gt; \"C\", \"C\", \"A\", \"A\", \"A\", \"A\", \"C\", \"C\",…\n$ assigned_room_type             &lt;chr&gt; \"C\", \"C\", \"C\", \"A\", \"A\", \"A\", \"C\", \"C\",…\n$ booking_changes                &lt;int&gt; 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ deposit_type                   &lt;chr&gt; \"No Deposit\", \"No Deposit\", \"No Deposit…\n$ agent                          &lt;int&gt; NA, NA, NA, 304, 240, 240, NA, 303, 240…\n$ company                        &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ days_in_waiting_list           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ customer_type                  &lt;chr&gt; \"Transient\", \"Transient\", \"Transient\", …\n$ adr                            &lt;dbl&gt; 0.00, 0.00, 75.00, 75.00, 98.00, 98.00,…\n$ required_car_parking_spaces    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ total_of_special_requests      &lt;int&gt; 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 3, …\n$ reservation_status             &lt;chr&gt; \"Check-Out\", \"Check-Out\", \"Check-Out\", …\n$ reservation_status_date        &lt;date&gt; 2015-07-01, 2015-07-01, 2015-07-02, 20…\n\n\n\nShowing you all variables listed including data type and the first entries."
  },
  {
    "objectID": "lectures/W03.html#grammar-of-data-wrangling",
    "href": "lectures/W03.html#grammar-of-data-wrangling",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Grammar of Data Wrangling",
    "text": "Grammar of Data Wrangling\n\n\n\n\nGrammar of data wrangling: Start with a dataset and pipe it through several manipulations with |&gt;\nmpg |&gt; \n  filter(cyl == 8) |&gt; \n  select(manufacturer, hwy) |&gt; \n  group_by(manufacturer) |&gt; \n  summarize(mean_hwy = mean(hwy))\n\nSimilar in python: Make a chain using . to apply pandas methods for dataframes one after the other.\nSimilar in ggplot2: Creating a ggplot object, then add graphical layers (geom_ functions) with + (instead of a pipe)\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = manufacturer)) + \n  geom_point() + \n  geom_line()"
  },
  {
    "objectID": "lectures/W03.html#what-is-the-pipe",
    "href": "lectures/W03.html#what-is-the-pipe",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "What is the pipe |>?",
    "text": "What is the pipe |&gt;?\nx |&gt; f(a,b) is the same as f(x,a,b)\nThe outcome of a command is put into the first argument of the next function call. Practice it. See that it is exactly identical! (Example: try c() as f and just number like 1 or 2 as a and b; or paste() with \"a\" as \"b\".)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/W03.html#reasons-for-using-pipes",
    "href": "lectures/W03.html#reasons-for-using-pipes",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Reasons for using pipes |>",
    "text": "Reasons for using pipes |&gt;\n\nstructure the sequence of your data operations from left to right\navoid nested function calls:\nnested: filter(select(hotels, hotel, adults), adults == 2)\npiped: hotels |&gt; select(hotel, adults) |&gt; filter(adults == 2)\n(base R: hotels[hotels$adults == 2, c(\"hotel\", \"adults\")])\nYou’ll minimize the need for local variables and function definitions\nYou’ll make it easy to add steps anywhere in the sequence of operations\n\n\n\nSince R 4.1.0, the pipe is part of base R. Before you had to load the magrittr package and use %&gt;%. You still find it in a lot of code out in the wild. It is almost the same."
  },
  {
    "objectID": "lectures/W03.html#dplyr-uses-verbs-to-manipulate",
    "href": "lectures/W03.html#dplyr-uses-verbs-to-manipulate",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "dplyr uses verbs to manipulate",
    "text": "dplyr uses verbs to manipulate\n\nselect: pick columns by name\narrange: reorder rows\nslice: pick rows using index(es)\nfilter: pick rows matching criteria\ndistinct: filter for unique rows\nmutate: add new variables\nsummarise: reduce variables to values\ngroup_by: for grouped operations\n… (many more)"
  },
  {
    "objectID": "lectures/W03.html#select-a-single-column",
    "href": "lectures/W03.html#select-a-single-column",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "select a single column",
    "text": "select a single column\n\n\n\nhotels |&gt; select(lead_time)\n\n\n\n# A tibble: 119,390 × 1\n   lead_time\n       &lt;int&gt;\n 1       342\n 2       737\n 3         7\n 4        13\n 5        14\n 6        14\n 7         0\n 8         9\n 9        85\n10        75\n# ℹ 119,380 more rows\n\n\nNote: select(hotels, lead_time) is identical (Reminder to understand the pipe |&gt;!).\n\nWhy does piping |&gt; work?\ndplyr philosophy\nEvery dplyr function\n\ntakes a dataframe (tibble) as first argument\noutputs a (manipulated) dataframe (tibble)\n\n\n\n\nIn hotel business, lead time is the time betweeen booking and arrival."
  },
  {
    "objectID": "lectures/W03.html#select-more-columns",
    "href": "lectures/W03.html#select-more-columns",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Select more columns",
    "text": "Select more columns\n\nhotels |&gt; select(hotel, lead_time)\n\n\n\n# A tibble: 119,390 × 2\n   hotel        lead_time\n   &lt;chr&gt;            &lt;int&gt;\n 1 Resort Hotel       342\n 2 Resort Hotel       737\n 3 Resort Hotel         7\n 4 Resort Hotel        13\n 5 Resort Hotel        14\n 6 Resort Hotel        14\n 7 Resort Hotel         0\n 8 Resort Hotel         9\n 9 Resort Hotel        85\n10 Resort Hotel        75\n# ℹ 119,380 more rows\n\n\nImportant: hotel is a column (variable) name, but hotels the object name of the dataframe"
  },
  {
    "objectID": "lectures/W03.html#select-helper-starts_with",
    "href": "lectures/W03.html#select-helper-starts_with",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Select helper starts_with",
    "text": "Select helper starts_with\n\nhotels |&gt; select(starts_with(\"arrival\"))\n\n\n\n# A tibble: 119,390 × 4\n   arrival_date_year arrival_date_month arrival_date_week_number\n               &lt;int&gt; &lt;chr&gt;                                 &lt;int&gt;\n 1              2015 July                                     27\n 2              2015 July                                     27\n 3              2015 July                                     27\n 4              2015 July                                     27\n 5              2015 July                                     27\n 6              2015 July                                     27\n 7              2015 July                                     27\n 8              2015 July                                     27\n 9              2015 July                                     27\n10              2015 July                                     27\n# ℹ 119,380 more rows\n# ℹ 1 more variable: arrival_date_day_of_month &lt;int&gt;"
  },
  {
    "objectID": "lectures/W03.html#bring-columns-to-the-front",
    "href": "lectures/W03.html#bring-columns-to-the-front",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Bring columns to the front",
    "text": "Bring columns to the front\n\nhotels |&gt; select(hotel, market_segment, children, everything())\n\n\n\n# A tibble: 119,390 × 32\n   hotel        market_segment children is_canceled lead_time arrival_date_year\n   &lt;chr&gt;        &lt;chr&gt;             &lt;int&gt; &lt;lgl&gt;           &lt;int&gt;             &lt;int&gt;\n 1 Resort Hotel Direct                0 FALSE             342              2015\n 2 Resort Hotel Direct                0 FALSE             737              2015\n 3 Resort Hotel Direct                0 FALSE               7              2015\n 4 Resort Hotel Corporate             0 FALSE              13              2015\n 5 Resort Hotel Online TA             0 FALSE              14              2015\n 6 Resort Hotel Online TA             0 FALSE              14              2015\n 7 Resort Hotel Direct                0 FALSE               0              2015\n 8 Resort Hotel Direct                0 FALSE               9              2015\n 9 Resort Hotel Online TA             0 TRUE               85              2015\n10 Resort Hotel Offline TA/TO         0 TRUE               75              2015\n# ℹ 119,380 more rows\n# ℹ 26 more variables: arrival_date_month &lt;chr&gt;,\n#   arrival_date_week_number &lt;int&gt;, arrival_date_day_of_month &lt;int&gt;,\n#   stays_in_weekend_nights &lt;int&gt;, stays_in_week_nights &lt;int&gt;, adults &lt;int&gt;,\n#   babies &lt;int&gt;, meal &lt;chr&gt;, country &lt;chr&gt;, distribution_channel &lt;chr&gt;,\n#   is_repeated_guest &lt;lgl&gt;, previous_cancellations &lt;int&gt;,\n#   previous_bookings_not_canceled &lt;int&gt;, reserved_room_type &lt;chr&gt;, …"
  },
  {
    "objectID": "lectures/W03.html#more-select-helpers",
    "href": "lectures/W03.html#more-select-helpers",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "More select helpers",
    "text": "More select helpers\n\nstarts_with(): Starts with a prefix\nends_with(): Ends with a suffix\ncontains(): Contains a literal string\nnum_range(): Matches a numerical range like x01, x02, x03\neverything(): Matches all variables\nlast_col(): Select last variable, possibly with an offset\nmatches(): Matches a regular expression (a sequence of symbols/characters expressing a string/pattern to be searched for within text)"
  },
  {
    "objectID": "lectures/W03.html#slice-for-certain-rows",
    "href": "lectures/W03.html#slice-for-certain-rows",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "slice for certain rows",
    "text": "slice for certain rows\n\nhotels |&gt; slice(2:4)\n\n\n\n# A tibble: 3 × 32\n  hotel        is_canceled lead_time arrival_date_year arrival_date_month\n  &lt;chr&gt;        &lt;lgl&gt;           &lt;int&gt;             &lt;int&gt; &lt;chr&gt;             \n1 Resort Hotel FALSE             737              2015 July              \n2 Resort Hotel FALSE               7              2015 July              \n3 Resort Hotel FALSE              13              2015 July              \n# ℹ 27 more variables: arrival_date_week_number &lt;int&gt;,\n#   arrival_date_day_of_month &lt;int&gt;, stays_in_weekend_nights &lt;int&gt;,\n#   stays_in_week_nights &lt;int&gt;, adults &lt;int&gt;, children &lt;int&gt;, babies &lt;int&gt;,\n#   meal &lt;chr&gt;, country &lt;chr&gt;, market_segment &lt;chr&gt;,\n#   distribution_channel &lt;chr&gt;, is_repeated_guest &lt;lgl&gt;,\n#   previous_cancellations &lt;int&gt;, previous_bookings_not_canceled &lt;int&gt;,\n#   reserved_room_type &lt;chr&gt;, assigned_room_type &lt;chr&gt;, …"
  },
  {
    "objectID": "lectures/W03.html#filter-for-rows-with-certain-criteria",
    "href": "lectures/W03.html#filter-for-rows-with-certain-criteria",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "filter for rows with certain criteria",
    "text": "filter for rows with certain criteria\n\nhotels |&gt; filter(hotel == \"City Hotel\")\n\n\n\n# A tibble: 79,330 × 32\n   hotel      is_canceled lead_time arrival_date_year arrival_date_month\n   &lt;chr&gt;      &lt;lgl&gt;           &lt;int&gt;             &lt;int&gt; &lt;chr&gt;             \n 1 City Hotel FALSE               6              2015 July              \n 2 City Hotel TRUE               88              2015 July              \n 3 City Hotel TRUE               65              2015 July              \n 4 City Hotel TRUE               92              2015 July              \n 5 City Hotel TRUE              100              2015 July              \n 6 City Hotel TRUE               79              2015 July              \n 7 City Hotel FALSE               3              2015 July              \n 8 City Hotel TRUE               63              2015 July              \n 9 City Hotel TRUE               62              2015 July              \n10 City Hotel TRUE               62              2015 July              \n# ℹ 79,320 more rows\n# ℹ 27 more variables: arrival_date_week_number &lt;int&gt;,\n#   arrival_date_day_of_month &lt;int&gt;, stays_in_weekend_nights &lt;int&gt;,\n#   stays_in_week_nights &lt;int&gt;, adults &lt;int&gt;, children &lt;int&gt;, babies &lt;int&gt;,\n#   meal &lt;chr&gt;, country &lt;chr&gt;, market_segment &lt;chr&gt;,\n#   distribution_channel &lt;chr&gt;, is_repeated_guest &lt;lgl&gt;,\n#   previous_cancellations &lt;int&gt;, previous_bookings_not_canceled &lt;int&gt;, …"
  },
  {
    "objectID": "lectures/W03.html#filter-for-multiple-criteria",
    "href": "lectures/W03.html#filter-for-multiple-criteria",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "filter for multiple criteria",
    "text": "filter for multiple criteria\n\nhotels |&gt;\n  filter(\n    babies &gt;= 1,\n    children &gt;= 1\n  ) |&gt;\n  select(hotel, adults, babies, children)\n\n\n\n# A tibble: 175 × 4\n   hotel        adults babies children\n   &lt;chr&gt;         &lt;int&gt;  &lt;int&gt;    &lt;int&gt;\n 1 Resort Hotel      2      1        1\n 2 Resort Hotel      2      1        1\n 3 Resort Hotel      2      1        1\n 4 Resort Hotel      2      1        1\n 5 Resort Hotel      2      1        1\n 6 Resort Hotel      2      1        1\n 7 Resort Hotel      2      1        1\n 8 Resort Hotel      2      1        2\n 9 Resort Hotel      2      1        2\n10 Resort Hotel      1      1        2\n# ℹ 165 more rows\n\n\nComma-separated conditions are interpreted as all these should be fulfilled.\nThis is identical to the logical AND &.\nhotels |&gt; filter(babies &gt;= 1 & children &gt;= 1)\ndelivers the same. (Spot the tiny difference!)"
  },
  {
    "objectID": "lectures/W03.html#filter-for-more-complex-criteria",
    "href": "lectures/W03.html#filter-for-more-complex-criteria",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "filter for more complex criteria",
    "text": "filter for more complex criteria\n\nhotels |&gt;\n  filter(\n    babies &gt;= 1 | children &gt;= 1\n  ) |&gt;\n  select(hotel, adults, babies, children)\n\n\n\n# A tibble: 9,332 × 4\n   hotel        adults babies children\n   &lt;chr&gt;         &lt;int&gt;  &lt;int&gt;    &lt;int&gt;\n 1 Resort Hotel      2      0        1\n 2 Resort Hotel      2      0        2\n 3 Resort Hotel      2      0        2\n 4 Resort Hotel      2      0        2\n 5 Resort Hotel      2      0        1\n 6 Resort Hotel      2      0        1\n 7 Resort Hotel      1      0        2\n 8 Resort Hotel      2      0        2\n 9 Resort Hotel      2      1        0\n10 Resort Hotel      2      1        0\n# ℹ 9,322 more rows\n\n\n| is the logical OR. Only one criterion needs to be fulfilled."
  },
  {
    "objectID": "lectures/W03.html#logical-operators",
    "href": "lectures/W03.html#logical-operators",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Logical operators1",
    "text": "Logical operators1\n\n\n\n\n\noperator\ndefinition\n\n\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to\n\n\nx & y\nx AND y\n\n\nx | y\nx OR y\n\n\n!x\nnot x\n\n\n\n\nTest these (vectors of) logical statements\n\nc(2 == 2, 2 == 3)\n\n\n\n[1]  TRUE FALSE\n\n\n\nc(2 != 2, 2 != 3)\n\n\n\n[1] FALSE  TRUE\n\n\n\nc(2 != 2 & 2 != 3, 2 != 2 | 2 != 3)\n\n\n\n[1] FALSE  TRUE\n\n\n\nc(2 == 2, !(2 == 2))\n\n\n\n[1]  TRUE FALSE\n\n\n\nc(2 != 2, !(2 != 2))\n\n\n\n[1] FALSE  TRUE\n\n\n\nLogical is sometimes called Boolean"
  },
  {
    "objectID": "lectures/W03.html#the-concept-of-indexing",
    "href": "lectures/W03.html#the-concept-of-indexing",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "The Concept of Indexing",
    "text": "The Concept of Indexing\nSelect and filter can also be achieved by numerical indexing.\nIn (base) R as well as in python.\nSelect ranges of rows and columns\n\nhotels[1:3, 5:7]\n\n\n\n# A tibble: 3 × 3\n  arrival_date_month arrival_date_week_number arrival_date_day_of_month\n  &lt;chr&gt;                                 &lt;int&gt;                     &lt;int&gt;\n1 July                                     27                         1\n2 July                                     27                         1\n3 July                                     27                         1\n\n\nYou can use any vector (with non-overshooting indexes)\n\nhotels[c(1:3, 100232), c(5:7, 1)]\n\n\n\n# A tibble: 4 × 4\n  arrival_date_month arrival_date_week_number arrival_date_day_of_month hotel   \n  &lt;chr&gt;                                 &lt;int&gt;                     &lt;int&gt; &lt;chr&gt;   \n1 July                                     27                         1 Resort …\n2 July                                     27                         1 Resort …\n3 July                                     27                         1 Resort …\n4 October                                  44                        23 City Ho…"
  },
  {
    "objectID": "lectures/W03.html#python-is-0-indexed-r-is-1-indexed",
    "href": "lectures/W03.html#python-is-0-indexed-r-is-1-indexed",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "python is 0-indexed, R is 1-indexed!",
    "text": "python is 0-indexed, R is 1-indexed!\npython: indexes go from 0 to n-1\nR: indexes go from 1 to n\nBe aware!\nNote: There is no correct way. For some use cases one is more natural for others the other.\nAnalogy: In mathematics there is an unsettled debate if \\(0 \\in \\mathbb{N}\\) or \\(0 \\notin \\mathbb{N}\\)"
  },
  {
    "objectID": "lectures/W03.html#logical-indexing",
    "href": "lectures/W03.html#logical-indexing",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Logical Indexing",
    "text": "Logical Indexing\nInstead of numerical indexing (with a vector of numbers) you can also use logical indexing with a vector of logicals.\nWith logical vectors you can select rows and columns.\nWe create a small sample data frame\n\n\ndata &lt;- tibble(x = LETTERS[1:5], y = letters[6:10])\ndata\n\n\n# A tibble: 5 × 2\n  x     y    \n  &lt;chr&gt; &lt;chr&gt;\n1 A     f    \n2 B     g    \n3 C     h    \n4 D     i    \n5 E     j    \n\n\n\nNow, we select some rows and a column with logical index vectors\n\n\ndata[c(TRUE, FALSE, TRUE, FALSE, TRUE), c(TRUE, FALSE)]\n\n\n# A tibble: 3 × 1\n  x    \n  &lt;chr&gt;\n1 A    \n2 C    \n3 E"
  },
  {
    "objectID": "lectures/W03.html#logical-vectors-from-conditional-statements",
    "href": "lectures/W03.html#logical-vectors-from-conditional-statements",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Logical vectors from conditional statements",
    "text": "Logical vectors from conditional statements\n\n\ndata$x\n\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\"\n\n\n\n\n\ndata$x %in% c(\"C\", \"E\")\n\n\n[1] FALSE FALSE  TRUE FALSE  TRUE\n\n\n\n\n\n\ndata[data$x %in% c(\"C\", \"E\"), ]\n\n\n# A tibble: 2 × 2\n  x     y    \n  &lt;chr&gt; &lt;chr&gt;\n1 C     h    \n2 E     j    \n\n\n\n\n\n\ndata[data$x %in% c(\"C\", \"E\") | data$y %in% c(\"h\", \"i\"), ]\n\n\n# A tibble: 3 × 2\n  x     y    \n  &lt;chr&gt; &lt;chr&gt;\n1 C     h    \n2 D     i    \n3 E     j    \n\n\n\n\n\n\ndata |&gt;\n  filter(\n    x %in% c(\"C\", \"E\") | y %in% c(\"h\", \"i\")\n  )\n\n\n# A tibble: 3 × 2\n  x     y    \n  &lt;chr&gt; &lt;chr&gt;\n1 C     h    \n2 D     i    \n3 E     j"
  },
  {
    "objectID": "lectures/W03.html#unique-combinations-arranging",
    "href": "lectures/W03.html#unique-combinations-arranging",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Unique combinations, arranging",
    "text": "Unique combinations, arranging\ndistinct and arrange (for sorting)\n\nhotels |&gt;\n  distinct(hotel, market_segment) |&gt;\n  arrange(hotel, market_segment)\n\n\n\n# A tibble: 14 × 2\n   hotel        market_segment\n   &lt;chr&gt;        &lt;chr&gt;         \n 1 City Hotel   Aviation      \n 2 City Hotel   Complementary \n 3 City Hotel   Corporate     \n 4 City Hotel   Direct        \n 5 City Hotel   Groups        \n 6 City Hotel   Offline TA/TO \n 7 City Hotel   Online TA     \n 8 City Hotel   Undefined     \n 9 Resort Hotel Complementary \n10 Resort Hotel Corporate     \n11 Resort Hotel Direct        \n12 Resort Hotel Groups        \n13 Resort Hotel Offline TA/TO \n14 Resort Hotel Online TA"
  },
  {
    "objectID": "lectures/W03.html#counting",
    "href": "lectures/W03.html#counting",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Counting",
    "text": "Counting\ncount\n\nhotels |&gt;\n  count(hotel, market_segment) |&gt; # This produces a new variable n\n  arrange(n)\n\n\n\n# A tibble: 14 × 3\n   hotel        market_segment     n\n   &lt;chr&gt;        &lt;chr&gt;          &lt;int&gt;\n 1 City Hotel   Undefined          2\n 2 Resort Hotel Complementary    201\n 3 City Hotel   Aviation         237\n 4 City Hotel   Complementary    542\n 5 Resort Hotel Corporate       2309\n 6 City Hotel   Corporate       2986\n 7 Resort Hotel Groups          5836\n 8 City Hotel   Direct          6093\n 9 Resort Hotel Direct          6513\n10 Resort Hotel Offline TA/TO   7472\n11 City Hotel   Groups         13975\n12 City Hotel   Offline TA/TO  16747\n13 Resort Hotel Online TA      17729\n14 City Hotel   Online TA      38748"
  },
  {
    "objectID": "lectures/W03.html#counting-arrange-descending",
    "href": "lectures/W03.html#counting-arrange-descending",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Counting, arrange descending",
    "text": "Counting, arrange descending\ncount, arrange, desc\n\nhotels |&gt;\n  count(hotel, market_segment) |&gt; # This produces a new variable n\n  arrange(desc(n))\n\n\n\n# A tibble: 14 × 3\n   hotel        market_segment     n\n   &lt;chr&gt;        &lt;chr&gt;          &lt;int&gt;\n 1 City Hotel   Online TA      38748\n 2 Resort Hotel Online TA      17729\n 3 City Hotel   Offline TA/TO  16747\n 4 City Hotel   Groups         13975\n 5 Resort Hotel Offline TA/TO   7472\n 6 Resort Hotel Direct          6513\n 7 City Hotel   Direct          6093\n 8 Resort Hotel Groups          5836\n 9 City Hotel   Corporate       2986\n10 Resort Hotel Corporate       2309\n11 City Hotel   Complementary    542\n12 City Hotel   Aviation         237\n13 Resort Hotel Complementary    201\n14 City Hotel   Undefined          2"
  },
  {
    "objectID": "lectures/W03.html#create-a-new-variable-with-mutate",
    "href": "lectures/W03.html#create-a-new-variable-with-mutate",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Create a new variable with mutate",
    "text": "Create a new variable with mutate\n\nhotels |&gt;\n  mutate(little_ones = children + babies) |&gt;\n  select(children, babies, little_ones) |&gt;\n  arrange(desc(little_ones)) # This sorts in descending order. See the big things!\n\n\n\n# A tibble: 119,390 × 3\n   children babies little_ones\n      &lt;int&gt;  &lt;int&gt;       &lt;int&gt;\n 1       10      0          10\n 2        0     10          10\n 3        0      9           9\n 4        2      1           3\n 5        2      1           3\n 6        2      1           3\n 7        3      0           3\n 8        2      1           3\n 9        2      1           3\n10        3      0           3\n# ℹ 119,380 more rows"
  },
  {
    "objectID": "lectures/W03.html#more-mutating",
    "href": "lectures/W03.html#more-mutating",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "More mutating",
    "text": "More mutating\n\nhotels |&gt;\n  mutate(little_ones = children + babies) |&gt;\n  count(hotel, little_ones) |&gt;\n  mutate(prop = n / sum(n))\n\n\n\n# A tibble: 12 × 4\n   hotel        little_ones     n       prop\n   &lt;chr&gt;              &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n 1 City Hotel             0 73923 0.619     \n 2 City Hotel             1  3263 0.0273    \n 3 City Hotel             2  2056 0.0172    \n 4 City Hotel             3    82 0.000687  \n 5 City Hotel             9     1 0.00000838\n 6 City Hotel            10     1 0.00000838\n 7 City Hotel            NA     4 0.0000335 \n 8 Resort Hotel           0 36131 0.303     \n 9 Resort Hotel           1  2183 0.0183    \n10 Resort Hotel           2  1716 0.0144    \n11 Resort Hotel           3    29 0.000243  \n12 Resort Hotel          10     1 0.00000838"
  },
  {
    "objectID": "lectures/W03.html#summarizing",
    "href": "lectures/W03.html#summarizing",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Summarizing",
    "text": "Summarizing\n\nhotels |&gt;\n  summarize(mean_adr = mean(adr))\n\n\n\n# A tibble: 1 × 1\n  mean_adr\n     &lt;dbl&gt;\n1     102.\n\n\n\nThat shrinks the dataframe to one row!\nDon’t forget to name the new variable (here mean_adr)\nYou can use any function you can apply to a vector!\n(Sometimes you may need to write your own one.)\n\n\n\nIn hoteling, ADR is the average daily rate, the average daily rental income per paid occupied room. A performce indicator."
  },
  {
    "objectID": "lectures/W03.html#grouped-operations",
    "href": "lectures/W03.html#grouped-operations",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Grouped operations",
    "text": "Grouped operations\n\nhotels |&gt;\n  group_by(hotel) |&gt;\n  summarise(mean_adr = mean(adr))\n\n\n\n# A tibble: 2 × 2\n  hotel        mean_adr\n  &lt;chr&gt;           &lt;dbl&gt;\n1 City Hotel      105. \n2 Resort Hotel     95.0\n\n\nLook at the grouping attributes:\n\nhotels |&gt;\n  group_by(hotel)\n\n\n\n# A tibble: 119,390 × 32\n# Groups:   hotel [2]\n   hotel        is_canceled lead_time arrival_date_year arrival_date_month\n   &lt;chr&gt;        &lt;lgl&gt;           &lt;int&gt;             &lt;int&gt; &lt;chr&gt;             \n 1 Resort Hotel FALSE             342              2015 July              \n 2 Resort Hotel FALSE             737              2015 July              \n 3 Resort Hotel FALSE               7              2015 July              \n 4 Resort Hotel FALSE              13              2015 July              \n 5 Resort Hotel FALSE              14              2015 July              \n 6 Resort Hotel FALSE              14              2015 July              \n 7 Resort Hotel FALSE               0              2015 July              \n 8 Resort Hotel FALSE               9              2015 July              \n 9 Resort Hotel TRUE               85              2015 July              \n10 Resort Hotel TRUE               75              2015 July              \n# ℹ 119,380 more rows\n# ℹ 27 more variables: arrival_date_week_number &lt;int&gt;,\n#   arrival_date_day_of_month &lt;int&gt;, stays_in_weekend_nights &lt;int&gt;,\n#   stays_in_week_nights &lt;int&gt;, adults &lt;int&gt;, children &lt;int&gt;, babies &lt;int&gt;,\n#   meal &lt;chr&gt;, country &lt;chr&gt;, market_segment &lt;chr&gt;,\n#   distribution_channel &lt;chr&gt;, is_repeated_guest &lt;lgl&gt;,\n#   previous_cancellations &lt;int&gt;, previous_bookings_not_canceled &lt;int&gt;, …"
  },
  {
    "objectID": "lectures/W03.html#grouping-summarizing-visualizing",
    "href": "lectures/W03.html#grouping-summarizing-visualizing",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Grouping, summarizing, visualizing",
    "text": "Grouping, summarizing, visualizing\n\nhotels |&gt;\n  group_by(hotel, arrival_date_week_number) |&gt;\n  summarise(mean_adr = mean(adr)) |&gt;\n  ggplot(aes(x = arrival_date_week_number, y = mean_adr, color = hotel)) +\n  geom_line()"
  },
  {
    "objectID": "lectures/W03.html#grouping-alternative",
    "href": "lectures/W03.html#grouping-alternative",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Grouping alternative",
    "text": "Grouping alternative\nInstead of a group_by(...) you can also use the .by = ... argument in summarize (or mutate)\n\nhotels |&gt;\n  summarise(mean_adr = mean(adr), .by = c(hotel, arrival_date_week_number)) |&gt;\n  ggplot(aes(x = arrival_date_week_number, y = mean_adr, color = hotel)) +\n  geom_line()"
  },
  {
    "objectID": "lectures/W03.html#resources",
    "href": "lectures/W03.html#resources",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Resources",
    "text": "Resources\n\nFor systemic understanding: Learning resources linked in the syllabus\n\nR for Data Science\nPython Data Science Handbook\n\nFor quick overview to get inspiration\n\nCheatsheets (find some in RStudio -&gt; Help, others by google)\n\nggplot2 Cheatsheet\ndplyr Cheatsheet\n\n\nFor detailed help with a function\n\nHelp file of the function ?FUNCTION-NAME, or search box in Help tab\nReference page on the package webpage\n\nTalk to ChatGPT? Does it work?"
  },
  {
    "objectID": "lectures/W03.html#named-vectors",
    "href": "lectures/W03.html#named-vectors",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Named vectors",
    "text": "Named vectors\nAll types of vectors can be named upon creation\n\nc(Num1 = 4, Second = 7, Last = 8)\n\n\n\n  Num1 Second   Last \n     4      7      8 \n\n\n\nor names can be set afterward.\n\nx &lt;- 1:4\ny &lt;- set_names(x, c(\"a\", \"b\", \"c\", \"d\"))\ny\n\n\n\na b c d \n1 2 3 4 \n\n\n\n\nNamed vectors can be used for subsetting.\n\ny[c(\"b\", \"d\")]\n\n\n\nb d \n2 4"
  },
  {
    "objectID": "lectures/W03.html#reminder-indexing-and-vectorized-thinking",
    "href": "lectures/W03.html#reminder-indexing-and-vectorized-thinking",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Reminder: Indexing and vectorized thinking",
    "text": "Reminder: Indexing and vectorized thinking\n\nx &lt;- set_names(1:10, LETTERS[1:10])\nx\n\n\n\n A  B  C  D  E  F  G  H  I  J \n 1  2  3  4  5  6  7  8  9 10 \n\n\n\n\nx[c(4, 2, 1, 1, 1, 1, 4, 1, 5)]\n\n\n\nD B A A A A D A E \n4 2 1 1 1 1 4 1 5 \n\n\n\n\nRemoving with negative index numbers.\n\nx[c(-3, -5, -2)]\n\n\n\n A  D  F  G  H  I  J \n 1  4  6  7  8  9 10 \n\n\n\n\nMixing negative and positive numbers does not work!\nx[c(-3, 1)] # Will throw an error"
  },
  {
    "objectID": "lectures/W03.html#r-objects-can-have-attributes",
    "href": "lectures/W03.html#r-objects-can-have-attributes",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "R objects can have attributes",
    "text": "R objects can have attributes\nIn a named vector, the names are an attribute.\n\nx\n\n A  B  C  D  E  F  G  H  I  J \n 1  2  3  4  5  6  7  8  9 10 \n\nattributes(x)\n\n$names\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\"\n\n\n\nAttributes can be assigned freely.\n\nattr(x, \"SayHi\") &lt;- \"Hi\"\nattr(x, \"SayBye\") &lt;- \"Bye\"\nattributes(x)\n\n\n\n$names\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\"\n\n$SayHi\n[1] \"Hi\"\n\n$SayBye\n[1] \"Bye\""
  },
  {
    "objectID": "lectures/W03.html#attributes-in-data-structures",
    "href": "lectures/W03.html#attributes-in-data-structures",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Attributes in data structures",
    "text": "Attributes in data structures\n\nlibrary(nycflights13)\nattributes(airports)\n\n\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n   [1]    1    2    3    4    5    6    7    8    9   10   11   12   13   14\n  [15]   15   16   17   18   19   20   21   22   23   24   25   26   27   28\n  [29]   29   30   31   32   33   34   35   36   37   38   39   40   41   42\n  [43]   43   44   45   46   47   48   49   50   51   52   53   54   55   56\n  [57]   57   58   59   60   61   62   63   64   65   66   67   68   69   70\n  [71]   71   72   73   74   75   76   77   78   79   80   81   82   83   84\n  [85]   85   86   87   88   89   90   91   92   93   94   95   96   97   98\n  [99]   99  100  101  102  103  104  105  106  107  108  109  110  111  112\n [113]  113  114  115  116  117  118  119  120  121  122  123  124  125  126\n [127]  127  128  129  130  131  132  133  134  135  136  137  138  139  140\n [141]  141  142  143  144  145  146  147  148  149  150  151  152  153  154\n [155]  155  156  157  158  159  160  161  162  163  164  165  166  167  168\n [169]  169  170  171  172  173  174  175  176  177  178  179  180  181  182\n [183]  183  184  185  186  187  188  189  190  191  192  193  194  195  196\n [197]  197  198  199  200  201  202  203  204  205  206  207  208  209  210\n [211]  211  212  213  214  215  216  217  218  219  220  221  222  223  224\n [225]  225  226  227  228  229  230  231  232  233  234  235  236  237  238\n [239]  239  240  241  242  243  244  245  246  247  248  249  250  251  252\n [253]  253  254  255  256  257  258  259  260  261  262  263  264  265  266\n [267]  267  268  269  270  271  272  273  274  275  276  277  278  279  280\n [281]  281  282  283  284  285  286  287  288  289  290  291  292  293  294\n [295]  295  296  297  298  299  300  301  302  303  304  305  306  307  308\n [309]  309  310  311  312  313  314  315  316  317  318  319  320  321  322\n [323]  323  324  325  326  327  328  329  330  331  332  333  334  335  336\n [337]  337  338  339  340  341  342  343  344  345  346  347  348  349  350\n [351]  351  352  353  354  355  356  357  358  359  360  361  362  363  364\n [365]  365  366  367  368  369  370  371  372  373  374  375  376  377  378\n [379]  379  380  381  382  383  384  385  386  387  388  389  390  391  392\n [393]  393  394  395  396  397  398  399  400  401  402  403  404  405  406\n [407]  407  408  409  410  411  412  413  414  415  416  417  418  419  420\n [421]  421  422  423  424  425  426  427  428  429  430  431  432  433  434\n [435]  435  436  437  438  439  440  441  442  443  444  445  446  447  448\n [449]  449  450  451  452  453  454  455  456  457  458  459  460  461  462\n [463]  463  464  465  466  467  468  469  470  471  472  473  474  475  476\n [477]  477  478  479  480  481  482  483  484  485  486  487  488  489  490\n [491]  491  492  493  494  495  496  497  498  499  500  501  502  503  504\n [505]  505  506  507  508  509  510  511  512  513  514  515  516  517  518\n [519]  519  520  521  522  523  524  525  526  527  528  529  530  531  532\n [533]  533  534  535  536  537  538  539  540  541  542  543  544  545  546\n [547]  547  548  549  550  551  552  553  554  555  556  557  558  559  560\n [561]  561  562  563  564  565  566  567  568  569  570  571  572  573  574\n [575]  575  576  577  578  579  580  581  582  583  584  585  586  587  588\n [589]  589  590  591  592  593  594  595  596  597  598  599  600  601  602\n [603]  603  604  605  606  607  608  609  610  611  612  613  614  615  616\n [617]  617  618  619  620  621  622  623  624  625  626  627  628  629  630\n [631]  631  632  633  634  635  636  637  638  639  640  641  642  643  644\n [645]  645  646  647  648  649  650  651  652  653  654  655  656  657  658\n [659]  659  660  661  662  663  664  665  666  667  668  669  670  671  672\n [673]  673  674  675  676  677  678  679  680  681  682  683  684  685  686\n [687]  687  688  689  690  691  692  693  694  695  696  697  698  699  700\n [701]  701  702  703  704  705  706  707  708  709  710  711  712  713  714\n [715]  715  716  717  718  719  720  721  722  723  724  725  726  727  728\n [729]  729  730  731  732  733  734  735  736  737  738  739  740  741  742\n [743]  743  744  745  746  747  748  749  750  751  752  753  754  755  756\n [757]  757  758  759  760  761  762  763  764  765  766  767  768  769  770\n [771]  771  772  773  774  775  776  777  778  779  780  781  782  783  784\n [785]  785  786  787  788  789  790  791  792  793  794  795  796  797  798\n [799]  799  800  801  802  803  804  805  806  807  808  809  810  811  812\n [813]  813  814  815  816  817  818  819  820  821  822  823  824  825  826\n [827]  827  828  829  830  831  832  833  834  835  836  837  838  839  840\n [841]  841  842  843  844  845  846  847  848  849  850  851  852  853  854\n [855]  855  856  857  858  859  860  861  862  863  864  865  866  867  868\n [869]  869  870  871  872  873  874  875  876  877  878  879  880  881  882\n [883]  883  884  885  886  887  888  889  890  891  892  893  894  895  896\n [897]  897  898  899  900  901  902  903  904  905  906  907  908  909  910\n [911]  911  912  913  914  915  916  917  918  919  920  921  922  923  924\n [925]  925  926  927  928  929  930  931  932  933  934  935  936  937  938\n [939]  939  940  941  942  943  944  945  946  947  948  949  950  951  952\n [953]  953  954  955  956  957  958  959  960  961  962  963  964  965  966\n [967]  967  968  969  970  971  972  973  974  975  976  977  978  979  980\n [981]  981  982  983  984  985  986  987  988  989  990  991  992  993  994\n [995]  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008\n[1009] 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022\n[1023] 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036\n[1037] 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050\n[1051] 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064\n[1065] 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078\n[1079] 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092\n[1093] 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106\n[1107] 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120\n[1121] 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134\n[1135] 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148\n[1149] 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162\n[1163] 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176\n[1177] 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190\n[1191] 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204\n[1205] 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218\n[1219] 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232\n[1233] 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246\n[1247] 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260\n[1261] 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274\n[1275] 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288\n[1289] 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302\n[1303] 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316\n[1317] 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330\n[1331] 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344\n[1345] 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358\n[1359] 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372\n[1373] 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386\n[1387] 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400\n[1401] 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414\n[1415] 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428\n[1429] 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442\n[1443] 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456\n[1457] 1457 1458\n\n$spec\ncols(\n  id = col_double(),\n  name = col_character(),\n  city = col_character(),\n  country = col_character(),\n  faa = col_character(),\n  icao = col_character(),\n  lat = col_double(),\n  lon = col_double(),\n  alt = col_double(),\n  tz = col_double(),\n  dst = col_character(),\n  tzone = col_character()\n)\n\n$names\n[1] \"faa\"   \"name\"  \"lat\"   \"lon\"   \"alt\"   \"tz\"    \"dst\"   \"tzone\""
  },
  {
    "objectID": "lectures/W03.html#three-important-attributes",
    "href": "lectures/W03.html#three-important-attributes",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Three important attributes",
    "text": "Three important attributes\n\nNames are used to name element of a vector, also works for lists and therefore also dataframes (lists of atomic vectors of the same length)\nDimensions (dim()) is a short numeric vector making a vector behave as a matrix or a higher dimensional array. A vector 1:6 together with dim being c(2,3) is a matrix with 2 rows and 3 columns\n\\(\\begin{bmatrix} 1 & 3 & 5 \\\\ 2 & 4 & 6 \\end{bmatrix}\\)\nClass is used to implement the S3 object oriented system. We don’t need to know the details here. The class system makes it for example possible that the same function, e.g. print() behaves differently for objects of a different class.\n\nClass plays a role in specifying augmented vectors like factors, dates, date-times, or tibbles."
  },
  {
    "objectID": "lectures/W03.html#factors",
    "href": "lectures/W03.html#factors",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Factors",
    "text": "Factors\nR uses factors to handle categorical variables\n\nx &lt;- factor(c(\"BS\", \"MS\", \"PhD\", \"MS\", \"BS\", \"BS\"))\nx\n\n\n\n[1] BS  MS  PhD MS  BS  BS \nLevels: BS MS PhD\n\n\n\nTechnically, a factor is vector of integers with a levels attribute which specifies the categories for the integers.\n\ntypeof(x)\n\n[1] \"integer\"\n\nas.integer(x)\n\n[1] 1 2 3 2 1 1\n\nattributes(x)\n\n$levels\n[1] \"BS\"  \"MS\"  \"PhD\"\n\n$class\n[1] \"factor\"\n\n\n\n\nThe $class \"factor\" makes R print the level of each element of the vector instead of the underlying integer!"
  },
  {
    "objectID": "lectures/W03.html#factors-for-data-visualization",
    "href": "lectures/W03.html#factors-for-data-visualization",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Factors for data visualization",
    "text": "Factors for data visualization\nWe manipulate factors with functions from the forcats package of the tidyverse core.\n\nPlotReverseOrder by frequencyRegroup\n\n\n\nmpg |&gt; ggplot(aes(y = manufacturer)) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nmpg |&gt; ggplot(aes(y = fct_rev(manufacturer))) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nmpg |&gt; ggplot(aes(y = fct_rev(fct_infreq(manufacturer)))) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nmpg |&gt;\n  ggplot(aes(\n    y = fct_other(manufacturer, keep = c(\"dodge\", \"toyota\", \"volkswagen\"))\n  )) +\n  geom_bar()"
  },
  {
    "objectID": "lectures/W03.html#dates",
    "href": "lectures/W03.html#dates",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Dates",
    "text": "Dates\n\n\n\nISO 8601 standard for dates: YYYY-MM-DD.\nDates in R are numeric vectors that represent the number of days since 1 January 1970.\n\n\ny &lt;- as.Date(\"2025-01-01\")\ny\n\n[1] \"2025-01-01\"\n\ntypeof(y)\n\n[1] \"double\"\n\nattributes(y)\n\n$class\n[1] \"Date\"\n\nas.double(y)\n\n[1] 20089\n\nas.double(as.Date(\"1970-01-01\"))\n\n[1] 0\n\nas.double(as.Date(\"1969-01-01\"))\n\n[1] -365\n\n\n\n\nSources Cartoons: Reddit xkcd"
  },
  {
    "objectID": "lectures/W03.html#how-many-days-are-you-old",
    "href": "lectures/W03.html#how-many-days-are-you-old",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "How many days are you old?",
    "text": "How many days are you old?\n\n\nSys.Date() - as.Date(\"1976-01-16\")\n\nTime difference of 18154 days\n\n\nSys.Date() gives the current day your computer is set to\nTest yours and don’t miss your 10.000th day on earth (if you are under 27 years old now)!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/W03.html#date-times",
    "href": "lectures/W03.html#date-times",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Date-times",
    "text": "Date-times\nFor date-time manipulation use lubridate form the tidyverse.\n\nx &lt;- lubridate::ymd_hm(\"1970-01-01 01:00\")\n# Note: Instead of loading package `pack` to use its function `func` you can also write `pack::func`\n# This works when the package is installed even when not loaded.\nx\n\n[1] \"1970-01-01 01:00:00 UTC\"\n\nattributes(x)\n\n$class\n[1] \"POSIXct\" \"POSIXt\" \n\n$tzone\n[1] \"UTC\"\n\nas.double(x)\n\n[1] 3600\n\n\nUTC: Coordinated Universal Time. We are in the UTC+1 timezone.\nPOSIXct: Portable Operating System Interface, calendar time. Stores date and time in seconds with the number of seconds beginning at 1 January 1970."
  },
  {
    "objectID": "lectures/W03.html#how-many-seconds-are-you-old",
    "href": "lectures/W03.html#how-many-seconds-are-you-old",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "How many seconds are you old?",
    "text": "How many seconds are you old?\n\nas.double(lubridate::now()) -\n  as.double(lubridate::ymd_hm(\"1976-01-16_12:04\"))\n\n[1] 1568513187"
  },
  {
    "objectID": "lectures/W03.html#summary-on-factors-and-dates",
    "href": "lectures/W03.html#summary-on-factors-and-dates",
    "title": "W#03 Data Import, Data Wrangling",
    "section": "Summary on Factors and Dates",
    "text": "Summary on Factors and Dates\n\nFactors\n\nCan be used to create categorical variables specified by the levels-attribute\nOften used to specify the order of categories. Particularly useful for graphics!\nCan be manipulated with functions from the forcats package\nOften it is sufficient to work with character vectors.\n\nDates and times\n\nDo not shy away from learning to work with dates and times properly!\nTedious to get right when the date format from the data is messy, but it is worth it!\nUse the lubridate package. Usually you just need one command to convert a character vector to a date or date-time vector, but you have to customize correctly.\n\n\nRead the chapter of factors and dates in R for Data Science"
  },
  {
    "objectID": "lectures/W05.html#preliminaries",
    "href": "lectures/W05.html#preliminaries",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Preliminaries",
    "text": "Preliminaries\nIn this lectures we will use these packages and datasets. You need to do this code in the Console to download data and play with some of the code in this lecture.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ngalton &lt;- read_csv(\"galton.csv\")\nviertel &lt;- read_csv(\"Viertelfest.csv\")\n\nThe datasets used can be downloaded from:\nhttps://github.com/CU-F25-MDSSB-01-Concepts-Tools/Website/tree/main/lectures"
  },
  {
    "objectID": "lectures/W05.html#descriptive-vs.-inferential-statistics",
    "href": "lectures/W05.html#descriptive-vs.-inferential-statistics",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Descriptive vs. Inferential Statistics",
    "text": "Descriptive vs. Inferential Statistics\n\nThe process of using and analyzing summary statistics\n\nSolely concerned with properties of the observed data.\n\nDistinct from inferential statistics:\n\nInference of properties of an underlying distribution given sampled observations from a larger population.\n\n\nSummary Statistics are used to summarize a set of observations to communicate the largest amount of information as simple as possible."
  },
  {
    "objectID": "lectures/W05.html#summary-statistics",
    "href": "lectures/W05.html#summary-statistics",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Summary statistics",
    "text": "Summary statistics\nUnivariate (for one variable)\n\nMeasures of location, or central tendency\nMeasures of statistical dispersion\nMeasure of the shape of the distribution like skewness or kurtosis\n\nBivariate (for two variables)\n\nMeasures of statistical dependence or correlation"
  },
  {
    "objectID": "lectures/W05.html#measures-of-central-tendency-1",
    "href": "lectures/W05.html#measures-of-central-tendency-1",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency\nGoal: For a sequence of numerical observations \\(x_1,\\dots,x_n\\) we want to measure\n\nthe “typical” value.\na value summarizing the location of values on the numerical axis.\n\nThree different ways:\n\nArithmetic mean (also mean, average): Sum of the all observations divided by the number of observations \\(\\frac{1}{n}\\sum_{i=1}^n x_i\\)\nMedian: Assume \\(x_1 \\leq x_2 \\leq\\dots\\leq x_n\\). Then the median is middlemost values in the sequence \\(x_\\frac{n+1}{2}\\) when \\(n\\) odd. For \\(n\\) even there are two middlemost values and the median is \\(\\frac{x_\\frac{n}{2} + x_\\frac{n+1}{2}}{2}\\)\nMode: The value that appears most often in the sequence."
  },
  {
    "objectID": "lectures/W05.html#measures-of-central-tendency-examples",
    "href": "lectures/W05.html#measures-of-central-tendency-examples",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Measures of central tendency: Examples",
    "text": "Measures of central tendency: Examples\n\n\n\nx &lt;- c(1, 2, 4, 10, 300)\nmean(x)\n\n\n\n[1] 63.4\n\n\n\nmedian(x)\n\n\n\n[1] 4\n\n\n\ny &lt;- c(-2, -2, 4, 7, 7, 7)\nmean(y)\n\n\n\n[1] 3.5\n\n\n\nmedian(y)\n\n\n\n[1] 5.5\n\n\nMedian of an even number of numbers: Mean of two most central numbers.\n\nThere is no function for the Mode in R.\n\nMode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\n\nMode(y)\n\n\n\n[1] 7\n\n\n\nMode(x)\n\n\n\n[1] 1\n\n\nWarning: Mode is not unique and there is no fix like for the Median."
  },
  {
    "objectID": "lectures/W05.html#philosophy-of-aggregation",
    "href": "lectures/W05.html#philosophy-of-aggregation",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Philosophy of aggregation",
    "text": "Philosophy of aggregation\n\nThe mean represents total value per value.\nExample: per capita income in a town is the total income per individual\nThe median represents the value such that half of the values are lower and higher.\nIn a democracy where each value is represented by one voter preferring it, the median is the value which is unbeatable by an absolute majority. Half of the people prefer higher the other half lower values. (Median voter model)\nThe mode represents the most common value.\nIn a democracy, the mode represents the winner of a plurality vote where each value runs as a candidate and the winner is the one with the most votes."
  },
  {
    "objectID": "lectures/W05.html#mean-median-mode-properties",
    "href": "lectures/W05.html#mean-median-mode-properties",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Mean, Median, Mode properties",
    "text": "Mean, Median, Mode properties\nDo they deliver one unambiguous answer for any sequence?\n\nMean and median, yes.\nThe mode has no rules for a tie.\n\n\nCan they by generalized to variables with ordered or even unordered categories?\n\n\nMean: No.\nMedian: For ordered categories (except when even number and the two middlemost are not the same)\nMode: For any categorical variable.\n\n\nIs the measured value also always in the data?\n\n\nMean: No.\nMedian: Yes, for sequences of odd length.\nMode: Yes."
  },
  {
    "objectID": "lectures/W05.html#generalized-means",
    "href": "lectures/W05.html#generalized-means",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Generalized means1",
    "text": "Generalized means1\nFor \\(x_1, \\dots, x_n &gt; 0\\) and \\(p\\in \\mathbb{R}_{\\neq 0}\\) the generalized mean is\n\\[M_p(x_1, \\dots, x_n) = (\\frac{1}{n}\\sum_{i=1}^n x_i^p)^\\frac{1}{p}\\]\nFor \\(p = 0\\) it is \\(M_0(x_1, \\dots, x_n) = (\\prod_{i=1}^n x_i)^\\frac{1}{n}\\).\n\\(M_1\\) is the arithmetic mean. \\(M_0\\) is called the geometric mean. \\(M_{-1}\\) the harmonic mean.\nNote: Generalized means are often only reasonable when all values are positive \\(x_i &gt; 0\\).\n\n\n\\(M_0\\) can also be expressed as the exponential (\\(\\exp(x) = e^x\\)) of the mean of the the \\(\\log\\)’s of the \\(x_i\\)’s: \\(\\exp(\\log((\\prod_{i=1}^n x_i)^\\frac{1}{n})) = \\exp(\\frac{1}{n}\\sum_{i=1}^n\\log(x_i))\\).\nAlso called power mean or \\(p\\)-mean."
  },
  {
    "objectID": "lectures/W05.html#box-cox-transformation-function",
    "href": "lectures/W05.html#box-cox-transformation-function",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Box-Cox transformation function",
    "text": "Box-Cox transformation function\nFor \\(p \\in \\mathbb{R}\\): \\(f(x) = \\begin{cases}\\frac{x^p - 1}{p} & \\text{for $p\\neq 0$} \\\\ \\log(x) & \\text{for $p= 0$}\\end{cases}\\)\n\n\nThe \\(p\\)-mean is\n\\[M_p(x) = f^{-1}(\\frac{1}{n}\\sum_{i=1}^n f(x_i))\\]\nwith \\(x = [x_1, \\dots, x_n]\\). \\(f^{-1}\\) is the inverse of \\(f\\).\n\nInverse means \\(f^-1(f(x)) = x =f(f^-1(x))\\).\n\nBox-Cox is a common transformation in data pre-processing to make the variable’s (arithmetic) mean being a “good” measure of central tendency.\n\n\n\n\nCode\npfun &lt;- function(x, p) (x^p - 1) / p\nipfun &lt;- function(x, p) (p * x + 1)^(1 / p)\nggplot() +\n  geom_function(fun = pfun, args = list(p = 1), color = \"red\", size = 1.5) +\n  geom_function(fun = pfun, args = list(p = 2), color = \"red\", alpha = 0.6) +\n  geom_function(fun = pfun, args = list(p = 3), color = \"red\", alpha = 0.3) +\n  geom_function(fun = pfun, args = list(p = 1 / 2), color = \"red3\") +\n  geom_function(fun = pfun, args = list(p = 1 / 3), color = \"red4\") +\n  geom_function(fun = pfun, args = list(p = -1), color = \"blue\", size = 1.5) +\n  geom_function(fun = pfun, args = list(p = -1 / 2), color = \"blue3\") +\n  geom_function(fun = pfun, args = list(p = -1 / 3), color = \"blue4\") +\n  geom_function(fun = pfun, args = list(p = -2), color = \"blue\", alpha = 0.6) +\n  geom_function(fun = pfun, args = list(p = -3), color = \"blue\", alpha = 0.3) +\n  geom_function(fun = log, color = \"black\", size = 1.5) +\n  coord_fixed() +\n  xlim(c(0.01, 4)) +\n  ylim(c(-2, 2)) +\n  labs(x = \"x\", y = \"f(x)\", title = \"p = -1 (blue), 0 (black), +1 (red)\") +\n  theme(title = element_text(size = 2)) +\n  theme_minimal()"
  },
  {
    "objectID": "lectures/W05.html#application-the-wisdom-of-the-crowd",
    "href": "lectures/W05.html#application-the-wisdom-of-the-crowd",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Application: The Wisdom of the Crowd",
    "text": "Application: The Wisdom of the Crowd\n\n\n\nPhenomenon: When collective estimate of a diverse group of independent individuals is better than that of single experts.\nThe classical wisdom-of-the-crowds finding is about point estimation of a continuous quantity.\nPopularized by James Surowiecki (2004).\nThe opening anecdote is about Francis Galton’s1 surprise in 1907 that the crowd at a county fair accurately guessed the weight of an ox’s meat when their individual guesses were averaged.\n\n\n\n\n\nGalton (1822-1911) was a half-cousin to Charles Darwin and one of the founding fathers of statistics. He also was a scientific racist, see https://twitter.com/kareem_carr/status/1575506343401775104?s=20&t=8T5TzrayAWNShmOSzJgCJQ.."
  },
  {
    "objectID": "lectures/W05.html#galtons-data",
    "href": "lectures/W05.html#galtons-data",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Galton’s data1",
    "text": "Galton’s data1\nWhat is the weight of the meat of this ox?\n\ngalton |&gt;\n  ggplot(aes(Estimate)) +\n  geom_histogram(binwidth = 5) +\n  geom_vline(xintercept = 1198, color = \"green\") +\n  geom_vline(xintercept = mean(galton$Estimate), color = \"red\") +\n  geom_vline(xintercept = median(galton$Estimate), color = \"blue\") +\n  geom_vline(xintercept = Mode(galton$Estimate), color = \"purple\")\n\n\n\n\n\n\n\n\n787 estimates, true value 1198, mean 1196.7, median 1208, mode 1218\nKenneth Wallis dug out the data from Galton’s notebook and put it here https://warwick.ac.uk/fac/soc/economics/staff/kfwallis/publications/galton_data.xlsx"
  },
  {
    "objectID": "lectures/W05.html#viertelfest-bremen-2008",
    "href": "lectures/W05.html#viertelfest-bremen-2008",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Viertelfest Bremen 20081",
    "text": "Viertelfest Bremen 20081\nHow many lots will be sold by the end of the festival?\n\nviertel |&gt;\n  ggplot(aes(\n    `Schätzung`\n  )) +\n  geom_histogram() +\n  geom_vline(xintercept = 10788, color = \"green\") +\n  geom_vline(xintercept = mean(viertel$Schätzung), color = \"red\") +\n  geom_vline(xintercept = median(viertel$Schätzung), color = \"blue\") +\n  geom_vline(xintercept = Mode(viertel$Schätzung), color = \"purple\")\n\n\n\n\n\n\n\n\n1226 estimates, the maximal value is 29530000! We should filter …\nData collected as additional guessing game at the Lottery “Haste mal ’nen Euro?”, data provided by Jan Lorenz https://docs.google.com/spreadsheets/d/1HiYhUrYrsbeybJ10mwsae_hQCawZlUQFOOZzcugXzgA/edit#gid=0"
  },
  {
    "objectID": "lectures/W05.html#viertelfest-bremen-2008-1",
    "href": "lectures/W05.html#viertelfest-bremen-2008-1",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Viertelfest Bremen 2008",
    "text": "Viertelfest Bremen 2008\nHow many lots will be sold by the end of the festival?\n\nviertel |&gt;\n  filter(Schätzung &lt; 100000) |&gt;\n  ggplot(aes(`Schätzung`)) +\n  geom_histogram(binwidth = 500) +\n  geom_vline(xintercept = 10788, color = \"green\") +\n  geom_vline(xintercept = mean(viertel$Schätzung), color = \"red\") +\n  geom_vline(xintercept = median(viertel$Schätzung), color = \"blue\") +\n  geom_vline(xintercept = Mode(viertel$Schätzung), color = \"purple\") +\n  geom_vline(xintercept = exp(mean(log(viertel$Schätzung))), color = \"orange\")\n\n\n1226 estimates, true value 10788, mean 53163.9, median 9843, mode 10000,\ngeometric mean 10510.1"
  },
  {
    "objectID": "lectures/W05.html#log_10-transformation-viertelfest",
    "href": "lectures/W05.html#log_10-transformation-viertelfest",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "\\(\\log_{10}\\) transformation Viertelfest",
    "text": "\\(\\log_{10}\\) transformation Viertelfest\n\nviertel |&gt;\n  mutate(log10Est = log10(Schätzung)) |&gt;\n  ggplot(aes(log10Est)) +\n  geom_histogram(binwidth = 0.05) +\n  geom_vline(xintercept = log10(10788), color = \"green\") +\n  geom_vline(xintercept = log10(mean(viertel$Schätzung)), color = \"red\") +\n  geom_vline(xintercept = log10(median(viertel$Schätzung)), color = \"blue\") +\n  geom_vline(xintercept = log10(Mode(viertel$Schätzung)), color = \"purple\") +\n  geom_vline(xintercept = mean(log10(viertel$Schätzung)), color = \"orange\")\n\n\n1226 estimates, true value 10788, mean 53163.9, median 9843, mode 10000,\ngeometric mean 10510.1"
  },
  {
    "objectID": "lectures/W05.html#wisdom-of-the-crowd-insights",
    "href": "lectures/W05.html#wisdom-of-the-crowd-insights",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Wisdom of the crowd insights",
    "text": "Wisdom of the crowd insights\n\nIn Galton’s sample the different measures do not make a big difference\nIn the Viertelfest data the arithmetic mean performs very bad!\nThe mean is vulnerable to extreme values.\nQuoting Galton on the mean as a democratic aggregation function:\n“The mean gives voting power to the cranks in proportion to their crankiness.”\nThe mode tends to be on focal values as round numbers (10,000). In Galton’s data this is not so pronounced beause estimators used several weight units (which Galton converted to pounds).\nHow to choose a measure to aggregate the wisdom?\n\nBy the nature of the estimate problem? Is the scale mostly clear? (Are we in the hundreds, thousands, ten thousands, …)\nBy the nature of the distribution?\nThere is no real insurance against a systematic bias in the population."
  },
  {
    "objectID": "lectures/W05.html#measures-of-dispersion-1",
    "href": "lectures/W05.html#measures-of-dispersion-1",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Measures of dispersion1",
    "text": "Measures of dispersion1\nGoal: We want to measure\n\nHow spread out values are around the central tendency.\nHow stretched or squeezed is the distribution?\n\nVariance is the mean of the squared deviation from the mean: \\(\\text{Var}(x) = \\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2\\) where \\(\\mu\\) (mu) is the mean.\n\nStandard deviation is the square root of the variance \\(\\text{SD}(x) = \\sqrt{\\text{Var}(x)}\\).\nThe standard deviation is often denoted \\(\\sigma\\) (sigma) and the variance \\(\\sigma^2\\).\n\n\nMean absolute deviation (MAD) is the mean of the absolute deviation from the mean: \\(\\text{MAD}(x) = \\frac{1}{n}\\sum_{i=1}^n|x_i - \\mu|\\).\n\n\nWarning: MAD can also be Median absolute deviation from the median.\nRange is the difference of the maximal and the minimal value \\(\\max(x) - \\min(x)\\).\n\nAlso called variability, scatter, or spread."
  },
  {
    "objectID": "lectures/W05.html#examples-of-measures-of-dispersion",
    "href": "lectures/W05.html#examples-of-measures-of-dispersion",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Examples of measures of dispersion",
    "text": "Examples of measures of dispersion\n\n\n\nvar(galton$Estimate)\n\n[1] 5415.013\n\nsd(galton$Estimate)\n\n[1] 73.58677\n\nmad(galton$Estimate) # Warning: median absolute deviation is default\n\n[1] 51.891\n\nrange(galton$Estimate) # Oh, range gives us a vector of min and max. So, we diff\n\n[1]  896 1516\n\ndiff(range(galton$Estimate))\n\n[1] 620\n\n\n\n\nvar(viertel$Schätzung)\n\n[1] 719774887849\n\nsd(viertel$Schätzung)\n\n[1] 848395.5\n\nmad(viertel$Schätzung) # Warning: median absolute deviation is default\n\n[1] 8771.803\n\nrange(viertel$Schätzung) # Oh, range gives us a vector of min and max. So, we diff\n\n[1]      120 29530000\n\ndiff(range(viertel$Schätzung))\n\n[1] 29529880\n\n\n\n\n\nVariance (and standard deviation) in statistics is usually computed with \\(\\frac{1}{n-1}\\) instead of \\(\\frac{1}{n}\\) to provide an unbiased estimator of the potentially underlying population variance. We omit more detail here."
  },
  {
    "objectID": "lectures/W05.html#normalization-of-variables",
    "href": "lectures/W05.html#normalization-of-variables",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Normalization of variables",
    "text": "Normalization of variables\nIn Machine Learning, Statistics, and Descripitve Analysis we often want to bring different variables to common scales. We want to make the dispersion and the location comparable.\nTo that end, some linear transformation are common:\n\nStandardization\nMin-max Feature Scaling\n\nWhen we normalize a variable we receive a dimensionless variable. It does not have a unit.\nExample: We measure height in \\(m\\) meters. When we standardize are scale by min-max the new variable has no unit. Mathematically it cancels out."
  },
  {
    "objectID": "lectures/W05.html#standardization",
    "href": "lectures/W05.html#standardization",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Standardization",
    "text": "Standardization\nVariables are standardized by subtracting their mean and then dividing by their standard deviations.\nA value from a standardized variable is called a standard score or z-score.\n\\(z_i = \\frac{x_i - \\mu}{\\sigma}\\)\nwhere \\(\\mu\\) is the mean and \\(\\sigma\\) the standard deviation of the vector \\(x\\).\n\nThis is a shift-scale transformation. We shift each value by the mean and scale by the standard deviation.\nA standard score \\(z_i\\) represents how many standard deviations \\(x_i\\) is away from the mean of \\(x\\).\nThe standard scores \\(z_i\\)’s have a mean of zero and a standard deviation of one (by construction)."
  },
  {
    "objectID": "lectures/W05.html#min-max-feature-scaling",
    "href": "lectures/W05.html#min-max-feature-scaling",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Min-max Feature Scaling",
    "text": "Min-max Feature Scaling\nWhen we want to make the values of the scaled variable to range from zero to one.\nThe transformed variable values \\(y_i\\)’s are\n\\[y_i = \\frac{x_i - \\min(x)}{\\max(x) - \\min(x)}.\\]\nWe shift by the minimum \\(\\min(x)\\) and scale by the range \\(\\max(x) - \\min(x)\\).\n\nWhat are mean and standard deviation of \\(y\\)? We do not know, but less than one.\nCaution: The new values are heavily dependent of the actual values of \\(\\min\\) and \\(\\max\\)!"
  },
  {
    "objectID": "lectures/W05.html#data-sets-1a-and-1b-widsom-of-crowd",
    "href": "lectures/W05.html#data-sets-1a-and-1b-widsom-of-crowd",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Data Sets 1a and 1b: Widsom of Crowd",
    "text": "Data Sets 1a and 1b: Widsom of Crowd\n1a: Ox weigh guessing competition 1907 (collected by Galton)\n\ngalton |&gt; ggplot(aes(Estimate)) + geom_histogram(binwidth = 5)\n\n\n\n\n\n\n\n\n1b: Viertelfest “guess the number of sold lots”-competition 2009\n\nviertel |&gt;\n  filter(Schätzung &lt; 100000) |&gt;\n  ggplot(aes(`Schätzung`)) +\n  geom_histogram(binwidth = 500)"
  },
  {
    "objectID": "lectures/W05.html#data-set-2-palmer-penguins",
    "href": "lectures/W05.html#data-set-2-palmer-penguins",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Data Set 2: Palmer Penguins",
    "text": "Data Set 2: Palmer Penguins\nPalmer Penguins\nChinstrap, Gentoo, and Adélie Penguins\n   \n\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "lectures/W05.html#summary-from-base-r",
    "href": "lectures/W05.html#summary-from-base-r",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "summary from base R",
    "text": "summary from base R\n\n\nShows summary statistics for the values in a vector\n\nsummary(galton$Estimate)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    896    1162    1208    1197    1236    1516 \n\n\n\nsummary(viertel$Schätzung)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n     120     5000     9843    53164    20000 29530000 \n\n\nOr for all columns in a data frame\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\n\nQuestion\nWhat does\n1 st Qu. and\n3 rd Qu. mean?"
  },
  {
    "objectID": "lectures/W05.html#quantiles-1",
    "href": "lectures/W05.html#quantiles-1",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Quantiles",
    "text": "Quantiles\nCut points specifying intervals which contain equal amounts of values of the distribution.\n\\(q\\)-quantiles divide numbers into \\(q\\) intervals covering all values.\nThe quantiles are the cut points: For \\(q\\) intervals there are \\(q-1\\) cut points of interest.\n\nThe one 2-quantile is the median\nThe three 4-quantiles are called quartiles\n\n1st Qu. is the first quartile\nThe second quartile is the median\n3rd Qu. is the third quartile\n\n100-quantiles are called percentiles\n\n\n\nWe omit problems of estimating quantiles from a sample where the number of estimates does not fit to a desired partition of equal size here."
  },
  {
    "objectID": "lectures/W05.html#a-galton-quartiles",
    "href": "lectures/W05.html#a-galton-quartiles",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "1a Galton: Quartiles",
    "text": "1a Galton: Quartiles\n\n# Min, 3 Quartiles, Max\nquantile(galton$Estimate, prob = seq(0, 1, by = 0.25))\n\n    0%    25%    50%    75%   100% \n 896.0 1162.5 1208.0 1236.0 1516.0 \n\n\nInterpretation: What does the value at 25% mean?\n\nThe 25% of all values are lower than the value. 75% are larger.\n\n\n\ngalton |&gt;\n  ggplot(aes(Estimate)) +\n  geom_histogram(binwidth = 5) +\n  geom_vline(\n    xintercept = quantile(galton$Estimate, prob = seq(0, 1, by = 0.25)),\n    color = \"red\"\n  )"
  },
  {
    "objectID": "lectures/W05.html#a-galton-20-quantiles",
    "href": "lectures/W05.html#a-galton-20-quantiles",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "1a Galton: 20-quantiles",
    "text": "1a Galton: 20-quantiles\n\n# Min, 3 Quartiles, Max\nquantile(galton$Estimate, prob = seq(0, 1, by = 0.05))\n\n    0%     5%    10%    15%    20%    25%    30%    35%    40%    45%    50% \n 896.0 1078.3 1109.0 1126.9 1150.0 1162.5 1174.0 1181.0 1189.0 1199.0 1208.0 \n   55%    60%    65%    70%    75%    80%    85%    90%    95%   100% \n1214.0 1219.0 1225.0 1231.0 1236.0 1243.8 1255.1 1270.0 1293.0 1516.0 \n\n\n\ngalton |&gt;\n  ggplot(aes(Estimate)) +\n  geom_histogram(binwidth = 5) +\n  geom_vline(\n    xintercept = quantile(galton$Estimate, prob = seq(0, 1, by = 0.05)),\n    color = \"red\"\n  )"
  },
  {
    "objectID": "lectures/W05.html#b-viertelfest-quartiles",
    "href": "lectures/W05.html#b-viertelfest-quartiles",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "1b Viertelfest: Quartiles",
    "text": "1b Viertelfest: Quartiles\n\nquantile(viertel$Schätzung, prob = seq(0, 1, by = 0.25))\n\n      0%      25%      50%      75%     100% \n     120     5000     9843    20000 29530000 \n\n\n\nviertel |&gt;\n  filter(Schätzung &lt; 100000) |&gt;\n  ggplot(aes(\n    `Schätzung`\n  )) +\n  geom_histogram(binwidth = 500) +\n  geom_vline(\n    xintercept = quantile(\n      viertel$`Schätzung`,\n      prob = seq(0, 1, by = 0.25)\n    )[1:4],\n    color = \"red\"\n  )"
  },
  {
    "objectID": "lectures/W05.html#b-viertelfest-20-quantiles",
    "href": "lectures/W05.html#b-viertelfest-20-quantiles",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "1b Viertelfest: 20-quantiles",
    "text": "1b Viertelfest: 20-quantiles\n\nquantile(viertel$Schätzung, prob = seq(0, 1, by = 0.05))\n\n         0%          5%         10%         15%         20%         25% \n     120.00     1213.25     2000.00     3115.00     4012.00     5000.00 \n        30%         35%         40%         45%         50%         55% \n    5853.50     7000.00     7821.00     8705.25     9843.00    10967.50 \n        60%         65%         70%         75%         80%         85% \n   12374.00    14444.00    16186.00    20000.00    27500.00    38000.00 \n        90%         95%        100% \n   63649.50    99773.50 29530000.00 \n\n\n\nviertel |&gt;\n  filter(Schätzung &lt; 100000) |&gt;\n  ggplot(aes(`Schätzung`)) +\n  geom_histogram(binwidth = 500) +\n  geom_vline(\n    xintercept = quantile(viertel$`Schätzung`, prob = seq(0, 1, by = 0.05))[\n      1:19\n    ],\n    color = \"red\"\n  )"
  },
  {
    "objectID": "lectures/W05.html#palmer-penguins-flipper-length-quartiles",
    "href": "lectures/W05.html#palmer-penguins-flipper-length-quartiles",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "2 Palmer Penguins Flipper Length: Quartiles",
    "text": "2 Palmer Penguins Flipper Length: Quartiles\n\nquantile(penguins$flipper_length_mm, prob = seq(0, 1, by = 0.25), na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n 172  190  197  213  231 \n\n\n\npenguins |&gt;\n  ggplot(aes(flipper_length_mm)) +\n  geom_histogram(binwidth = 1) +\n  geom_vline(\n    xintercept = quantile(\n      penguins$flipper_length_mm,\n      prob = seq(0, 1, by = 0.25),\n      na.rm = TRUE\n    ),\n    color = \"red\"\n  )"
  },
  {
    "objectID": "lectures/W05.html#palmer-penguins-flipper-length-20-quantiles",
    "href": "lectures/W05.html#palmer-penguins-flipper-length-20-quantiles",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "2 Palmer Penguins Flipper Length: 20-quantiles",
    "text": "2 Palmer Penguins Flipper Length: 20-quantiles\n\nquantile(penguins$flipper_length_mm, prob = seq(0, 1, by = 0.05), na.rm = TRUE)\n\n   0%    5%   10%   15%   20%   25%   30%   35%   40%   45%   50%   55%   60% \n172.0 181.0 185.0 187.0 188.0 190.0 191.0 193.0 194.0 195.0 197.0 199.0 203.0 \n  65%   70%   75%   80%   85%   90%   95%  100% \n208.0 210.0 213.0 215.0 218.0 220.9 225.0 231.0 \n\n\n\npenguins |&gt;\n  ggplot(aes(flipper_length_mm)) +\n  geom_histogram(binwidth = 1) +\n  geom_vline(\n    xintercept = quantile(\n      penguins$flipper_length_mm,\n      prob = seq(0, 1, by = 0.05),\n      na.rm = TRUE\n    ),\n    color = \"red\"\n  )"
  },
  {
    "objectID": "lectures/W05.html#interquartile-range-iqr",
    "href": "lectures/W05.html#interquartile-range-iqr",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Interquartile range (IQR)",
    "text": "Interquartile range (IQR)\nThe difference between the 1st and the 3rd quartile. Alternative dispersion measure.\nThe range in which the middle 50% of the values are located.\nExamples:\n\n\n\n# Min, 3 Quartiles, Max\nIQR(galton$Estimate)\n\n[1] 73.5\n\nsd(galton$Estimate) # for comparison\n\n[1] 73.58677\n\nIQR(viertel$Schätzung)\n\n[1] 15000\n\nsd(viertel$Schätzung) # for comparison\n\n[1] 848395.5\n\nIQR(penguins$flipper_length_mm, na.rm = TRUE)\n\n[1] 23\n\nsd(penguins$flipper_length_mm, na.rm = TRUE) # for comparison\n\n[1] 14.06171"
  },
  {
    "objectID": "lectures/W05.html#boxplots",
    "href": "lectures/W05.html#boxplots",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Boxplots",
    "text": "Boxplots\nA condensed visualization of a distribution showing location, spread, skewness and outliers.\n\ngalton |&gt; ggplot(aes(x = Estimate)) + geom_boxplot()\n\n\n\nThe box shows the median in the middle and the other two quartiles as their borders.\nWhiskers: From above the upper quartile, a distance of 1.5 times the IQR is measured out and a whisker is drawn up to the largest observed data point from the dataset that falls within this distance. Similarly, for the lower quartile.\nWhiskers must end at an observed data point! (So lengths can differ.)\nAll other values outside of box and whiskers are shown as points and often called outliers. (There may be none.)"
  },
  {
    "objectID": "lectures/W05.html#boxplots-vs.-histograms",
    "href": "lectures/W05.html#boxplots-vs.-histograms",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Boxplots vs. histograms",
    "text": "Boxplots vs. histograms\n\nHistograms can show the shape of the distribution well, but not the summary statistics like the median.\n\n\ngalton |&gt; ggplot(aes(x = Estimate)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\ngalton |&gt; ggplot(aes(x = Estimate)) + geom_histogram(binwidth = 5)"
  },
  {
    "objectID": "lectures/W05.html#boxplots-vs.-histograms-1",
    "href": "lectures/W05.html#boxplots-vs.-histograms-1",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Boxplots vs. histograms",
    "text": "Boxplots vs. histograms\n\nBoxplots can not show the patterns of bimodal or multimodal distributions.\n\n\npalmerpenguins::penguins |&gt; ggplot(aes(x = flipper_length_mm)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\npalmerpenguins::penguins |&gt;\n  ggplot(aes(x = flipper_length_mm)) +\n  geom_histogram(binwidth = 1)"
  },
  {
    "objectID": "lectures/W05.html#minimizing-proporties-of-mean-and-median",
    "href": "lectures/W05.html#minimizing-proporties-of-mean-and-median",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Minimizing proporties of Mean and Median",
    "text": "Minimizing proporties of Mean and Median\nMean minimizes the mean of squared deviations from it. No other value \\(a\\) has a lower mean of square distances from the data points. \\(\\frac{1}{n}\\sum_{i=1}^n(x_i - a)^2\\).\n\nMedian minimizes the sum of the absolute deviation. No other value \\(a\\) has a lower mean of absolute distances from the data points. \\(\\frac{1}{n}\\sum_{i=1}^n|x_i - a|\\).\n\n\nThe Concept of Minimizing\nIs central for all statisitical fitting and learning procedures! These are among the simplest examples of this concept."
  },
  {
    "objectID": "lectures/W05.html#two-families-of-summary-statistics",
    "href": "lectures/W05.html#two-families-of-summary-statistics",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Two families of summary statistics",
    "text": "Two families of summary statistics\n\nMeasures based on sums (related to mathematical moments)\n\nMean\nStandard deviation\n\nMeasures based on the ordered sequence of these observations (order statistics)\n\nMedian (and all quantiles)\nInterquartile range"
  },
  {
    "objectID": "lectures/W05.html#a-hierarchy-of-moments",
    "href": "lectures/W05.html#a-hierarchy-of-moments",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "A hierarchy of moments",
    "text": "A hierarchy of moments\n\\(k\\)th raw moment: \\(\\frac{1}{n}\\sum_i^n x_i^k\\).\n\nThe mean is the 1st raw moment (because no exponents appear in formula)\nThe variance is the 2nd raw moment the mean-shifted \\(x\\)\nThe 3rd moment appears in the definition of the skewness of \\(x\\)\nThe 4th moment appears in the definition of the kurtosis of \\(x\\)"
  },
  {
    "objectID": "lectures/W05.html#skewness",
    "href": "lectures/W05.html#skewness",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Skewness",
    "text": "Skewness\nThe skewness of a distribution is a measure of its asymmetry.\nEquation: \\(\\text{skewness} = \\frac{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^3}{\\left(\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2\\right)^{3/2}}\\)\n\nPositive skewness: The right tail is longer or fatter than the left tail.\nNegative skewness: The left tail is longer or fatter than the right tail.\n\n\nThe relation of mean and median can give a hint on skewness!\nThe Viertelfest data is heavily positively skew. (The Galton data is a little bit negatively skew, but it is barely visible.)"
  },
  {
    "objectID": "lectures/W05.html#kurtosis",
    "href": "lectures/W05.html#kurtosis",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Kurtosis",
    "text": "Kurtosis\nThe kurtosis of a distribution is a measure of the “tailedness” of the distribution. It often goes along with also higher “peakedness”.\nEquation: \\(\\text{kurtosis} = \\frac{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^4}{\\left(\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2\\right)^{2}}\\)\n\nLeptokurtic: Fatter tails and a higher peak than the normal distribution.\nPlatykurtic: Thinner tails and a lower peak than the normal distribution.\n\n  A logarithmic y-axis shows the fatter tails!"
  },
  {
    "objectID": "lectures/W05.html#covariance",
    "href": "lectures/W05.html#covariance",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Covariance",
    "text": "Covariance\nGoal: We want to measure the joint variation in numerical observations of two variables \\(x_1,\\dots,x_n\\) and \\(y_1, \\dots, y_n\\).\nCovariance\n\\(\\text{cov}(x,y) = \\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu_x)(y_i - \\mu_y)\\)\nwhere \\(\\mu_x\\) and \\(\\mu_y\\) are the arithmetic means of \\(x\\) and \\(y\\).\n\nNote: \\(\\text{cov}(x,x) = \\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu_x)(x_i - \\mu_x) = \\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu_x)^2 = \\text{Var}(x)\\)"
  },
  {
    "objectID": "lectures/W05.html#correlation",
    "href": "lectures/W05.html#correlation",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Correlation",
    "text": "Correlation\nGoal: We want to measure the linear correlation in numerical observations of two variables \\(x_1,\\dots,x_n\\) and \\(y_1, \\dots, y_n\\).\nPearson correlation coefficient \\(r_{xy} = \\frac{\\sum_{i=1}^n(x_i - \\mu_x)(y_i - \\mu_y)}{\\sqrt{\\sum_{i=1}^n(x_i - \\mu_x)^2}\\sqrt{\\sum_{i=1}^n(y_i - \\mu_y)^2}}\\)\n(Note: Do you are missing $ terms compared to covariance? They all cancel out!)\n\nRelation to covariance: \\(r_{xy} = \\frac{\\text{cov}(x,y)}{\\sigma_x\\sigma_y}\\)\nwhere \\(\\sigma_x\\) and \\(\\sigma_y\\) are the standard deviations of \\(x\\) and \\(y\\).\nRelation to standard scores:\nWhen \\(x\\) and \\(y\\) are standard scores (each with mean zero and standard deviation one), then \\(\\text{cov}(x,y) = r_{xy}\\).\n\n\n\nThere are other correlation coefficients which we omit here."
  },
  {
    "objectID": "lectures/W05.html#interpretation-of-correlation",
    "href": "lectures/W05.html#interpretation-of-correlation",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Interpretation of correlation",
    "text": "Interpretation of correlation\nCorrelation between two vectors \\(x\\) and \\(y\\) is “normalized”.\n\nThe maximal possible values is \\(r_{xy} = 1\\)\n\n\\(x\\) and \\(y\\) are fully correlated\n\nThe minimal values is \\(r_{xy} = -1\\)\n\n\\(x\\) and \\(y\\) are anticorrelated\n\n\\(r_{xy} \\approx 0\\) mean\n\nthe variables are uncorrelated\n\n\\(r_{xy} = r_{yx}\\)"
  },
  {
    "objectID": "lectures/W05.html#correlation-matrix",
    "href": "lectures/W05.html#correlation-matrix",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Correlation matrix",
    "text": "Correlation matrix\nUsing corrr from the packages tidymodels\n\nlibrary(corrr)\npenguins |&gt; select(-species, -island, -sex) |&gt; correlate()\n\n# A tibble: 5 × 6\n  term        bill_length_mm bill_depth_mm flipper_length_mm body_mass_g    year\n  &lt;chr&gt;                &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 bill_lengt…        NA            -0.235              0.656      0.595   0.0545\n2 bill_depth…        -0.235        NA                 -0.584     -0.472  -0.0604\n3 flipper_le…         0.656        -0.584             NA          0.871   0.170 \n4 body_mass_g         0.595        -0.472              0.871     NA       0.0422\n5 year                0.0545       -0.0604             0.170      0.0422 NA"
  },
  {
    "objectID": "lectures/W05.html#correlation-table",
    "href": "lectures/W05.html#correlation-table",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Correlation table",
    "text": "Correlation table\nUsing correlation from the packages correlation\n\nlibrary(correlation)\nresults &lt;- palmerpenguins::penguins |&gt;\n  select(-species, -island, -sex) |&gt;\n  correlation()\nresults\n\n# Correlation Matrix (pearson-method)\n\nParameter1        |        Parameter2 |     r |         95% CI | t(340) |         p\n-----------------------------------------------------------------------------------\nbill_length_mm    |     bill_depth_mm | -0.24 | [-0.33, -0.13] |  -4.46 | &lt; .001***\nbill_length_mm    | flipper_length_mm |  0.66 | [ 0.59,  0.71] |  16.03 | &lt; .001***\nbill_length_mm    |       body_mass_g |  0.60 | [ 0.52,  0.66] |  13.65 | &lt; .001***\nbill_length_mm    |              year |  0.05 | [-0.05,  0.16] |   1.01 | 0.797    \nbill_depth_mm     | flipper_length_mm | -0.58 | [-0.65, -0.51] | -13.26 | &lt; .001***\nbill_depth_mm     |       body_mass_g | -0.47 | [-0.55, -0.39] |  -9.87 | &lt; .001***\nbill_depth_mm     |              year | -0.06 | [-0.17,  0.05] |  -1.11 | 0.797    \nflipper_length_mm |       body_mass_g |  0.87 | [ 0.84,  0.89] |  32.72 | &lt; .001***\nflipper_length_mm |              year |  0.17 | [ 0.06,  0.27] |   3.17 | 0.007**  \nbody_mass_g       |              year |  0.04 | [-0.06,  0.15] |   0.78 | 0.797    \n\np-value adjustment method: Holm (1979)\nObservations: 342\n\n\n\n\nWhat do the stars mean? Statistical significance automatically added by the . We treat that later."
  },
  {
    "objectID": "lectures/W05.html#correlation-visualization",
    "href": "lectures/W05.html#correlation-visualization",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Correlation visualization",
    "text": "Correlation visualization\n\nresults %&gt;%\n  summary(redundant = TRUE) %&gt;%\n  plot()"
  },
  {
    "objectID": "lectures/W05.html#exploratory-data-analysis-1",
    "href": "lectures/W05.html#exploratory-data-analysis-1",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nEDA is the systematic exploration of data using\n\nvisualization\ntransformation\ncomputation of characteristic values\nmodeling\n\n\n\nComputation of characteristic values: Functions like mean, median, mode, standard deviation, or interquartile range\nModeling: Operations like linear regression or dimensionality reduction. We haven’t talked about it, but will do soon."
  },
  {
    "objectID": "lectures/W05.html#systematic-but-no-standard-routine",
    "href": "lectures/W05.html#systematic-but-no-standard-routine",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Systematic but no standard routine",
    "text": "Systematic but no standard routine\n\n“There are no routine statistical questions, only questionable statistical routines.” — Sir David Cox\n\n\n“Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.” — John Tukey"
  },
  {
    "objectID": "lectures/W05.html#systematic-but-no-standard-routine-1",
    "href": "lectures/W05.html#systematic-but-no-standard-routine-1",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Systematic but no standard routine",
    "text": "Systematic but no standard routine\n\nGoal of EDA: Develop understanding of your data.\nEDA’s iterative cycle\n\nGenerate questions about your data.\nSearch for answers by visualizing, transforming, and modelling your data.\nUse what you learn to refine your questions and/or generate new questions.\n\nEDA is fundamentally a creative process. What could be interesting?"
  },
  {
    "objectID": "lectures/W05.html#questions",
    "href": "lectures/W05.html#questions",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Questions",
    "text": "Questions\n\nThe way to ask quality questions:\n\nGenerate many questions!\nYou cannot come up with most interesting questions when you start.\n\nThere is no rule which questions to ask. These are useful\n\nWhat type of variation occurs within my variables?\n(Barplots, Histograms,…)\nWhat type of covariation occurs between my variables?\n(Scatterplots, Timelines,…)"
  },
  {
    "objectID": "lectures/W05.html#eda-embedded-in-a-statistical-data-science-project",
    "href": "lectures/W05.html#eda-embedded-in-a-statistical-data-science-project",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "EDA embedded in a statistical data science project",
    "text": "EDA embedded in a statistical data science project\n\nStating and refining the question\nExploring the data\nBuilding formal statistical models\nInterpreting the results\nCommunicating the results\n\n\n\nRoger D. Peng and Elizabeth Matsui. “The Art of Data Science.” A Guide for Anyone Who Works with Data. Skybrude Consulting, LLC (2015)."
  },
  {
    "objectID": "lectures/W05.html#six-types-of-questions",
    "href": "lectures/W05.html#six-types-of-questions",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Six types of questions",
    "text": "Six types of questions\n\nDescriptive: summarize a characteristic of a set of data\nExploratory: analyze to see if there are patterns, trends, or relationships between variables (hypothesis generating)\nInferential: analyze patterns, trends, or relationships in representative data from a population\nPredictive: make predictions for individuals or groups of individuals\nCausal: whether changing one factor will change another factor, on average, in a population\nMechanistic: explore “how” one factor (probably/most likely/potentially) changes another\n\n\nWe only did 1 and 2, so far.\n\n\n\nLeek, Jeffery T., and Roger D. Peng. 2015. “What Is the Question?” Science 347 (6228): 1314–15. https://doi.org/10.1126/science.aaa6146."
  },
  {
    "objectID": "lectures/W05.html#descriptive-projects",
    "href": "lectures/W05.html#descriptive-projects",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Descriptive Projects",
    "text": "Descriptive Projects\n\n\n\nDubin (1969). Theory Building - A Practical Guide to the Construction and Testing of Theoretical Models"
  },
  {
    "objectID": "lectures/W05.html#data-analysis-flowchart",
    "href": "lectures/W05.html#data-analysis-flowchart",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Data Analysis Flowchart",
    "text": "Data Analysis Flowchart"
  },
  {
    "objectID": "lectures/W05.html#example-covid-19-and-vitamin-d",
    "href": "lectures/W05.html#example-covid-19-and-vitamin-d",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Example: COVID-19 and Vitamin D",
    "text": "Example: COVID-19 and Vitamin D\nExamine\n\nDescriptive: the frequency of daily hospitalisations due to COVID-19 and the frequency of Vitamin D intake in a sample of people\nExploratory: examine the relationships between taking Vitamine D supplements and COVID-19 hospitalisations in a sample of people diagnosed with COVID-19\nInferential: examine whether any relationship between taking Vitamin D supplements and COVID-19 hospitalisations found in the sample hold for the population at large\nPredictive: examine what types of people and how many will take Vitamin D supplements next year\nCausal: examine whether people with COVID-19 who were randomly assigned to take Vitamin D supplements or those who were not are hospitalised\nMechanistic: examine when and how increased vitamin D intake leads to a reduction in the number of viral illnesses"
  },
  {
    "objectID": "lectures/W05.html#questions-to-questions",
    "href": "lectures/W05.html#questions-to-questions",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Questions to questions",
    "text": "Questions to questions\n\nDo you have appropriate data to answer your question?\nDo you have information on confounding variables?\nWas the data you’re working with collected in a way that introduces bias?\n\n\n\nExample\nI want to estimate the average number of children in households in Bremen. I conduct a survey at an elementary school and ask pupils how many children, including themselves, live in their house. Then, I take the average of the responses.\n\nIs this a biased or an unbiased estimate of the number of children in households in Bremen?\nIf biased, will the value be an overestimate or underestimate?"
  },
  {
    "objectID": "lectures/W05.html#context-information-is-important",
    "href": "lectures/W05.html#context-information-is-important",
    "title": "W#05: Descriptive Statistics, Exploratory Data Analysis",
    "section": "Context Information is important!",
    "text": "Context Information is important!\n\nNot all information is in the data!\nPotential confounding variables you infer from general knowledge\nInformation about data collection you may receive from an accompanying report\nInformation about computed variables you may need to look up in accompanying documentation\nInformation about certain variables you may find in an accompanying codebook. For example the exact wording of questions in survey data."
  }
]